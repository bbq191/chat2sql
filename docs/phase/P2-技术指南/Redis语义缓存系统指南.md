# ğŸ”´ Redisè¯­ä¹‰ç¼“å­˜ç³»ç»ŸæŒ‡å—

<div align="center">

![Redis](https://img.shields.io/badge/Redis-7.4+-red.svg)
![Cache](https://img.shields.io/badge/Cache-Semantic-blue.svg)
![HitRate](https://img.shields.io/badge/Hit_Rate->75%25-green.svg)

**Chat2SQL P2é˜¶æ®µ - é«˜æ€§èƒ½è¯­ä¹‰ç¼“å­˜å®Œæ•´å®ç°æ–¹æ¡ˆ**

</div>

## ğŸ“‹ æ¦‚è¿°

æœ¬æ–‡æ¡£ä¸“é—¨é’ˆå¯¹Chat2SQLç³»ç»Ÿçš„Redisè¯­ä¹‰ç¼“å­˜å®ç°ï¼Œæä¾›ä»æ¶æ„è®¾è®¡åˆ°ä»£ç å®ç°çš„å®Œæ•´æŠ€æœ¯æ–¹æ¡ˆï¼Œå®ç°é«˜å‘½ä¸­ç‡çš„æ™ºèƒ½ç¼“å­˜ç³»ç»Ÿï¼Œå¤§å¹…æå‡æŸ¥è¯¢æ€§èƒ½å¹¶é™ä½AIè°ƒç”¨æˆæœ¬ã€‚

## ğŸ¯ æ ¸å¿ƒåŠŸèƒ½

### ç¼“å­˜èƒ½åŠ›
- âœ… **ç²¾ç¡®åŒ¹é…ç¼“å­˜**ï¼šæŸ¥è¯¢å­—ç¬¦ä¸²å®Œå…¨åŒ¹é…çš„é«˜é€Ÿç¼“å­˜
- âœ… **è¯­ä¹‰ç›¸ä¼¼ç¼“å­˜**ï¼šåŸºäºç¼–è¾‘è·ç¦»å’Œè¯­ä¹‰ç›¸ä¼¼åº¦çš„æ™ºèƒ½ç¼“å­˜
- âœ… **åˆ†å±‚ç¼“å­˜æ¶æ„**ï¼šL1å†…å­˜ç¼“å­˜ + L2 Redisç¼“å­˜
- âœ… **åŠ¨æ€TTLç®¡ç†**ï¼šæ ¹æ®æŸ¥è¯¢é¢‘ç‡å’Œè´¨é‡åŠ¨æ€è°ƒæ•´è¿‡æœŸæ—¶é—´

### æ€§èƒ½æŒ‡æ ‡
| ç¼“å­˜ç±»å‹ | å‘½ä¸­ç‡ç›®æ ‡ | å“åº”æ—¶é—´ | æˆæœ¬èŠ‚çœ |
|---------|-----------|---------|----------|
| **ç²¾ç¡®åŒ¹é…** | > 40% | < 1ms | 100% |
| **è¯­ä¹‰ç›¸ä¼¼** | > 35% | < 5ms | 100% |
| **éƒ¨åˆ†ç»“æœ** | > 20% | < 10ms | 60% |

---

## ğŸ—ï¸ ç¼“å­˜ç³»ç»Ÿæ¶æ„

### ğŸ“¦ æ ¸å¿ƒç»„ä»¶è®¾è®¡

```go
// internal/cache/semantic_cache.go
package cache

import (
    "context"
    "crypto/md5"
    "encoding/json"
    "fmt"
    "sort"
    "sync"
    "time"
    
    "github.com/go-redis/redis/v9"
)

type SemanticCache struct {
    // Rediså®¢æˆ·ç«¯
    redisClient    redis.UniversalClient
    
    // å†…å­˜ç¼“å­˜ (L1)
    memoryCache    *MemoryCache
    
    // ç¼“å­˜ç­–ç•¥
    strategy       *CacheStrategy
    
    // ç›¸ä¼¼åº¦è®¡ç®—
    similarityCalculator *SimilarityCalculator
    
    // é…ç½®
    config         *CacheConfig
    
    // ç›‘æ§
    metrics        *CacheMetrics
    
    // å¹¶å‘æ§åˆ¶
    mu             sync.RWMutex
}

type CacheConfig struct {
    // Redisé…ç½®
    Redis struct {
        Addrs        []string      `yaml:"addrs"`          // ["localhost:6379"]
        Password     string        `yaml:"password"`       // ""
        DB           int           `yaml:"db"`             // 0
        PoolSize     int           `yaml:"pool_size"`      // 100
        MinIdleConns int           `yaml:"min_idle_conns"` // 20
    } `yaml:"redis"`
    
    // ç¼“å­˜ç­–ç•¥
    Strategy struct {
        // TTLé…ç½®
        ExactMatchTTL    time.Duration `yaml:"exact_match_ttl"`    // 24h
        SimilarTTL       time.Duration `yaml:"similar_ttl"`        // 12h
        PartialTTL       time.Duration `yaml:"partial_ttl"`        // 6h
        
        // ç›¸ä¼¼åº¦é˜ˆå€¼
        SimilarityThreshold float64 `yaml:"similarity_threshold"` // 0.85
        EditDistanceThreshold int   `yaml:"edit_distance_threshold"` // 5
        
        // ç¼“å­˜å¤§å°
        MaxMemoryCacheSize int `yaml:"max_memory_cache_size"` // 10000
        MaxRedisCacheSize  int `yaml:"max_redis_cache_size"`  // 100000
    } `yaml:"strategy"`
    
    // é¢„çƒ­é…ç½®
    Warmup struct {
        Enabled       bool     `yaml:"enabled"`        // true
        CommonQueries []string `yaml:"common_queries"` // å¸¸ç”¨æŸ¥è¯¢åˆ—è¡¨
        WarmupOnStart bool     `yaml:"warmup_on_start"` // true
    } `yaml:"warmup"`
}

type CacheEntry struct {
    // åŸºç¡€ä¿¡æ¯
    Key           string                 `json:"key"`
    Query         string                 `json:"query"`
    Result        *QueryResult           `json:"result"`
    
    // æ—¶é—´ä¿¡æ¯
    CreatedAt     time.Time              `json:"created_at"`
    LastAccessed  time.Time              `json:"last_accessed"`
    ExpiresAt     time.Time              `json:"expires_at"`
    
    // ç»Ÿè®¡ä¿¡æ¯
    HitCount      int64                  `json:"hit_count"`
    Quality       float64                `json:"quality"`      // ç»“æœè´¨é‡è¯„åˆ†
    
    // å…ƒæ•°æ®
    Metadata      map[string]interface{} `json:"metadata"`
    
    // ç›¸ä¼¼åº¦ä¿¡æ¯
    SimilarQueries []SimilarQuery        `json:"similar_queries,omitempty"`
}

type QueryResult struct {
    SQL           string                 `json:"sql"`
    Explanation   string                 `json:"explanation,omitempty"`
    Tables        []string               `json:"tables"`
    Confidence    float64                `json:"confidence"`
    ModelUsed     string                 `json:"model_used"`
    GeneratedAt   time.Time              `json:"generated_at"`
    TokensUsed    int                    `json:"tokens_used"`
    Cost          float64                `json:"cost"`
}

type SimilarQuery struct {
    Query      string  `json:"query"`
    Similarity float64 `json:"similarity"`
    LastUsed   time.Time `json:"last_used"`
}
```

### ğŸ”§ ç¼“å­˜ç³»ç»Ÿåˆå§‹åŒ–

```go
func NewSemanticCache(config *CacheConfig) (*SemanticCache, error) {
    // åˆ›å»ºRediså®¢æˆ·ç«¯
    rdb := redis.NewUniversalClient(&redis.UniversalOptions{
        Addrs:        config.Redis.Addrs,
        Password:     config.Redis.Password,
        DB:           config.Redis.DB,
        PoolSize:     config.Redis.PoolSize,
        MinIdleConns: config.Redis.MinIdleConns,
    })
    
    // æµ‹è¯•è¿æ¥
    ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
    defer cancel()
    
    if err := rdb.Ping(ctx).Err(); err != nil {
        return nil, fmt.Errorf("Redisè¿æ¥å¤±è´¥: %w", err)
    }
    
    cache := &SemanticCache{
        redisClient:          rdb,
        memoryCache:          NewMemoryCache(config.Strategy.MaxMemoryCacheSize),
        strategy:            NewCacheStrategy(config),
        similarityCalculator: NewSimilarityCalculator(),
        config:              config,
        metrics:             NewCacheMetrics(),
    }
    
    // é¢„çƒ­ç¼“å­˜
    if config.Warmup.Enabled && config.Warmup.WarmupOnStart {
        go cache.warmupCache()
    }
    
    // å¯åŠ¨åå°ä»»åŠ¡
    go cache.startBackgroundTasks()
    
    return cache, nil
}

func (sc *SemanticCache) warmupCache() {
    log.Info("å¼€å§‹ç¼“å­˜é¢„çƒ­...")
    
    for _, query := range sc.config.Warmup.CommonQueries {
        // é¢„çƒ­å¸¸ç”¨æŸ¥è¯¢çš„å‘é‡åŒ–ç»“æœ
        if err := sc.precomputeSimilarity(query); err != nil {
            log.Warn("é¢„çƒ­æŸ¥è¯¢å¤±è´¥", zap.String("query", query), zap.Error(err))
        }
    }
    
    log.Info("ç¼“å­˜é¢„çƒ­å®Œæˆ", zap.Int("queries", len(sc.config.Warmup.CommonQueries)))
}

func (sc *SemanticCache) startBackgroundTasks() {
    // å®šæœŸæ¸…ç†è¿‡æœŸç¼“å­˜
    go sc.startExpirationCleanup()
    
    // å®šæœŸæ”¶é›†æŒ‡æ ‡
    go sc.startMetricsCollection()
    
    // å®šæœŸä¼˜åŒ–ç¼“å­˜
    go sc.startCacheOptimization()
}
```

---

## ğŸ¯ ç²¾ç¡®åŒ¹é…ç¼“å­˜å®ç°

### é«˜é€Ÿç²¾ç¡®åŒ¹é…

```go
// internal/cache/exact_cache.go
package cache

import (
    "context"
    "crypto/md5"
    "fmt"
    "time"
)

func (sc *SemanticCache) GetExact(ctx context.Context, query string) (*QueryResult, error) {
    start := time.Now()
    defer func() {
        sc.metrics.RecordCacheLatency("exact", time.Since(start))
    }()
    
    // 1. ç”Ÿæˆç¼“å­˜é”®
    cacheKey := sc.generateExactCacheKey(query)
    
    // 2. å…ˆæŸ¥L1å†…å­˜ç¼“å­˜
    if entry := sc.memoryCache.Get(cacheKey); entry != nil {
        sc.metrics.RecordCacheHit("exact", "memory")
        sc.updateAccessInfo(entry)
        return entry.Result, nil
    }
    
    // 3. æŸ¥L2 Redisç¼“å­˜
    entry, err := sc.getFromRedis(ctx, cacheKey)
    if err != nil {
        sc.metrics.RecordCacheError("exact", "redis")
        return nil, err
    }
    
    if entry != nil {
        sc.metrics.RecordCacheHit("exact", "redis")
        
        // å›å¡«åˆ°å†…å­˜ç¼“å­˜
        sc.memoryCache.Set(cacheKey, entry)
        sc.updateAccessInfo(entry)
        
        return entry.Result, nil
    }
    
    // 4. ç¼“å­˜æœªå‘½ä¸­
    sc.metrics.RecordCacheMiss("exact")
    return nil, nil
}

func (sc *SemanticCache) SetExact(
    ctx context.Context, 
    query string, 
    result *QueryResult) error {
    
    start := time.Now()
    defer func() {
        sc.metrics.RecordCacheLatency("exact_set", time.Since(start))
    }()
    
    cacheKey := sc.generateExactCacheKey(query)
    
    entry := &CacheEntry{
        Key:       cacheKey,
        Query:     query,
        Result:    result,
        CreatedAt: time.Now(),
        LastAccessed: time.Now(),
        ExpiresAt: time.Now().Add(sc.config.Strategy.ExactMatchTTL),
        HitCount:  0,
        Quality:   sc.calculateResultQuality(result),
        Metadata:  make(map[string]interface{}),
    }
    
    // åŒæ—¶å†™å…¥å†…å­˜å’ŒRedis
    sc.memoryCache.Set(cacheKey, entry)
    
    if err := sc.setToRedis(ctx, cacheKey, entry); err != nil {
        sc.metrics.RecordCacheError("exact_set", "redis")
        return fmt.Errorf("Rediså†™å…¥å¤±è´¥: %w", err)
    }
    
    sc.metrics.RecordCacheSet("exact")
    return nil
}

func (sc *SemanticCache) generateExactCacheKey(query string) string {
    // æ ‡å‡†åŒ–æŸ¥è¯¢å­—ç¬¦ä¸²
    normalized := sc.normalizeQuery(query)
    
    // ç”ŸæˆMD5å“ˆå¸Œ
    hash := md5.Sum([]byte(normalized))
    return fmt.Sprintf("exact:%x", hash)
}

func (sc *SemanticCache) normalizeQuery(query string) string {
    // 1. è½¬æ¢ä¸ºå°å†™
    normalized := strings.ToLower(query)
    
    // 2. å»é™¤å¤šä½™ç©ºæ ¼
    normalized = regexp.MustCompile(`\s+`).ReplaceAllString(normalized, " ")
    
    // 3. å»é™¤é¦–å°¾ç©ºæ ¼
    normalized = strings.TrimSpace(normalized)
    
    // 4. å»é™¤æ ‡ç‚¹ç¬¦å·å·®å¼‚
    normalized = regexp.MustCompile(`[ï¼Œã€‚ï¼ï¼Ÿï¼›ï¼š]/g`).ReplaceAllString(normalized, "")
    
    return normalized
}

func (sc *SemanticCache) calculateResultQuality(result *QueryResult) float64 {
    quality := 0.0
    
    // åŸºäºä¿¡å¿ƒåº¦ (50%)
    quality += result.Confidence * 0.5
    
    // åŸºäºSQLå¤æ‚åº¦ (20%)
    sqlComplexity := sc.analyzeSQLComplexity(result.SQL)
    quality += sqlComplexity * 0.2
    
    // åŸºäºæ¨¡å‹è´¨é‡ (20%)
    modelQuality := sc.getModelQuality(result.ModelUsed)
    quality += modelQuality * 0.2
    
    // åŸºäºå“åº”æ—¶é—´ (10%)
    responseTime := time.Since(result.GeneratedAt).Seconds()
    timeScore := math.Max(0, 1.0-responseTime/10.0) // 10ç§’å†…å“åº”å¾—æ»¡åˆ†
    quality += timeScore * 0.1
    
    return math.Min(quality, 1.0)
}
```

---

## ğŸ§  è¯­ä¹‰ç›¸ä¼¼ç¼“å­˜å®ç°

### æ™ºèƒ½ç›¸ä¼¼åº¦åŒ¹é…

```go
// internal/cache/similarity_cache.go
package cache

import (
    "context"
    "math"
    "sort"
    "strings"
    "time"
)

type SimilarityCalculator struct {
    // ç¼–è¾‘è·ç¦»è®¡ç®—å™¨
    editDistanceCalculator *EditDistanceCalculator
    
    // è¯­ä¹‰ç›¸ä¼¼åº¦è®¡ç®—å™¨
    semanticCalculator     *SemanticSimilarityCalculator
    
    // ç¼“å­˜
    similarityCache        map[string]float64
    mu                     sync.RWMutex
}

type SimilarityResult struct {
    Query           string  `json:"query"`
    CacheKey        string  `json:"cache_key"`
    Similarity      float64 `json:"similarity"`
    EditDistance    int     `json:"edit_distance"`
    SemanticScore   float64 `json:"semantic_score"`
    OverallScore    float64 `json:"overall_score"`
}

func (sc *SemanticCache) GetSimilar(
    ctx context.Context, 
    query string, 
    threshold float64) (*QueryResult, error) {
    
    start := time.Now()
    defer func() {
        sc.metrics.RecordCacheLatency("similar", time.Since(start))
    }()
    
    // 1. æŸ¥æ‰¾ç›¸ä¼¼æŸ¥è¯¢
    similarQueries, err := sc.findSimilarQueries(ctx, query, threshold)
    if err != nil {
        return nil, err
    }
    
    if len(similarQueries) == 0 {
        sc.metrics.RecordCacheMiss("similar")
        return nil, nil
    }
    
    // 2. é€‰æ‹©æœ€ä½³åŒ¹é…
    bestMatch := sc.selectBestMatch(similarQueries)
    
    // 3. è·å–ç¼“å­˜ç»“æœ
    entry, err := sc.getFromRedis(ctx, bestMatch.CacheKey)
    if err != nil {
        return nil, err
    }
    
    if entry == nil {
        sc.metrics.RecordCacheMiss("similar")
        return nil, nil
    }
    
    sc.metrics.RecordCacheHit("similar", "redis")
    
    // 4. æ›´æ–°ç›¸ä¼¼æŸ¥è¯¢ä¿¡æ¯
    sc.updateSimilarQueryInfo(entry, query, bestMatch.Similarity)
    
    return entry.Result, nil
}

func (sc *SemanticCache) findSimilarQueries(
    ctx context.Context, 
    query string, 
    threshold float64) ([]*SimilarityResult, error) {
    
    // 1. è·å–å€™é€‰æŸ¥è¯¢åˆ—è¡¨
    candidates, err := sc.getCandidateQueries(ctx, query)
    if err != nil {
        return nil, err
    }
    
    var results []*SimilarityResult
    
    // 2. è®¡ç®—ç›¸ä¼¼åº¦
    for _, candidate := range candidates {
        similarity := sc.calculateSimilarity(query, candidate.Query)
        
        if similarity >= threshold {
            results = append(results, &SimilarityResult{
                Query:        candidate.Query,
                CacheKey:     candidate.Key,
                Similarity:   similarity,
                OverallScore: similarity,
            })
        }
    }
    
    // 3. æŒ‰ç›¸ä¼¼åº¦æ’åº
    sort.Slice(results, func(i, j int) bool {
        return results[i].OverallScore > results[j].OverallScore
    })
    
    return results, nil
}

func (sc *SemanticCache) calculateSimilarity(query1, query2 string) float64 {
    // 1. æ ‡å‡†åŒ–æŸ¥è¯¢
    norm1 := sc.normalizeQuery(query1)
    norm2 := sc.normalizeQuery(query2)
    
    if norm1 == norm2 {
        return 1.0
    }
    
    // 2. ç¼–è¾‘è·ç¦»ç›¸ä¼¼åº¦ (40%)
    editDistance := sc.calculateEditDistance(norm1, norm2)
    maxLen := math.Max(float64(len(norm1)), float64(len(norm2)))
    editSimilarity := 1.0 - float64(editDistance)/maxLen
    
    // 3. å­—ç¬¦çº§ç›¸ä¼¼åº¦ (30%)
    charSimilarity := sc.calculateCharSimilarity(norm1, norm2)
    
    // 4. è¯çº§ç›¸ä¼¼åº¦ (30%)
    wordSimilarity := sc.calculateWordSimilarity(norm1, norm2)
    
    // åŠ æƒå¹³å‡
    overall := editSimilarity*0.4 + charSimilarity*0.3 + wordSimilarity*0.3
    
    return overall
}

func (sc *SemanticCache) calculateEditDistance(s1, s2 string) int {
    len1, len2 := len(s1), len(s2)
    
    // åˆ›å»ºDPè¡¨
    dp := make([][]int, len1+1)
    for i := range dp {
        dp[i] = make([]int, len2+1)
    }
    
    // åˆå§‹åŒ–
    for i := 0; i <= len1; i++ {
        dp[i][0] = i
    }
    for j := 0; j <= len2; j++ {
        dp[0][j] = j
    }
    
    // åŠ¨æ€è§„åˆ’è®¡ç®—
    for i := 1; i <= len1; i++ {
        for j := 1; j <= len2; j++ {
            if s1[i-1] == s2[j-1] {
                dp[i][j] = dp[i-1][j-1]
            } else {
                dp[i][j] = 1 + min(dp[i-1][j], dp[i][j-1], dp[i-1][j-1])
            }
        }
    }
    
    return dp[len1][len2]
}

func (sc *SemanticCache) calculateCharSimilarity(s1, s2 string) float64 {
    if len(s1) == 0 && len(s2) == 0 {
        return 1.0
    }
    if len(s1) == 0 || len(s2) == 0 {
        return 0.0
    }
    
    // è®¡ç®—å­—ç¬¦äº¤é›†
    chars1 := make(map[rune]int)
    chars2 := make(map[rune]int)
    
    for _, char := range s1 {
        chars1[char]++
    }
    for _, char := range s2 {
        chars2[char]++
    }
    
    // è®¡ç®—äº¤é›†å¤§å°
    intersection := 0
    for char, count1 := range chars1 {
        if count2, exists := chars2[char]; exists {
            intersection += min(count1, count2)
        }
    }
    
    // è®¡ç®—å¹¶é›†å¤§å°
    union := len(s1) + len(s2) - intersection
    
    return float64(intersection) / float64(union)
}

func (sc *SemanticCache) calculateWordSimilarity(s1, s2 string) float64 {
    words1 := strings.Fields(s1)
    words2 := strings.Fields(s2)
    
    if len(words1) == 0 && len(words2) == 0 {
        return 1.0
    }
    if len(words1) == 0 || len(words2) == 0 {
        return 0.0
    }
    
    // è®¡ç®—è¯æ±‡äº¤é›†
    wordSet1 := make(map[string]bool)
    wordSet2 := make(map[string]bool)
    
    for _, word := range words1 {
        wordSet1[word] = true
    }
    for _, word := range words2 {
        wordSet2[word] = true
    }
    
    // è®¡ç®—Jaccardç›¸ä¼¼åº¦
    intersection := 0
    for word := range wordSet1 {
        if wordSet2[word] {
            intersection++
        }
    }
    
    union := len(wordSet1) + len(wordSet2) - intersection
    return float64(intersection) / float64(union)
}

func (sc *SemanticCache) getCandidateQueries(
    ctx context.Context, 
    query string) ([]*CacheEntry, error) {
    
    // 1. åŸºäºæŸ¥è¯¢é•¿åº¦ç­›é€‰å€™é€‰
    queryLen := len(query)
    pattern := fmt.Sprintf("query_len:%d-*", queryLen/10*10) // æŒ‰10å­—ç¬¦åˆ†æ¡¶
    
    keys, err := sc.redisClient.Keys(ctx, pattern).Result()
    if err != nil {
        return nil, err
    }
    
    // 2. é™åˆ¶å€™é€‰æ•°é‡ï¼Œé¿å…è®¡ç®—è¿‡è½½
    maxCandidates := 100
    if len(keys) > maxCandidates {
        keys = keys[:maxCandidates]
    }
    
    var candidates []*CacheEntry
    
    // 3. æ‰¹é‡è·å–å€™é€‰æ¡ç›®
    if len(keys) > 0 {
        results := sc.redisClient.MGet(ctx, keys...)
        values, err := results.Result()
        if err != nil {
            return nil, err
        }
        
        for _, value := range values {
            if value != nil {
                var entry CacheEntry
                if err := json.Unmarshal([]byte(value.(string)), &entry); err == nil {
                    candidates = append(candidates, &entry)
                }
            }
        }
    }
    
    return candidates, nil
}

func (sc *SemanticCache) selectBestMatch(results []*SimilarityResult) *SimilarityResult {
    if len(results) == 0 {
        return nil
    }
    
    // å·²ç»æŒ‰ç›¸ä¼¼åº¦æ’åºï¼Œè¿”å›ç¬¬ä¸€ä¸ªï¼ˆæœ€ä½³ï¼‰
    return results[0]
}

func min(a, b, c int) int {
    if a < b {
        if a < c {
            return a
        }
        return c
    }
    if b < c {
        return b
    }
    return c
}
```

---

## ğŸ“Š åˆ†å±‚ç¼“å­˜ç­–ç•¥

### L1å†…å­˜ç¼“å­˜ + L2 Redisç¼“å­˜

```go
// internal/cache/memory_cache.go
package cache

import (
    "container/list"
    "sync"
    "time"
)

type MemoryCache struct {
    // LRUç¼“å­˜
    capacity int
    cache    map[string]*list.Element
    lruList  *list.List
    
    // å¹¶å‘æ§åˆ¶
    mu       sync.RWMutex
    
    // ç»Ÿè®¡ä¿¡æ¯
    hits     int64
    misses   int64
    sets     int64
}

type memoryCacheItem struct {
    key       string
    entry     *CacheEntry
    createdAt time.Time
    lastAccess time.Time
}

func NewMemoryCache(capacity int) *MemoryCache {
    return &MemoryCache{
        capacity: capacity,
        cache:    make(map[string]*list.Element),
        lruList:  list.New(),
    }
}

func (mc *MemoryCache) Get(key string) *CacheEntry {
    mc.mu.Lock()
    defer mc.mu.Unlock()
    
    if element, exists := mc.cache[key]; exists {
        // æ£€æŸ¥è¿‡æœŸ
        item := element.Value.(*memoryCacheItem)
        if time.Now().After(item.entry.ExpiresAt) {
            mc.removeElement(element)
            mc.misses++
            return nil
        }
        
        // ç§»åŠ¨åˆ°é“¾è¡¨å¤´éƒ¨ (LRU)
        mc.lruList.MoveToFront(element)
        item.lastAccess = time.Now()
        
        mc.hits++
        return item.entry
    }
    
    mc.misses++
    return nil
}

func (mc *MemoryCache) Set(key string, entry *CacheEntry) {
    mc.mu.Lock()
    defer mc.mu.Unlock()
    
    now := time.Now()
    
    // å¦‚æœkeyå·²å­˜åœ¨ï¼Œæ›´æ–°å€¼
    if element, exists := mc.cache[key]; exists {
        item := element.Value.(*memoryCacheItem)
        item.entry = entry
        item.lastAccess = now
        mc.lruList.MoveToFront(element)
        mc.sets++
        return
    }
    
    // æ£€æŸ¥å®¹é‡ï¼Œå¦‚æœ‰å¿…è¦ç§»é™¤æœ€ä¹…æœªä½¿ç”¨çš„é¡¹
    if mc.lruList.Len() >= mc.capacity {
        mc.removeOldest()
    }
    
    // æ·»åŠ æ–°é¡¹
    item := &memoryCacheItem{
        key:        key,
        entry:      entry,
        createdAt:  now,
        lastAccess: now,
    }
    
    element := mc.lruList.PushFront(item)
    mc.cache[key] = element
    mc.sets++
}

func (mc *MemoryCache) Delete(key string) bool {
    mc.mu.Lock()
    defer mc.mu.Unlock()
    
    if element, exists := mc.cache[key]; exists {
        mc.removeElement(element)
        return true
    }
    
    return false
}

func (mc *MemoryCache) removeOldest() {
    element := mc.lruList.Back()
    if element != nil {
        mc.removeElement(element)
    }
}

func (mc *MemoryCache) removeElement(element *list.Element) {
    item := element.Value.(*memoryCacheItem)
    delete(mc.cache, item.key)
    mc.lruList.Remove(element)
}

func (mc *MemoryCache) Stats() map[string]interface{} {
    mc.mu.RLock()
    defer mc.mu.RUnlock()
    
    total := mc.hits + mc.misses
    hitRate := 0.0
    if total > 0 {
        hitRate = float64(mc.hits) / float64(total)
    }
    
    return map[string]interface{}{
        "capacity":   mc.capacity,
        "size":      mc.lruList.Len(),
        "hits":      mc.hits,
        "misses":    mc.misses,
        "sets":      mc.sets,
        "hit_rate":  hitRate,
    }
}

func (mc *MemoryCache) Clear() {
    mc.mu.Lock()
    defer mc.mu.Unlock()
    
    mc.cache = make(map[string]*list.Element)
    mc.lruList = list.New()
    mc.hits = 0
    mc.misses = 0
    mc.sets = 0
}
```

### Redisç¼“å­˜æ“ä½œ

```go
// internal/cache/redis_operations.go
package cache

import (
    "context"
    "encoding/json"
    "time"
)

func (sc *SemanticCache) getFromRedis(ctx context.Context, key string) (*CacheEntry, error) {
    result := sc.redisClient.Get(ctx, key)
    if result.Err() == redis.Nil {
        return nil, nil // ç¼“å­˜æœªå‘½ä¸­
    }
    if result.Err() != nil {
        return nil, result.Err()
    }
    
    var entry CacheEntry
    if err := json.Unmarshal([]byte(result.Val()), &entry); err != nil {
        return nil, err
    }
    
    // æ£€æŸ¥è¿‡æœŸæ—¶é—´
    if time.Now().After(entry.ExpiresAt) {
        // å¼‚æ­¥åˆ é™¤è¿‡æœŸæ¡ç›®
        go sc.redisClient.Del(context.Background(), key)
        return nil, nil
    }
    
    return &entry, nil
}

func (sc *SemanticCache) setToRedis(ctx context.Context, key string, entry *CacheEntry) error {
    data, err := json.Marshal(entry)
    if err != nil {
        return err
    }
    
    // è®¡ç®—TTL
    ttl := time.Until(entry.ExpiresAt)
    if ttl <= 0 {
        return nil // å·²è¿‡æœŸï¼Œä¸å­˜å‚¨
    }
    
    return sc.redisClient.Set(ctx, key, data, ttl).Err()
}

func (sc *SemanticCache) existsInRedis(ctx context.Context, key string) (bool, error) {
    result := sc.redisClient.Exists(ctx, key)
    if result.Err() != nil {
        return false, result.Err()
    }
    
    return result.Val() > 0, nil
}

func (sc *SemanticCache) deleteFromRedis(ctx context.Context, key string) error {
    return sc.redisClient.Del(ctx, key).Err()
}

func (sc *SemanticCache) getAllKeysFromRedis(ctx context.Context, pattern string) ([]string, error) {
    return sc.redisClient.Keys(ctx, pattern).Result()
}

// æ‰¹é‡æ“ä½œ
func (sc *SemanticCache) batchGetFromRedis(ctx context.Context, keys []string) (map[string]*CacheEntry, error) {
    if len(keys) == 0 {
        return make(map[string]*CacheEntry), nil
    }
    
    results := sc.redisClient.MGet(ctx, keys...)
    values, err := results.Result()
    if err != nil {
        return nil, err
    }
    
    entries := make(map[string]*CacheEntry)
    
    for i, value := range values {
        if value != nil {
            var entry CacheEntry
            if err := json.Unmarshal([]byte(value.(string)), &entry); err == nil {
                // æ£€æŸ¥è¿‡æœŸ
                if time.Now().Before(entry.ExpiresAt) {
                    entries[keys[i]] = &entry
                }
            }
        }
    }
    
    return entries, nil
}

func (sc *SemanticCache) batchSetToRedis(ctx context.Context, entries map[string]*CacheEntry) error {
    if len(entries) == 0 {
        return nil
    }
    
    pipe := sc.redisClient.Pipeline()
    
    for key, entry := range entries {
        data, err := json.Marshal(entry)
        if err != nil {
            continue
        }
        
        ttl := time.Until(entry.ExpiresAt)
        if ttl > 0 {
            pipe.Set(ctx, key, data, ttl)
        }
    }
    
    _, err := pipe.Exec(ctx)
    return err
}
```

---

## ğŸ• åŠ¨æ€TTLç®¡ç†

### æ™ºèƒ½è¿‡æœŸæ—¶é—´è°ƒæ•´

```go
// internal/cache/ttl_manager.go
package cache

import (
    "context"
    "math"
    "time"
)

type TTLManager struct {
    baseConfig     *CacheConfig
    metrics        *CacheMetrics
    
    // TTLç­–ç•¥
    strategy       *TTLStrategy
}

type TTLStrategy struct {
    // åŸºç¡€TTL
    BaseTTLs map[string]time.Duration
    
    // è°ƒæ•´å› å­
    QualityFactor    float64 // è´¨é‡å› å­
    AccessFactor     float64 // è®¿é—®é¢‘ç‡å› å­
    SuccessFactor    float64 // æˆåŠŸç‡å› å­
    
    // é™åˆ¶
    MinTTL          time.Duration
    MaxTTL          time.Duration
}

func NewTTLManager(config *CacheConfig) *TTLManager {
    return &TTLManager{
        baseConfig: config,
        strategy: &TTLStrategy{
            BaseTTLs: map[string]time.Duration{
                "exact":   config.Strategy.ExactMatchTTL,
                "similar": config.Strategy.SimilarTTL,
                "partial": config.Strategy.PartialTTL,
            },
            QualityFactor:  1.5,
            AccessFactor:   2.0,
            SuccessFactor:  1.2,
            MinTTL:        1 * time.Hour,
            MaxTTL:        7 * 24 * time.Hour,
        },
    }
}

func (tm *TTLManager) CalculateOptimalTTL(
    cacheType string,
    entry *CacheEntry,
    stats *CacheStats) time.Duration {
    
    // è·å–åŸºç¡€TTL
    baseTTL, exists := tm.strategy.BaseTTLs[cacheType]
    if !exists {
        baseTTL = 12 * time.Hour
    }
    
    // è®¡ç®—è°ƒæ•´å› å­
    adjustmentFactor := 1.0
    
    // 1. è´¨é‡å› å­è°ƒæ•´
    if entry.Quality > 0.8 {
        adjustmentFactor *= tm.strategy.QualityFactor
    } else if entry.Quality < 0.5 {
        adjustmentFactor *= 0.7
    }
    
    // 2. è®¿é—®é¢‘ç‡è°ƒæ•´
    if stats != nil {
        accessRate := float64(entry.HitCount) / math.Max(1, time.Since(entry.CreatedAt).Hours())
        if accessRate > 1 { // æ¯å°æ—¶è®¿é—®è¶…è¿‡1æ¬¡
            adjustmentFactor *= tm.strategy.AccessFactor
        } else if accessRate < 0.1 { // æ¯å°æ—¶è®¿é—®å°‘äº0.1æ¬¡
            adjustmentFactor *= 0.5
        }
    }
    
    // 3. æ¨¡å‹æˆåŠŸç‡è°ƒæ•´
    if entry.Result != nil && entry.Result.Confidence > 0.9 {
        adjustmentFactor *= tm.strategy.SuccessFactor
    }
    
    // 4. æ—¶é—´è¡°å‡å› å­
    age := time.Since(entry.CreatedAt)
    if age > 24*time.Hour {
        decayFactor := math.Exp(-age.Hours() / (24 * 7)) // ä¸€å‘¨è¡°å‡
        adjustmentFactor *= decayFactor
    }
    
    // è®¡ç®—æœ€ç»ˆTTL
    finalTTL := time.Duration(float64(baseTTL) * adjustmentFactor)
    
    // åº”ç”¨é™åˆ¶
    if finalTTL < tm.strategy.MinTTL {
        finalTTL = tm.strategy.MinTTL
    }
    if finalTTL > tm.strategy.MaxTTL {
        finalTTL = tm.strategy.MaxTTL
    }
    
    return finalTTL
}

func (tm *TTLManager) UpdateTTL(ctx context.Context, key string, newTTL time.Duration) error {
    // å®ç°TTLæ›´æ–°é€»è¾‘
    return nil
}

// æ‰¹é‡TTLä¼˜åŒ–
func (sc *SemanticCache) optimizeTTLs(ctx context.Context) error {
    // è·å–éœ€è¦ä¼˜åŒ–çš„ç¼“å­˜æ¡ç›®
    keys, err := sc.redisClient.Keys(ctx, "*").Result()
    if err != nil {
        return err
    }
    
    // æ‰¹é‡è·å–æ¡ç›®
    entries, err := sc.batchGetFromRedis(ctx, keys)
    if err != nil {
        return err
    }
    
    // ä¸ºæ¯ä¸ªæ¡ç›®è®¡ç®—æ–°TTL
    updates := make(map[string]time.Duration)
    
    for key, entry := range entries {
        // åˆ¤æ–­ç¼“å­˜ç±»å‹
        cacheType := "exact"
        if strings.Contains(key, "similar:") {
            cacheType = "similar"
        } else if strings.Contains(key, "partial:") {
            cacheType = "partial"
        }
        
        // è®¡ç®—æ–°TTL
        newTTL := sc.ttlManager.CalculateOptimalTTL(cacheType, entry, nil)
        
        // å¦‚æœTTLå˜åŒ–æ˜¾è‘—ï¼Œè®°å½•æ›´æ–°
        currentRemainingTTL := time.Until(entry.ExpiresAt)
        if math.Abs(newTTL.Seconds()-currentRemainingTTL.Seconds()) > 3600 { // å·®å¼‚è¶…è¿‡1å°æ—¶
            updates[key] = newTTL
        }
    }
    
    // æ‰¹é‡æ›´æ–°TTL
    if len(updates) > 0 {
        pipe := sc.redisClient.Pipeline()
        for key, ttl := range updates {
            pipe.Expire(ctx, key, ttl)
        }
        _, err = pipe.Exec(ctx)
    }
    
    return err
}
```

---

## ğŸ“Š ç¼“å­˜æ€§èƒ½ç›‘æ§

### è¯¦ç»†æŒ‡æ ‡æ”¶é›†

```go
// internal/cache/metrics.go
package cache

import (
    "sync"
    "time"
    
    "github.com/prometheus/client_golang/prometheus"
    "github.com/prometheus/client_golang/prometheus/promauto"
)

type CacheMetrics struct {
    // ç¼“å­˜å‘½ä¸­ç‡
    CacheHits    *prometheus.CounterVec
    CacheMisses  *prometheus.CounterVec
    CacheSets    *prometheus.CounterVec
    
    // ç¼“å­˜å»¶è¿Ÿ
    CacheLatency *prometheus.HistogramVec
    
    // ç¼“å­˜å¤§å°
    CacheSize    *prometheus.GaugeVec
    CacheMemory  *prometheus.GaugeVec
    
    // è¿‡æœŸå’Œæ¸…ç†
    CacheEvictions *prometheus.CounterVec
    CacheExpired   *prometheus.CounterVec
    
    // ç›¸ä¼¼åº¦åˆ†æ
    SimilarityScores *prometheus.HistogramVec
    SimilarityTime   *prometheus.HistogramVec
    
    // é”™è¯¯ç›‘æ§
    CacheErrors  *prometheus.CounterVec
    
    // æœ¬åœ°ç»Ÿè®¡
    localStats   map[string]*LocalCacheStats
    mu           sync.RWMutex
}

type LocalCacheStats struct {
    HitCount      int64     `json:"hit_count"`
    MissCount     int64     `json:"miss_count"`
    SetCount      int64     `json:"set_count"`
    ErrorCount    int64     `json:"error_count"`
    TotalLatency  time.Duration `json:"total_latency"`
    LastUpdated   time.Time     `json:"last_updated"`
}

func NewCacheMetrics() *CacheMetrics {
    return &CacheMetrics{
        CacheHits: promauto.NewCounterVec(prometheus.CounterOpts{
            Name: "chat2sql_cache_hits_total",
            Help: "ç¼“å­˜å‘½ä¸­æ€»æ•°",
        }, []string{"type", "layer"}),
        
        CacheMisses: promauto.NewCounterVec(prometheus.CounterOpts{
            Name: "chat2sql_cache_misses_total",
            Help: "ç¼“å­˜æœªå‘½ä¸­æ€»æ•°",
        }, []string{"type"}),
        
        CacheSets: promauto.NewCounterVec(prometheus.CounterOpts{
            Name: "chat2sql_cache_sets_total",
            Help: "ç¼“å­˜å†™å…¥æ€»æ•°",
        }, []string{"type"}),
        
        CacheLatency: promauto.NewHistogramVec(prometheus.HistogramOpts{
            Name: "chat2sql_cache_latency_seconds",
            Help: "ç¼“å­˜æ“ä½œå»¶è¿Ÿåˆ†å¸ƒ",
            Buckets: []float64{0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0},
        }, []string{"operation", "type"}),
        
        CacheSize: promauto.NewGaugeVec(prometheus.GaugeOpts{
            Name: "chat2sql_cache_size_entries",
            Help: "ç¼“å­˜æ¡ç›®æ•°é‡",
        }, []string{"type", "layer"}),
        
        CacheMemory: promauto.NewGaugeVec(prometheus.GaugeOpts{
            Name: "chat2sql_cache_memory_bytes",
            Help: "ç¼“å­˜å†…å­˜ä½¿ç”¨é‡",
        }, []string{"type"}),
        
        SimilarityScores: promauto.NewHistogramVec(prometheus.HistogramOpts{
            Name: "chat2sql_similarity_scores",
            Help: "ç›¸ä¼¼åº¦åˆ†æ•°åˆ†å¸ƒ",
            Buckets: []float64{0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0},
        }, []string{"algorithm"}),
        
        CacheErrors: promauto.NewCounterVec(prometheus.CounterOpts{
            Name: "chat2sql_cache_errors_total",
            Help: "ç¼“å­˜é”™è¯¯æ€»æ•°",
        }, []string{"type", "operation"}),
        
        localStats: make(map[string]*LocalCacheStats),
    }
}

func (cm *CacheMetrics) RecordCacheHit(cacheType, layer string) {
    cm.CacheHits.WithLabelValues(cacheType, layer).Inc()
    cm.updateLocalStats(cacheType, "hit", 0)
}

func (cm *CacheMetrics) RecordCacheMiss(cacheType string) {
    cm.CacheMisses.WithLabelValues(cacheType).Inc()
    cm.updateLocalStats(cacheType, "miss", 0)
}

func (cm *CacheMetrics) RecordCacheSet(cacheType string) {
    cm.CacheSets.WithLabelValues(cacheType).Inc()
    cm.updateLocalStats(cacheType, "set", 0)
}

func (cm *CacheMetrics) RecordCacheLatency(operation string, latency time.Duration) {
    cm.CacheLatency.WithLabelValues(operation, "").Observe(latency.Seconds())
}

func (cm *CacheMetrics) RecordCacheError(cacheType, operation string) {
    cm.CacheErrors.WithLabelValues(cacheType, operation).Inc()
    cm.updateLocalStats(cacheType, "error", 0)
}

func (cm *CacheMetrics) RecordSimilarityScore(algorithm string, score float64) {
    cm.SimilarityScores.WithLabelValues(algorithm).Observe(score)
}

func (cm *CacheMetrics) updateLocalStats(cacheType, operation string, latency time.Duration) {
    cm.mu.Lock()
    defer cm.mu.Unlock()
    
    key := fmt.Sprintf("%s_%s", cacheType, operation)
    stats, exists := cm.localStats[key]
    if !exists {
        stats = &LocalCacheStats{}
        cm.localStats[key] = stats
    }
    
    switch operation {
    case "hit":
        stats.HitCount++
    case "miss":
        stats.MissCount++
    case "set":
        stats.SetCount++
    case "error":
        stats.ErrorCount++
    }
    
    stats.TotalLatency += latency
    stats.LastUpdated = time.Now()
}

func (cm *CacheMetrics) GetCacheStats() map[string]*LocalCacheStats {
    cm.mu.RLock()
    defer cm.mu.RUnlock()
    
    result := make(map[string]*LocalCacheStats)
    for key, stats := range cm.localStats {
        result[key] = &LocalCacheStats{
            HitCount:     stats.HitCount,
            MissCount:    stats.MissCount,
            SetCount:     stats.SetCount,
            ErrorCount:   stats.ErrorCount,
            TotalLatency: stats.TotalLatency,
            LastUpdated:  stats.LastUpdated,
        }
    }
    
    return result
}

func (cm *CacheMetrics) CalculateHitRate(cacheType string) float64 {
    cm.mu.RLock()
    defer cm.mu.RUnlock()
    
    hitKey := fmt.Sprintf("%s_hit", cacheType)
    missKey := fmt.Sprintf("%s_miss", cacheType)
    
    hitStats := cm.localStats[hitKey]
    missStats := cm.localStats[missKey]
    
    hits := int64(0)
    misses := int64(0)
    
    if hitStats != nil {
        hits = hitStats.HitCount
    }
    if missStats != nil {
        misses = missStats.MissCount
    }
    
    total := hits + misses
    if total == 0 {
        return 0.0
    }
    
    return float64(hits) / float64(total)
}
```

---

## ğŸ› ï¸ é…ç½®å’Œéƒ¨ç½²

### ç¼“å­˜é…ç½®ç¤ºä¾‹

```yaml
# config/cache_config.yaml
cache:
  # Redisé…ç½®
  redis:
    addrs: ["localhost:6379"]
    password: ""
    db: 0
    pool_size: 100
    min_idle_conns: 20
    dial_timeout: "5s"
    read_timeout: "3s"
    write_timeout: "3s"
    
  # ç¼“å­˜ç­–ç•¥
  strategy:
    # TTLé…ç½®
    exact_match_ttl: "24h"
    similar_ttl: "12h"
    partial_ttl: "6h"
    
    # ç›¸ä¼¼åº¦é˜ˆå€¼
    similarity_threshold: 0.85
    edit_distance_threshold: 5
    
    # ç¼“å­˜å¤§å°é™åˆ¶
    max_memory_cache_size: 10000
    max_redis_cache_size: 100000
    
    # æ¸…ç†ç­–ç•¥
    cleanup_interval: "1h"
    max_idle_time: "24h"
    
  # é¢„çƒ­é…ç½®
  warmup:
    enabled: true
    warmup_on_start: true
    common_queries:
      - "æŸ¥è¯¢ç”¨æˆ·ä¿¡æ¯"
      - "è·å–è®¢å•åˆ—è¡¨"
      - "ç»Ÿè®¡é”€å”®æ•°æ®"
      - "åˆ†æç”¨æˆ·è¡Œä¸º"
      - "ç”ŸæˆæŠ¥è¡¨"
      
  # ç›‘æ§é…ç½®
  monitoring:
    metrics_interval: "30s"
    detailed_logging: true
    slow_query_threshold: "100ms"
```

### Dockeréƒ¨ç½²è„šæœ¬

```bash
#!/bin/bash
# deploy/deploy_cache.sh

set -e

echo "ğŸ”´ éƒ¨ç½²Redisç¼“å­˜ç³»ç»Ÿ..."

# 1. åˆ›å»ºRedisé›†ç¾¤
echo "ğŸ“¦ å¯åŠ¨Redisé›†ç¾¤..."
docker network create chat2sql-net 2>/dev/null || true

# ä¸»Rediså®ä¾‹
docker run -d --name chat2sql-redis-master \
  --network chat2sql-net \
  -p 6379:6379 \
  -v redis-master-data:/data \
  -e REDIS_PASSWORD=${REDIS_PASSWORD:-} \
  redis:7.4-alpine \
  redis-server --appendonly yes --maxmemory 2gb --maxmemory-policy allkeys-lru

# Redis Sentinel (é«˜å¯ç”¨)
docker run -d --name chat2sql-redis-sentinel \
  --network chat2sql-net \
  -p 26379:26379 \
  -v redis-sentinel-conf:/etc/redis \
  redis:7.4-alpine \
  redis-sentinel /etc/redis/sentinel.conf

# 2. éƒ¨ç½²ç¼“å­˜æœåŠ¡é…ç½®
echo "âš™ï¸ éƒ¨ç½²ç¼“å­˜é…ç½®..."
cp config/cache_config.yaml /etc/chat2sql/

# 3. å¯åŠ¨ç¼“å­˜é¢„çƒ­
echo "ğŸ”¥ å¼€å§‹ç¼“å­˜é¢„çƒ­..."
go run tools/cache_warmup.go \
  --config=/etc/chat2sql/cache_config.yaml \
  --redis-addr=localhost:6379

echo "âœ… ç¼“å­˜ç³»ç»Ÿéƒ¨ç½²å®Œæˆï¼"
echo "ğŸ”´ Redis: localhost:6379"
echo "ğŸ“Š ç¼“å­˜ç›‘æ§: http://localhost:9090/metrics"
```

---

<div align="center">

**ğŸ”´ è¯­ä¹‰ç¼“å­˜æˆåŠŸå…³é”®ï¼šç²¾ç¡®åŒ¹é… + æ™ºèƒ½ç›¸ä¼¼ + åŠ¨æ€ä¼˜åŒ–**

</div>