# âš¡ å‘é‡ç¼“å­˜ä¸æ€§èƒ½ä¼˜åŒ–æŒ‡å—

<div align="center">

![Vector Cache](https://img.shields.io/badge/Vector_Cache-Performance-blue.svg)
![Optimization](https://img.shields.io/badge/Optimization-Multi_Layer-green.svg)
![Latency](https://img.shields.io/badge/Latency-<10ms-orange.svg)

**Chat2SQL P3é˜¶æ®µ - å‘é‡ç¼“å­˜ç³»ç»Ÿä¸æ€§èƒ½ä¼˜åŒ–å®Œæ•´æ–¹æ¡ˆ**

</div>

## ğŸ“‹ æ¦‚è¿°

æœ¬æ–‡æ¡£ä¸“é—¨é’ˆå¯¹Chat2SQLç³»ç»Ÿä¸­å‘é‡ç¼“å­˜çš„è®¾è®¡å®ç°ã€æ€§èƒ½ä¼˜åŒ–ç­–ç•¥å’Œç³»ç»Ÿè°ƒä¼˜æ–¹æ¡ˆï¼Œæä¾›ä»å†…å­˜åˆ°åˆ†å¸ƒå¼çš„å®Œæ•´ç¼“å­˜è§£å†³æ–¹æ¡ˆã€‚

## ğŸ¯ æ€§èƒ½ç›®æ ‡

### æ ¸å¿ƒæŒ‡æ ‡
- âœ… **ç¼“å­˜å‘½ä¸­ç‡**ï¼šEmbeddingç¼“å­˜ > 85%ï¼Œæœç´¢ç¼“å­˜ > 70%
- âœ… **å“åº”å»¶è¿Ÿ**ï¼šç¼“å­˜æŸ¥æ‰¾ < 1msï¼Œå‘é‡è®¡ç®— < 10ms
- âœ… **å†…å­˜æ•ˆç‡**ï¼šç¼“å­˜ç©ºé—´åˆ©ç”¨ç‡ > 80%
- âœ… **ååé‡**ï¼šæ”¯æŒ > 1000 QPS

### ä¼˜åŒ–å±‚çº§
| ç¼“å­˜å±‚çº§ | å“åº”æ—¶é—´ | å‘½ä¸­ç‡ | å®¹é‡ | é€‚ç”¨åœºæ™¯ |
|---------|---------|--------|------|----------|
| **L1 - å†…å­˜ç¼“å­˜** | < 1ms | > 90% | 1GB | çƒ­ç‚¹æ•°æ® |
| **L2 - Redisç¼“å­˜** | < 5ms | > 80% | 10GB | æ¸©æ•°æ® |
| **L3 - æŒä¹…åŒ–ç¼“å­˜** | < 50ms | > 60% | 100GB | å†·æ•°æ® |

---

## ğŸ—ï¸ å¤šå±‚ç¼“å­˜æ¶æ„

### ğŸ“¦ ç¼“å­˜ç³»ç»Ÿæ¶æ„

```go
// internal/cache/vector_cache.go
package cache

import (
    "context"
    "sync"
    "time"
    "crypto/md5"
    "encoding/hex"
    "encoding/json"
)

type VectorCacheSystem struct {
    // å¤šå±‚ç¼“å­˜
    l1Cache     *MemoryCache      // L1: å†…å­˜ç¼“å­˜
    l2Cache     *RedisCache       // L2: Redisç¼“å­˜  
    l3Cache     *PersistentCache  // L3: æŒä¹…åŒ–ç¼“å­˜
    
    // é…ç½®å’Œç›‘æ§
    config      *CacheConfig
    metrics     *CacheMetrics
    
    // ç¼“å­˜ç­–ç•¥
    strategy    *CacheStrategy
    eviction    *EvictionManager
    
    // å¹¶å‘æ§åˆ¶
    mu          sync.RWMutex
    loadGroups  sync.Map  // é˜²æ­¢ç¼“å­˜å‡»ç©¿
}

type CacheConfig struct {
    // L1å†…å­˜ç¼“å­˜é…ç½®
    L1 struct {
        MaxSize     int           `yaml:"max_size"`      // 10000
        TTL         time.Duration `yaml:"ttl"`           // 1h
        EvictPolicy string        `yaml:"evict_policy"`  // "lru"
    } `yaml:"l1"`
    
    // L2 Redisç¼“å­˜é…ç½®
    L2 struct {
        Endpoints   []string      `yaml:"endpoints"`
        Password    string        `yaml:"password"`
        Database    int           `yaml:"database"`
        MaxRetries  int           `yaml:"max_retries"`   // 3
        TTL         time.Duration `yaml:"ttl"`           // 6h
        PoolSize    int           `yaml:"pool_size"`     // 100
    } `yaml:"l2"`
    
    // L3æŒä¹…åŒ–ç¼“å­˜é…ç½®
    L3 struct {
        StoragePath string        `yaml:"storage_path"`  // "/data/cache"
        MaxSize     int64         `yaml:"max_size"`      // 100GB
        TTL         time.Duration `yaml:"ttl"`           // 24h
        Compression bool          `yaml:"compression"`   // true
    } `yaml:"l3"`
    
    // é¢„çƒ­é…ç½®
    Warmup struct {
        Enabled     bool     `yaml:"enabled"`      // true
        CommonQueries []string `yaml:"common_queries"`
        WarmupRatio float64  `yaml:"warmup_ratio"` // 0.1
    } `yaml:"warmup"`
}

type CacheEntry struct {
    Key         string      `json:"key"`
    Value       interface{} `json:"value"`
    CreatedAt   time.Time   `json:"created_at"`
    AccessedAt  time.Time   `json:"accessed_at"`
    AccessCount int         `json:"access_count"`
    TTL         time.Duration `json:"ttl"`
    Size        int         `json:"size"`
    Level       int         `json:"level"` // 1, 2, 3
}
```

### ğŸ”§ ç¼“å­˜ç³»ç»Ÿåˆå§‹åŒ–

```go
func NewVectorCacheSystem(config *CacheConfig) (*VectorCacheSystem, error) {
    // åˆå§‹åŒ–L1å†…å­˜ç¼“å­˜
    l1Cache, err := NewMemoryCache(&MemoryCacheConfig{
        MaxSize:     config.L1.MaxSize,
        TTL:         config.L1.TTL,
        EvictPolicy: config.L1.EvictPolicy,
    })
    if err != nil {
        return nil, fmt.Errorf("L1ç¼“å­˜åˆå§‹åŒ–å¤±è´¥: %w", err)
    }
    
    // åˆå§‹åŒ–L2 Redisç¼“å­˜
    l2Cache, err := NewRedisCache(&RedisCacheConfig{
        Endpoints:  config.L2.Endpoints,
        Password:   config.L2.Password,
        Database:   config.L2.Database,
        MaxRetries: config.L2.MaxRetries,
        PoolSize:   config.L2.PoolSize,
        TTL:        config.L2.TTL,
    })
    if err != nil {
        return nil, fmt.Errorf("L2ç¼“å­˜åˆå§‹åŒ–å¤±è´¥: %w", err)
    }
    
    // åˆå§‹åŒ–L3æŒä¹…åŒ–ç¼“å­˜
    l3Cache, err := NewPersistentCache(&PersistentCacheConfig{
        StoragePath: config.L3.StoragePath,
        MaxSize:     config.L3.MaxSize,
        TTL:         config.L3.TTL,
        Compression: config.L3.Compression,
    })
    if err != nil {
        return nil, fmt.Errorf("L3ç¼“å­˜åˆå§‹åŒ–å¤±è´¥: %w", err)
    }
    
    system := &VectorCacheSystem{
        l1Cache:  l1Cache,
        l2Cache:  l2Cache,
        l3Cache:  l3Cache,
        config:   config,
        metrics:  NewCacheMetrics(),
        strategy: NewCacheStrategy(config),
        eviction: NewEvictionManager(),
    }
    
    // å¯åŠ¨ç¼“å­˜é¢„çƒ­
    if config.Warmup.Enabled {
        go system.startWarmup()
    }
    
    // å¯åŠ¨åå°ç»´æŠ¤ä»»åŠ¡
    go system.startMaintenance()
    
    return system, nil
}

func (vcs *VectorCacheSystem) startWarmup() {
    log.Info("å¼€å§‹ç¼“å­˜é¢„çƒ­...")
    
    for _, query := range vcs.config.Warmup.CommonQueries {
        // é¢„çƒ­Embeddingç¼“å­˜
        key := vcs.generateEmbeddingKey(query)
        if _, exists := vcs.get(key); !exists {
            // è§¦å‘embeddingè®¡ç®—å’Œç¼“å­˜
            go vcs.precomputeEmbedding(query)
        }
    }
    
    log.Info("ç¼“å­˜é¢„çƒ­å®Œæˆ")
}

func (vcs *VectorCacheSystem) startMaintenance() {
    ticker := time.NewTicker(5 * time.Minute)
    defer ticker.Stop()
    
    for {
        select {
        case <-ticker.C:
            vcs.performMaintenance()
        }
    }
}

func (vcs *VectorCacheSystem) performMaintenance() {
    // æ¸…ç†è¿‡æœŸç¼“å­˜
    vcs.cleanupExpiredEntries()
    
    // æ›´æ–°ç¼“å­˜ç»Ÿè®¡
    vcs.updateCacheStatistics()
    
    // ä¼˜åŒ–ç¼“å­˜åˆ†å¸ƒ
    vcs.optimizeCacheDistribution()
    
    // ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
    vcs.generatePerformanceReport()
}
```

---

## ğŸ’¾ Embeddingå‘é‡ç¼“å­˜

### ğŸ”‘ æ™ºèƒ½é”®å€¼ç®¡ç†

```go
// internal/cache/embedding_cache.go
type EmbeddingCache struct {
    cacheSystem *VectorCacheSystem
    hasher      *ConsistentHasher
    compressor  *VectorCompressor
}

func NewEmbeddingCache(cacheSystem *VectorCacheSystem) *EmbeddingCache {
    return &EmbeddingCache{
        cacheSystem: cacheSystem,
        hasher:      NewConsistentHasher(),
        compressor:  NewVectorCompressor(),
    }
}

func (ec *EmbeddingCache) GetEmbedding(ctx context.Context, text string) ([]float32, bool) {
    key := ec.generateKey(text)
    
    start := time.Now()
    defer func() {
        ec.cacheSystem.metrics.RecordLatency("get", time.Since(start))
    }()
    
    // å°è¯•ä»ç¼“å­˜è·å–
    if cached, exists := ec.cacheSystem.get(key); exists {
        if embedding, ok := ec.deserializeEmbedding(cached); ok {
            ec.cacheSystem.metrics.RecordHit("embedding")
            return embedding, true
        }
    }
    
    ec.cacheSystem.metrics.RecordMiss("embedding")
    return nil, false
}

func (ec *EmbeddingCache) SetEmbedding(
    ctx context.Context, 
    text string, 
    embedding []float32,
    ttl time.Duration) error {
    
    key := ec.generateKey(text)
    
    // å‹ç¼©å‘é‡ä»¥èŠ‚çœç©ºé—´
    compressed, err := ec.compressor.Compress(embedding)
    if err != nil {
        return fmt.Errorf("å‘é‡å‹ç¼©å¤±è´¥: %w", err)
    }
    
    // åºåˆ—åŒ–ç¼“å­˜æ¡ç›®
    entry := &EmbeddingCacheEntry{
        Text:        text,
        Embedding:   compressed,
        CreatedAt:   time.Now(),
        TTL:         ttl,
        OriginalSize: len(embedding) * 4, // float32 = 4 bytes
        CompressedSize: len(compressed),
    }
    
    serialized, err := json.Marshal(entry)
    if err != nil {
        return fmt.Errorf("åºåˆ—åŒ–å¤±è´¥: %w", err)
    }
    
    // å­˜å‚¨åˆ°ç¼“å­˜ç³»ç»Ÿ
    return ec.cacheSystem.set(key, serialized, ttl)
}

func (ec *EmbeddingCache) generateKey(text string) string {
    // ä½¿ç”¨MD5ç”Ÿæˆä¸€è‡´çš„é”®
    hasher := md5.New()
    hasher.Write([]byte(text))
    hash := hex.EncodeToString(hasher.Sum(nil))
    
    return fmt.Sprintf("embedding:%s", hash)
}

func (ec *EmbeddingCache) BatchGetEmbeddings(
    ctx context.Context, 
    texts []string) (map[string][]float32, []string) {
    
    cached := make(map[string][]float32)
    missing := make([]string, 0)
    
    // æ‰¹é‡ç”Ÿæˆé”®
    keys := make([]string, len(texts))
    for i, text := range texts {
        keys[i] = ec.generateKey(text)
    }
    
    // æ‰¹é‡æŸ¥è¯¢ç¼“å­˜
    results := ec.cacheSystem.batchGet(keys)
    
    for i, text := range texts {
        if result, exists := results[keys[i]]; exists {
            if embedding, ok := ec.deserializeEmbedding(result); ok {
                cached[text] = embedding
            } else {
                missing = append(missing, text)
            }
        } else {
            missing = append(missing, text)
        }
    }
    
    // æ›´æ–°æ‰¹é‡æŒ‡æ ‡
    hitCount := len(cached)
    missCount := len(missing)
    ec.cacheSystem.metrics.RecordBatchOperation("embedding", hitCount, missCount)
    
    return cached, missing
}

func (ec *EmbeddingCache) BatchSetEmbeddings(
    ctx context.Context,
    embeddings map[string][]float32,
    ttl time.Duration) error {
    
    entries := make(map[string][]byte)
    
    for text, embedding := range embeddings {
        key := ec.generateKey(text)
        
        // å‹ç¼©å’Œåºåˆ—åŒ–
        compressed, err := ec.compressor.Compress(embedding)
        if err != nil {
            log.Warn("å‘é‡å‹ç¼©å¤±è´¥", zap.String("text", text), zap.Error(err))
            continue
        }
        
        entry := &EmbeddingCacheEntry{
            Text:           text,
            Embedding:      compressed,
            CreatedAt:      time.Now(),
            TTL:            ttl,
            OriginalSize:   len(embedding) * 4,
            CompressedSize: len(compressed),
        }
        
        serialized, err := json.Marshal(entry)
        if err != nil {
            log.Warn("åºåˆ—åŒ–å¤±è´¥", zap.String("text", text), zap.Error(err))
            continue
        }
        
        entries[key] = serialized
    }
    
    // æ‰¹é‡å­˜å‚¨
    return ec.cacheSystem.batchSet(entries, ttl)
}
```

### ğŸ—œï¸ å‘é‡å‹ç¼©ä¼˜åŒ–

```go
// internal/cache/vector_compressor.go
type VectorCompressor struct {
    config *CompressionConfig
}

type CompressionConfig struct {
    Algorithm    string  `yaml:"algorithm"`     // "quantization", "pca", "gzip"
    Precision    int     `yaml:"precision"`     // 8 (8-bit quantization)
    CompressionRatio float64 `yaml:"compression_ratio"` // 0.25 (4:1)
}

func NewVectorCompressor() *VectorCompressor {
    return &VectorCompressor{
        config: &CompressionConfig{
            Algorithm:        "quantization",
            Precision:        8,
            CompressionRatio: 0.25,
        },
    }
}

func (vc *VectorCompressor) Compress(vector []float32) ([]byte, error) {
    switch vc.config.Algorithm {
    case "quantization":
        return vc.quantizeVector(vector)
    case "pca":
        return vc.pcaCompress(vector)
    case "gzip":
        return vc.gzipCompress(vector)
    default:
        return vc.rawCompress(vector)
    }
}

func (vc *VectorCompressor) Decompress(data []byte) ([]float32, error) {
    switch vc.config.Algorithm {
    case "quantization":
        return vc.dequantizeVector(data)
    case "pca":
        return vc.pcaDecompress(data)
    case "gzip":
        return vc.gzipDecompress(data)
    default:
        return vc.rawDecompress(data)
    }
}

func (vc *VectorCompressor) quantizeVector(vector []float32) ([]byte, error) {
    if len(vector) == 0 {
        return nil, nil
    }
    
    // æ‰¾åˆ°å‘é‡çš„æœ€å°å€¼å’Œæœ€å¤§å€¼
    minVal, maxVal := vector[0], vector[0]
    for _, v := range vector {
        if v < minVal {
            minVal = v
        }
        if v > maxVal {
            maxVal = v
        }
    }
    
    // è®¡ç®—é‡åŒ–å‚æ•°
    scale := (maxVal - minVal) / 255.0
    
    // åˆ›å»ºé‡åŒ–ç»“æœ
    result := make([]byte, 8+len(vector)) // 8 bytes for minVal + scale, rest for quantized values
    
    // å­˜å‚¨é‡åŒ–å‚æ•°
    binary.LittleEndian.PutUint32(result[0:4], math.Float32bits(minVal))
    binary.LittleEndian.PutUint32(result[4:8], math.Float32bits(scale))
    
    // é‡åŒ–å‘é‡å€¼
    for i, v := range vector {
        if scale > 0 {
            quantized := uint8((v - minVal) / scale)
            result[8+i] = quantized
        } else {
            result[8+i] = 0
        }
    }
    
    return result, nil
}

func (vc *VectorCompressor) dequantizeVector(data []byte) ([]float32, error) {
    if len(data) < 8 {
        return nil, fmt.Errorf("æ•°æ®é•¿åº¦ä¸è¶³")
    }
    
    // è§£æé‡åŒ–å‚æ•°
    minVal := math.Float32frombits(binary.LittleEndian.Uint32(data[0:4]))
    scale := math.Float32frombits(binary.LittleEndian.Uint32(data[4:8]))
    
    // åé‡åŒ–å‘é‡
    vectorSize := len(data) - 8
    result := make([]float32, vectorSize)
    
    for i := 0; i < vectorSize; i++ {
        quantized := data[8+i]
        result[i] = minVal + float32(quantized)*scale
    }
    
    return result, nil
}

func (vc *VectorCompressor) EstimateCompressionRatio(vector []float32) float64 {
    originalSize := len(vector) * 4 // float32 = 4 bytes
    
    switch vc.config.Algorithm {
    case "quantization":
        compressedSize := 8 + len(vector) // 8 bytes metadata + 1 byte per value
        return float64(compressedSize) / float64(originalSize)
    case "pca":
        reducedSize := int(float64(len(vector)) * vc.config.CompressionRatio)
        return float64(reducedSize*4) / float64(originalSize)
    default:
        return 1.0
    }
}
```

---

## ğŸƒ æœç´¢ç»“æœç¼“å­˜

### ğŸ” è¯­ä¹‰ç¼“å­˜ç­–ç•¥

```go
// internal/cache/search_cache.go
type SearchCache struct {
    cacheSystem     *VectorCacheSystem
    similarityCache *SimilarityCache
    resultRanker    *ResultRanker
}

type SearchCacheEntry struct {
    Query           string           `json:"query"`
    QueryVector     []float32        `json:"query_vector"`
    Results         []*SearchResult  `json:"results"`
    Metadata        *SearchMetadata  `json:"metadata"`
    CreatedAt       time.Time        `json:"created_at"`
    ExpiresAt       time.Time        `json:"expires_at"`
    AccessCount     int              `json:"access_count"`
    SimilarQueries  []string         `json:"similar_queries"`
}

type SearchMetadata struct {
    SearchType      string    `json:"search_type"`
    ConnectionID    int64     `json:"connection_id"`
    UserID          int64     `json:"user_id"`
    ResponseTime    time.Duration `json:"response_time"`
    ResultCount     int       `json:"result_count"`
    SimilarityThreshold float64 `json:"similarity_threshold"`
}

func NewSearchCache(cacheSystem *VectorCacheSystem) *SearchCache {
    return &SearchCache{
        cacheSystem:     cacheSystem,
        similarityCache: NewSimilarityCache(),
        resultRanker:    NewResultRanker(),
    }
}

func (sc *SearchCache) GetSearchResults(
    ctx context.Context,
    query string,
    queryVector []float32,
    searchType string) (*SearchCacheResult, bool) {
    
    // 1. å°è¯•ç²¾ç¡®åŒ¹é…
    exactKey := sc.generateExactKey(query, searchType)
    if cached, exists := sc.cacheSystem.get(exactKey); exists {
        if result, ok := sc.deserializeSearchResult(cached); ok {
            sc.recordCacheHit("exact", result)
            return result, true
        }
    }
    
    // 2. å°è¯•è¯­ä¹‰ç›¸ä¼¼åŒ¹é…
    if semanticResult := sc.findSimilarCachedQuery(queryVector, searchType); semanticResult != nil {
        sc.recordCacheHit("semantic", semanticResult)
        return semanticResult, true
    }
    
    sc.recordCacheMiss(searchType)
    return nil, false
}

func (sc *SearchCache) findSimilarCachedQuery(
    queryVector []float32,
    searchType string) *SearchCacheResult {
    
    // è·å–å€™é€‰ç¼“å­˜æ¡ç›®
    candidates := sc.getCandidateEntries(searchType)
    
    var bestMatch *SearchCacheEntry
    var bestSimilarity float64
    
    for _, candidate := range candidates {
        // è®¡ç®—è¯­ä¹‰ç›¸ä¼¼åº¦
        similarity := sc.calculateVectorSimilarity(queryVector, candidate.QueryVector)
        
        if similarity > 0.9 && similarity > bestSimilarity { // 90%ä»¥ä¸Šç›¸ä¼¼åº¦
            bestMatch = candidate
            bestSimilarity = similarity
        }
    }
    
    if bestMatch != nil {
        // é‡æ–°æ’åºç»“æœä»¥é€‚åº”å½“å‰æŸ¥è¯¢
        rerankedResults := sc.resultRanker.RerankForQuery(bestMatch.Results, queryVector)
        
        return &SearchCacheResult{
            Results:      rerankedResults,
            Source:       "semantic_cache",
            Similarity:   bestSimilarity,
            OriginalQuery: bestMatch.Query,
            CacheAge:     time.Since(bestMatch.CreatedAt),
        }
    }
    
    return nil
}

func (sc *SearchCache) SetSearchResults(
    ctx context.Context,
    query string,
    queryVector []float32,
    results []*SearchResult,
    metadata *SearchMetadata,
    ttl time.Duration) error {
    
    entry := &SearchCacheEntry{
        Query:       query,
        QueryVector: queryVector,
        Results:     results,
        Metadata:    metadata,
        CreatedAt:   time.Now(),
        ExpiresAt:   time.Now().Add(ttl),
        AccessCount: 0,
    }
    
    // æ‰¾åˆ°ç›¸ä¼¼æŸ¥è¯¢ä»¥å»ºç«‹å…³è”
    entry.SimilarQueries = sc.findSimilarQueries(queryVector)
    
    // ç”Ÿæˆç¼“å­˜é”®
    exactKey := sc.generateExactKey(query, metadata.SearchType)
    semanticKey := sc.generateSemanticKey(queryVector, metadata.SearchType)
    
    // åºåˆ—åŒ–æ¡ç›®
    serialized, err := json.Marshal(entry)
    if err != nil {
        return fmt.Errorf("åºåˆ—åŒ–æœç´¢ç»“æœå¤±è´¥: %w", err)
    }
    
    // å­˜å‚¨åˆ°ç²¾ç¡®åŒ¹é…ç¼“å­˜
    if err := sc.cacheSystem.set(exactKey, serialized, ttl); err != nil {
        return err
    }
    
    // å­˜å‚¨åˆ°è¯­ä¹‰åŒ¹é…ç¼“å­˜
    return sc.cacheSystem.set(semanticKey, serialized, ttl)
}

func (sc *SearchCache) InvalidateRelatedCache(
    ctx context.Context,
    connectionID int64,
    affectedTables []string) error {
    
    // æ„å»ºå¤±æ•ˆæ¨¡å¼
    patterns := make([]string, 0, len(affectedTables))
    for _, table := range affectedTables {
        patterns = append(patterns, fmt.Sprintf("search:*:conn_%d:*table_%s*", connectionID, table))
    }
    
    // æ‰¹é‡å¤±æ•ˆç›¸å…³ç¼“å­˜
    return sc.cacheSystem.invalidateByPatterns(patterns)
}

func (sc *SearchCache) generateExactKey(query, searchType string) string {
    hasher := md5.New()
    hasher.Write([]byte(fmt.Sprintf("%s:%s", query, searchType)))
    hash := hex.EncodeToString(hasher.Sum(nil))
    
    return fmt.Sprintf("search:exact:%s", hash)
}

func (sc *SearchCache) generateSemanticKey(vector []float32, searchType string) string {
    // ä½¿ç”¨å‘é‡çš„hashä½œä¸ºè¯­ä¹‰é”®çš„ä¸€éƒ¨åˆ†
    vectorHash := sc.hashVector(vector)
    return fmt.Sprintf("search:semantic:%s:%s", searchType, vectorHash)
}
```

### ğŸ“ˆ æ™ºèƒ½é¢„å–ç­–ç•¥

```go
// internal/cache/prefetch_strategy.go
type PrefetchStrategy struct {
    cacheSystem    *VectorCacheSystem
    usageAnalyzer  *UsageAnalyzer
    predictor      *QueryPredictor
    scheduler      *PrefetchScheduler
}

type PrefetchConfig struct {
    Enabled         bool    `yaml:"enabled"`         // true
    PrefetchRatio   float64 `yaml:"prefetch_ratio"`  // 0.2 (20%èµ„æºç”¨äºé¢„å–)
    MinConfidence   float64 `yaml:"min_confidence"`  // 0.7
    MaxPrefetchSize int     `yaml:"max_prefetch_size"` // 100
    TriggerThreshold int    `yaml:"trigger_threshold"` // 5 (è®¿é—®5æ¬¡åè§¦å‘é¢„å–)
}

func NewPrefetchStrategy(cacheSystem *VectorCacheSystem) *PrefetchStrategy {
    return &PrefetchStrategy{
        cacheSystem:   cacheSystem,
        usageAnalyzer: NewUsageAnalyzer(),
        predictor:     NewQueryPredictor(),
        scheduler:     NewPrefetchScheduler(),
    }
}

func (ps *PrefetchStrategy) StartPrefetching() {
    ticker := time.NewTicker(10 * time.Minute)
    defer ticker.Stop()
    
    for {
        select {
        case <-ticker.C:
            ps.performPrefetch()
        }
    }
}

func (ps *PrefetchStrategy) performPrefetch() {
    // 1. åˆ†æç”¨æˆ·è®¿é—®æ¨¡å¼
    patterns := ps.usageAnalyzer.AnalyzeAccessPatterns()
    
    // 2. é¢„æµ‹ä¸‹ä¸€æ­¥å¯èƒ½çš„æŸ¥è¯¢
    predictions := ps.predictor.PredictNextQueries(patterns)
    
    // 3. é€‰æ‹©é«˜ç½®ä¿¡åº¦çš„é¢„æµ‹è¿›è¡Œé¢„å–
    candidates := ps.selectPrefetchCandidates(predictions)
    
    // 4. æ‰§è¡Œé¢„å–ä»»åŠ¡
    ps.scheduler.SchedulePrefetchTasks(candidates)
}

func (ps *PrefetchStrategy) selectPrefetchCandidates(
    predictions []*QueryPrediction) []*PrefetchCandidate {
    
    var candidates []*PrefetchCandidate
    
    for _, pred := range predictions {
        if pred.Confidence < ps.config.MinConfidence {
            continue
        }
        
        // æ£€æŸ¥ç¼“å­˜ä¸­æ˜¯å¦å·²å­˜åœ¨
        if ps.isAlreadyCached(pred.Query) {
            continue
        }
        
        candidate := &PrefetchCandidate{
            Query:       pred.Query,
            QueryType:   pred.QueryType,
            Confidence:  pred.Confidence,
            Priority:    ps.calculatePriority(pred),
            EstimatedCost: ps.estimateComputationCost(pred),
        }
        
        candidates = append(candidates, candidate)
    }
    
    // æŒ‰ä¼˜å…ˆçº§æ’åº
    sort.Slice(candidates, func(i, j int) bool {
        return candidates[i].Priority > candidates[j].Priority
    })
    
    // é™åˆ¶é¢„å–æ•°é‡
    if len(candidates) > ps.config.MaxPrefetchSize {
        candidates = candidates[:ps.config.MaxPrefetchSize]
    }
    
    return candidates
}

func (ps *PrefetchStrategy) OnQueryExecuted(query string, results []*SearchResult) {
    // è®°å½•æŸ¥è¯¢æ‰§è¡Œï¼Œç”¨äºæ¨¡å¼åˆ†æ
    ps.usageAnalyzer.RecordQuery(query, results)
    
    // è§¦å‘ç›¸å…³æŸ¥è¯¢çš„é¢„å–
    go ps.triggerRelatedPrefetch(query, results)
}

func (ps *PrefetchStrategy) triggerRelatedPrefetch(query string, results []*SearchResult) {
    // åŸºäºå½“å‰æŸ¥è¯¢ç»“æœï¼Œé¢„æµ‹ç”¨æˆ·å¯èƒ½çš„åç»­æŸ¥è¯¢
    relatedQueries := ps.predictor.PredictRelatedQueries(query, results)
    
    for _, relatedQuery := range relatedQueries {
        if !ps.isAlreadyCached(relatedQuery.Query) {
            ps.scheduler.ScheduleImmediatePrefetch(relatedQuery)
        }
    }
}
```

---

## ğŸ’¡ æ€§èƒ½ä¼˜åŒ–ç­–ç•¥

### âš¡ æ‰¹é‡æ“ä½œä¼˜åŒ–

```go
// internal/cache/batch_operations.go
type BatchOperationManager struct {
    cacheSystem    *VectorCacheSystem
    batchConfig    *BatchConfig
    operationQueue chan *BatchOperation
    workers        []*BatchWorker
    aggregator     *OperationAggregator
}

type BatchConfig struct {
    MaxBatchSize    int           `yaml:"max_batch_size"`    // 100
    MaxWaitTime     time.Duration `yaml:"max_wait_time"`     // 10ms
    WorkerCount     int           `yaml:"worker_count"`      // 4
    AggregateWindow time.Duration `yaml:"aggregate_window"`  // 1ms
}

type BatchOperation struct {
    Type        OperationType `json:"type"`
    Keys        []string      `json:"keys"`
    Values      [][]byte      `json:"values"`
    TTL         time.Duration `json:"ttl"`
    ResponseCh  chan *BatchResponse `json:"-"`
    SubmittedAt time.Time     `json:"submitted_at"`
}

type BatchResponse struct {
    Results []interface{} `json:"results"`
    Errors  []error       `json:"errors"`
    Latency time.Duration `json:"latency"`
}

func NewBatchOperationManager(cacheSystem *VectorCacheSystem) *BatchOperationManager {
    bom := &BatchOperationManager{
        cacheSystem:    cacheSystem,
        batchConfig:    loadBatchConfig(),
        operationQueue: make(chan *BatchOperation, 1000),
        aggregator:     NewOperationAggregator(),
    }
    
    // å¯åŠ¨å·¥ä½œçº¿ç¨‹
    for i := 0; i < bom.batchConfig.WorkerCount; i++ {
        worker := NewBatchWorker(i, bom.cacheSystem, bom.operationQueue)
        bom.workers = append(bom.workers, worker)
        go worker.Start()
    }
    
    // å¯åŠ¨æ“ä½œèšåˆå™¨
    go bom.aggregator.Start()
    
    return bom
}

func (bom *BatchOperationManager) BatchGet(keys []string) (*BatchResponse, error) {
    operation := &BatchOperation{
        Type:        OperationTypeGet,
        Keys:        keys,
        ResponseCh:  make(chan *BatchResponse, 1),
        SubmittedAt: time.Now(),
    }
    
    // æäº¤åˆ°é˜Ÿåˆ—
    select {
    case bom.operationQueue <- operation:
        // ç­‰å¾…å“åº”
        response := <-operation.ResponseCh
        return response, nil
    case <-time.After(bom.batchConfig.MaxWaitTime * 2):
        return nil, fmt.Errorf("æ‰¹é‡æ“ä½œè¶…æ—¶")
    }
}

func (bom *BatchOperationManager) BatchSet(
    entries map[string][]byte,
    ttl time.Duration) (*BatchResponse, error) {
    
    keys := make([]string, 0, len(entries))
    values := make([][]byte, 0, len(entries))
    
    for key, value := range entries {
        keys = append(keys, key)
        values = append(values, value)
    }
    
    operation := &BatchOperation{
        Type:        OperationTypeSet,
        Keys:        keys,
        Values:      values,
        TTL:         ttl,
        ResponseCh:  make(chan *BatchResponse, 1),
        SubmittedAt: time.Now(),
    }
    
    select {
    case bom.operationQueue <- operation:
        response := <-operation.ResponseCh
        return response, nil
    case <-time.After(bom.batchConfig.MaxWaitTime * 2):
        return nil, fmt.Errorf("æ‰¹é‡æ“ä½œè¶…æ—¶")
    }
}

type BatchWorker struct {
    id             int
    cacheSystem    *VectorCacheSystem
    operationQueue <-chan *BatchOperation
    batchBuffer    []*BatchOperation
    lastFlush      time.Time
}

func (bw *BatchWorker) Start() {
    ticker := time.NewTicker(1 * time.Millisecond)
    defer ticker.Stop()
    
    for {
        select {
        case operation := <-bw.operationQueue:
            bw.batchBuffer = append(bw.batchBuffer, operation)
            
            // æ£€æŸ¥æ˜¯å¦éœ€è¦ç«‹å³åˆ·æ–°
            if bw.shouldFlush() {
                bw.flushBatch()
            }
            
        case <-ticker.C:
            // å®šæœŸåˆ·æ–°
            if len(bw.batchBuffer) > 0 && time.Since(bw.lastFlush) > 5*time.Millisecond {
                bw.flushBatch()
            }
        }
    }
}

func (bw *BatchWorker) shouldFlush() bool {
    return len(bw.batchBuffer) >= 50 || // æ‰¹é‡å¤§å°è¾¾åˆ°é˜ˆå€¼
           time.Since(bw.lastFlush) > 10*time.Millisecond // ç­‰å¾…æ—¶é—´è¾¾åˆ°é˜ˆå€¼
}

func (bw *BatchWorker) flushBatch() {
    if len(bw.batchBuffer) == 0 {
        return
    }
    
    start := time.Now()
    
    // æŒ‰æ“ä½œç±»å‹åˆ†ç»„
    getBatch := make([]*BatchOperation, 0)
    setBatch := make([]*BatchOperation, 0)
    
    for _, op := range bw.batchBuffer {
        switch op.Type {
        case OperationTypeGet:
            getBatch = append(getBatch, op)
        case OperationTypeSet:
            setBatch = append(setBatch, op)
        }
    }
    
    // æ‰§è¡Œæ‰¹é‡GETæ“ä½œ
    if len(getBatch) > 0 {
        bw.executeBatchGet(getBatch)
    }
    
    // æ‰§è¡Œæ‰¹é‡SETæ“ä½œ
    if len(setBatch) > 0 {
        bw.executeBatchSet(setBatch)
    }
    
    // æ¸…ç©ºç¼“å†²åŒº
    bw.batchBuffer = bw.batchBuffer[:0]
    bw.lastFlush = time.Now()
    
    // è®°å½•æ‰¹é‡æ“ä½œæŒ‡æ ‡
    bw.cacheSystem.metrics.RecordBatchFlush(len(getBatch)+len(setBatch), time.Since(start))
}
```

### ğŸ”„ è¿æ¥æ± ä¼˜åŒ–

```go
// internal/cache/connection_pool.go
type ConnectionPoolManager struct {
    pools   map[string]*ConnectionPool
    config  *PoolConfig
    monitor *PoolMonitor
    mu      sync.RWMutex
}

type PoolConfig struct {
    // Redisè¿æ¥æ± é…ç½®
    Redis struct {
        MaxIdle     int           `yaml:"max_idle"`     // 10
        MaxActive   int           `yaml:"max_active"`   // 100
        IdleTimeout time.Duration `yaml:"idle_timeout"` // 5m
        Wait        bool          `yaml:"wait"`         // true
        MaxConnLifetime time.Duration `yaml:"max_conn_lifetime"` // 1h
    } `yaml:"redis"`
    
    // è¿æ¥å¥åº·æ£€æŸ¥
    HealthCheck struct {
        Enabled  bool          `yaml:"enabled"`  // true
        Interval time.Duration `yaml:"interval"` // 30s
        Timeout  time.Duration `yaml:"timeout"`  // 5s
    } `yaml:"health_check"`
}

type ConnectionPool struct {
    name       string
    pool       *redis.Pool
    config     *PoolConfig
    metrics    *PoolMetrics
    healthChecker *HealthChecker
}

func NewConnectionPoolManager(config *PoolConfig) *ConnectionPoolManager {
    return &ConnectionPoolManager{
        pools:   make(map[string]*ConnectionPool),
        config:  config,
        monitor: NewPoolMonitor(),
    }
}

func (cpm *ConnectionPoolManager) GetOrCreatePool(name, address string) *ConnectionPool {
    cpm.mu.RLock()
    if pool, exists := cpm.pools[name]; exists {
        cpm.mu.RUnlock()
        return pool
    }
    cpm.mu.RUnlock()
    
    cpm.mu.Lock()
    defer cpm.mu.Unlock()
    
    // åŒé‡æ£€æŸ¥
    if pool, exists := cpm.pools[name]; exists {
        return pool
    }
    
    // åˆ›å»ºæ–°è¿æ¥æ± 
    pool := &ConnectionPool{
        name:    name,
        config:  cpm.config,
        metrics: NewPoolMetrics(name),
    }
    
    pool.pool = &redis.Pool{
        MaxIdle:         cpm.config.Redis.MaxIdle,
        MaxActive:       cpm.config.Redis.MaxActive,
        IdleTimeout:     cpm.config.Redis.IdleTimeout,
        Wait:            cpm.config.Redis.Wait,
        MaxConnLifetime: cpm.config.Redis.MaxConnLifetime,
        Dial: func() (redis.Conn, error) {
            return redis.Dial("tcp", address,
                redis.DialConnectTimeout(5*time.Second),
                redis.DialReadTimeout(3*time.Second),
                redis.DialWriteTimeout(3*time.Second),
            )
        },
        TestOnBorrow: func(c redis.Conn, t time.Time) error {
            if time.Since(t) < 30*time.Second {
                return nil
            }
            _, err := c.Do("PING")
            return err
        },
    }
    
    // å¯åŠ¨å¥åº·æ£€æŸ¥
    if cpm.config.HealthCheck.Enabled {
        pool.healthChecker = NewHealthChecker(pool)
        go pool.healthChecker.Start()
    }
    
    cpm.pools[name] = pool
    return pool
}

func (cp *ConnectionPool) GetConnection() redis.Conn {
    start := time.Now()
    conn := cp.pool.Get()
    
    // è®°å½•è·å–è¿æ¥çš„å»¶è¿Ÿ
    cp.metrics.RecordConnectionAcquisition(time.Since(start))
    
    return &instrumentedConnection{
        Conn:    conn,
        pool:    cp,
        startTime: time.Now(),
    }
}

type instrumentedConnection struct {
    redis.Conn
    pool      *ConnectionPool
    startTime time.Time
}

func (ic *instrumentedConnection) Close() error {
    // è®°å½•è¿æ¥ä½¿ç”¨æ—¶é—´
    ic.pool.metrics.RecordConnectionUsage(time.Since(ic.startTime))
    
    return ic.Conn.Close()
}

func (ic *instrumentedConnection) Do(commandName string, args ...interface{}) (interface{}, error) {
    start := time.Now()
    result, err := ic.Conn.Do(commandName, args...)
    duration := time.Since(start)
    
    // è®°å½•å‘½ä»¤æ‰§è¡ŒæŒ‡æ ‡
    ic.pool.metrics.RecordCommand(commandName, duration, err == nil)
    
    return result, err
}
```

---

## ğŸ“Š æ€§èƒ½ç›‘æ§ç³»ç»Ÿ

### ğŸ“ˆ ç¼“å­˜æŒ‡æ ‡ç›‘æ§

```go
// internal/cache/cache_metrics.go
type CacheMetrics struct {
    // åŸºç¡€æŒ‡æ ‡
    hitCount    *prometheus.CounterVec
    missCount   *prometheus.CounterVec
    setCount    *prometheus.CounterVec
    deleteCount *prometheus.CounterVec
    
    // å»¶è¿ŸæŒ‡æ ‡
    operationDuration *prometheus.HistogramVec
    cacheSize         *prometheus.GaugeVec
    
    // å‘½ä¸­ç‡æŒ‡æ ‡
    hitRate    *prometheus.GaugeVec
    missRate   *prometheus.GaugeVec
    
    // å†…å­˜ä½¿ç”¨æŒ‡æ ‡
    memoryUsage    *prometheus.GaugeVec
    evictionCount  *prometheus.CounterVec
    
    // æ‰¹é‡æ“ä½œæŒ‡æ ‡
    batchOperationDuration *prometheus.HistogramVec
    batchSize              *prometheus.HistogramVec
}

func NewCacheMetrics() *CacheMetrics {
    return &CacheMetrics{
        hitCount: prometheus.NewCounterVec(
            prometheus.CounterOpts{
                Name: "cache_hits_total",
                Help: "Total cache hits",
            },
            []string{"cache_type", "cache_level"},
        ),
        missCount: prometheus.NewCounterVec(
            prometheus.CounterOpts{
                Name: "cache_misses_total",
                Help: "Total cache misses",
            },
            []string{"cache_type", "cache_level"},
        ),
        operationDuration: prometheus.NewHistogramVec(
            prometheus.HistogramOpts{
                Name: "cache_operation_duration_seconds",
                Help: "Cache operation duration",
                Buckets: []float64{0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1},
            },
            []string{"operation", "cache_level"},
        ),
        cacheSize: prometheus.NewGaugeVec(
            prometheus.GaugeOpts{
                Name: "cache_size_entries",
                Help: "Current cache size in entries",
            },
            []string{"cache_type", "cache_level"},
        ),
        hitRate: prometheus.NewGaugeVec(
            prometheus.GaugeOpts{
                Name: "cache_hit_rate",
                Help: "Cache hit rate",
            },
            []string{"cache_type", "cache_level"},
        ),
    }
}

func (cm *CacheMetrics) RecordHit(cacheType string, level int) {
    cm.hitCount.WithLabelValues(cacheType, fmt.Sprintf("L%d", level)).Inc()
    cm.updateHitRate(cacheType, level)
}

func (cm *CacheMetrics) RecordMiss(cacheType string, level int) {
    cm.missCount.WithLabelValues(cacheType, fmt.Sprintf("L%d", level)).Inc()
    cm.updateHitRate(cacheType, level)
}

func (cm *CacheMetrics) updateHitRate(cacheType string, level int) {
    levelStr := fmt.Sprintf("L%d", level)
    
    hits := getCounterValue(cm.hitCount.WithLabelValues(cacheType, levelStr))
    misses := getCounterValue(cm.missCount.WithLabelValues(cacheType, levelStr))
    
    if hits+misses > 0 {
        hitRate := hits / (hits + misses)
        cm.hitRate.WithLabelValues(cacheType, levelStr).Set(hitRate)
    }
}

// æ€§èƒ½æŠ¥å‘Šç”Ÿæˆ
func (cm *CacheMetrics) GeneratePerformanceReport() *PerformanceReport {
    report := &PerformanceReport{
        Timestamp: time.Now(),
        Metrics:   make(map[string]interface{}),
    }
    
    // æ”¶é›†L1ç¼“å­˜æŒ‡æ ‡
    l1Metrics := cm.collectL1Metrics()
    report.Metrics["l1_cache"] = l1Metrics
    
    // æ”¶é›†L2ç¼“å­˜æŒ‡æ ‡
    l2Metrics := cm.collectL2Metrics()
    report.Metrics["l2_cache"] = l2Metrics
    
    // æ”¶é›†L3ç¼“å­˜æŒ‡æ ‡
    l3Metrics := cm.collectL3Metrics()
    report.Metrics["l3_cache"] = l3Metrics
    
    // è®¡ç®—æ•´ä½“æ€§èƒ½æŒ‡æ ‡
    overallMetrics := cm.calculateOverallMetrics(l1Metrics, l2Metrics, l3Metrics)
    report.Metrics["overall"] = overallMetrics
    
    return report
}
```

### ğŸ“‹ Grafanaä»ªè¡¨æ¿

```yaml
# monitoring/grafana/cache-dashboard.yaml
dashboard:
  title: "å‘é‡ç¼“å­˜æ€§èƒ½ç›‘æ§"
  panels:
    - title: "ç¼“å­˜å‘½ä¸­ç‡"
      type: "graph"
      targets:
        - expr: "cache_hit_rate"
          legendFormat: "{{cache_type}} - {{cache_level}}"
      yAxes:
        - min: 0
          max: 1
          unit: "percentunit"
    
    - title: "ç¼“å­˜æ“ä½œå»¶è¿Ÿ"
      type: "graph"
      targets:
        - expr: "histogram_quantile(0.95, rate(cache_operation_duration_seconds_bucket[5m]))"
          legendFormat: "P95å»¶è¿Ÿ"
        - expr: "histogram_quantile(0.50, rate(cache_operation_duration_seconds_bucket[5m]))"
          legendFormat: "P50å»¶è¿Ÿ"
      yAxes:
        - unit: "s"
    
    - title: "ç¼“å­˜å¤§å°"
      type: "graph"
      targets:
        - expr: "cache_size_entries"
          legendFormat: "{{cache_type}} - {{cache_level}}"
      yAxes:
        - unit: "short"
    
    - title: "å†…å­˜ä½¿ç”¨ç‡"
      type: "singlestat"
      targets:
        - expr: "sum(cache_memory_usage_bytes) / sum(cache_memory_limit_bytes)"
      valueMaps:
        - value: "null"
          text: "N/A"
      thresholds: "0.7,0.9"
      colors: ["green", "yellow", "red"]
      format: "percentunit"
```

---

## ğŸ› ï¸ è°ƒä¼˜å»ºè®®

### 1. ç¼“å­˜é…ç½®ä¼˜åŒ–

```yaml
# config/cache_optimization.yaml
cache_tuning:
  # L1å†…å­˜ç¼“å­˜ä¼˜åŒ–
  l1_optimization:
    max_size: 10000           # æ ¹æ®å†…å­˜å®¹é‡è°ƒæ•´
    evict_policy: "lru"       # LRUæœ€é€‚åˆçƒ­ç‚¹æ•°æ®
    ttl: "1h"                 # çŸ­TTLä¿è¯æ•°æ®æ–°é²œåº¦
    
  # L2 Redisç¼“å­˜ä¼˜åŒ–  
  l2_optimization:
    connection_pool_size: 100  # æ ¹æ®å¹¶å‘é‡è°ƒæ•´
    max_retries: 3
    retry_delay: "100ms"
    compression: true          # å¯ç”¨å‹ç¼©èŠ‚çœç½‘ç»œå¸¦å®½
    
  # L3æŒä¹…åŒ–ç¼“å­˜ä¼˜åŒ–
  l3_optimization:
    storage_path: "/ssd/cache" # ä½¿ç”¨SSDæå‡æ€§èƒ½
    compression: true
    background_cleanup: true
    
  # é¢„çƒ­ç­–ç•¥ä¼˜åŒ–
  warmup_optimization:
    common_queries_file: "common_queries.txt"
    warmup_concurrency: 5
    warmup_timeout: "30s"
```

### 2. ç›‘æ§å‘Šè­¦é…ç½®

```yaml
# config/cache_alerts.yaml
cache_alerts:
  hit_rate_low:
    threshold: 0.7
    severity: "warning"
    duration: "5m"
    
  memory_usage_high:
    threshold: 0.85
    severity: "critical"
    duration: "2m"
    
  latency_high:
    threshold: "50ms"
    severity: "warning"
    duration: "5m"
    
  error_rate_high:
    threshold: 0.05
    severity: "critical"
    duration: "1m"
```

---

<div align="center">

**âš¡ å‘é‡ç¼“å­˜æˆåŠŸå…³é”®ï¼šå¤šå±‚æ¶æ„ + æ™ºèƒ½é¢„å– + æ€§èƒ½ç›‘æ§**

</div>