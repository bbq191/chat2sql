# ⚡ 向量缓存与性能优化指南

<div align="center">

![Vector Cache](https://img.shields.io/badge/Vector_Cache-Performance-blue.svg)
![Optimization](https://img.shields.io/badge/Optimization-Multi_Layer-green.svg)
![Latency](https://img.shields.io/badge/Latency-<10ms-orange.svg)

**Chat2SQL P3阶段 - 向量缓存系统与性能优化完整方案**

</div>

## 📋 概述

本文档专门针对Chat2SQL系统中向量缓存的设计实现、性能优化策略和系统调优方案，提供从内存到分布式的完整缓存解决方案。

## 🎯 性能目标

### 核心指标
- ✅ **缓存命中率**：Embedding缓存 > 85%，搜索缓存 > 70%
- ✅ **响应延迟**：缓存查找 < 1ms，向量计算 < 10ms
- ✅ **内存效率**：缓存空间利用率 > 80%
- ✅ **吞吐量**：支持 > 1000 QPS

### 优化层级
| 缓存层级 | 响应时间 | 命中率 | 容量 | 适用场景 |
|---------|---------|--------|------|----------|
| **L1 - 内存缓存** | < 1ms | > 90% | 1GB | 热点数据 |
| **L2 - Redis缓存** | < 5ms | > 80% | 10GB | 温数据 |
| **L3 - 持久化缓存** | < 50ms | > 60% | 100GB | 冷数据 |

---

## 🏗️ 多层缓存架构

### 📦 缓存系统架构

```go
// internal/cache/vector_cache.go
package cache

import (
    "context"
    "sync"
    "time"
    "crypto/md5"
    "encoding/hex"
    "encoding/json"
)

type VectorCacheSystem struct {
    // 多层缓存
    l1Cache     *MemoryCache      // L1: 内存缓存
    l2Cache     *RedisCache       // L2: Redis缓存  
    l3Cache     *PersistentCache  // L3: 持久化缓存
    
    // 配置和监控
    config      *CacheConfig
    metrics     *CacheMetrics
    
    // 缓存策略
    strategy    *CacheStrategy
    eviction    *EvictionManager
    
    // 并发控制
    mu          sync.RWMutex
    loadGroups  sync.Map  // 防止缓存击穿
}

type CacheConfig struct {
    // L1内存缓存配置
    L1 struct {
        MaxSize     int           `yaml:"max_size"`      // 10000
        TTL         time.Duration `yaml:"ttl"`           // 1h
        EvictPolicy string        `yaml:"evict_policy"`  // "lru"
    } `yaml:"l1"`
    
    // L2 Redis缓存配置
    L2 struct {
        Endpoints   []string      `yaml:"endpoints"`
        Password    string        `yaml:"password"`
        Database    int           `yaml:"database"`
        MaxRetries  int           `yaml:"max_retries"`   // 3
        TTL         time.Duration `yaml:"ttl"`           // 6h
        PoolSize    int           `yaml:"pool_size"`     // 100
    } `yaml:"l2"`
    
    // L3持久化缓存配置
    L3 struct {
        StoragePath string        `yaml:"storage_path"`  // "/data/cache"
        MaxSize     int64         `yaml:"max_size"`      // 100GB
        TTL         time.Duration `yaml:"ttl"`           // 24h
        Compression bool          `yaml:"compression"`   // true
    } `yaml:"l3"`
    
    // 预热配置
    Warmup struct {
        Enabled     bool     `yaml:"enabled"`      // true
        CommonQueries []string `yaml:"common_queries"`
        WarmupRatio float64  `yaml:"warmup_ratio"` // 0.1
    } `yaml:"warmup"`
}

type CacheEntry struct {
    Key         string      `json:"key"`
    Value       interface{} `json:"value"`
    CreatedAt   time.Time   `json:"created_at"`
    AccessedAt  time.Time   `json:"accessed_at"`
    AccessCount int         `json:"access_count"`
    TTL         time.Duration `json:"ttl"`
    Size        int         `json:"size"`
    Level       int         `json:"level"` // 1, 2, 3
}
```

### 🔧 缓存系统初始化

```go
func NewVectorCacheSystem(config *CacheConfig) (*VectorCacheSystem, error) {
    // 初始化L1内存缓存
    l1Cache, err := NewMemoryCache(&MemoryCacheConfig{
        MaxSize:     config.L1.MaxSize,
        TTL:         config.L1.TTL,
        EvictPolicy: config.L1.EvictPolicy,
    })
    if err != nil {
        return nil, fmt.Errorf("L1缓存初始化失败: %w", err)
    }
    
    // 初始化L2 Redis缓存
    l2Cache, err := NewRedisCache(&RedisCacheConfig{
        Endpoints:  config.L2.Endpoints,
        Password:   config.L2.Password,
        Database:   config.L2.Database,
        MaxRetries: config.L2.MaxRetries,
        PoolSize:   config.L2.PoolSize,
        TTL:        config.L2.TTL,
    })
    if err != nil {
        return nil, fmt.Errorf("L2缓存初始化失败: %w", err)
    }
    
    // 初始化L3持久化缓存
    l3Cache, err := NewPersistentCache(&PersistentCacheConfig{
        StoragePath: config.L3.StoragePath,
        MaxSize:     config.L3.MaxSize,
        TTL:         config.L3.TTL,
        Compression: config.L3.Compression,
    })
    if err != nil {
        return nil, fmt.Errorf("L3缓存初始化失败: %w", err)
    }
    
    system := &VectorCacheSystem{
        l1Cache:  l1Cache,
        l2Cache:  l2Cache,
        l3Cache:  l3Cache,
        config:   config,
        metrics:  NewCacheMetrics(),
        strategy: NewCacheStrategy(config),
        eviction: NewEvictionManager(),
    }
    
    // 启动缓存预热
    if config.Warmup.Enabled {
        go system.startWarmup()
    }
    
    // 启动后台维护任务
    go system.startMaintenance()
    
    return system, nil
}

func (vcs *VectorCacheSystem) startWarmup() {
    log.Info("开始缓存预热...")
    
    for _, query := range vcs.config.Warmup.CommonQueries {
        // 预热Embedding缓存
        key := vcs.generateEmbeddingKey(query)
        if _, exists := vcs.get(key); !exists {
            // 触发embedding计算和缓存
            go vcs.precomputeEmbedding(query)
        }
    }
    
    log.Info("缓存预热完成")
}

func (vcs *VectorCacheSystem) startMaintenance() {
    ticker := time.NewTicker(5 * time.Minute)
    defer ticker.Stop()
    
    for {
        select {
        case <-ticker.C:
            vcs.performMaintenance()
        }
    }
}

func (vcs *VectorCacheSystem) performMaintenance() {
    // 清理过期缓存
    vcs.cleanupExpiredEntries()
    
    // 更新缓存统计
    vcs.updateCacheStatistics()
    
    // 优化缓存分布
    vcs.optimizeCacheDistribution()
    
    // 生成性能报告
    vcs.generatePerformanceReport()
}
```

---

## 💾 Embedding向量缓存

### 🔑 智能键值管理

```go
// internal/cache/embedding_cache.go
type EmbeddingCache struct {
    cacheSystem *VectorCacheSystem
    hasher      *ConsistentHasher
    compressor  *VectorCompressor
}

func NewEmbeddingCache(cacheSystem *VectorCacheSystem) *EmbeddingCache {
    return &EmbeddingCache{
        cacheSystem: cacheSystem,
        hasher:      NewConsistentHasher(),
        compressor:  NewVectorCompressor(),
    }
}

func (ec *EmbeddingCache) GetEmbedding(ctx context.Context, text string) ([]float32, bool) {
    key := ec.generateKey(text)
    
    start := time.Now()
    defer func() {
        ec.cacheSystem.metrics.RecordLatency("get", time.Since(start))
    }()
    
    // 尝试从缓存获取
    if cached, exists := ec.cacheSystem.get(key); exists {
        if embedding, ok := ec.deserializeEmbedding(cached); ok {
            ec.cacheSystem.metrics.RecordHit("embedding")
            return embedding, true
        }
    }
    
    ec.cacheSystem.metrics.RecordMiss("embedding")
    return nil, false
}

func (ec *EmbeddingCache) SetEmbedding(
    ctx context.Context, 
    text string, 
    embedding []float32,
    ttl time.Duration) error {
    
    key := ec.generateKey(text)
    
    // 压缩向量以节省空间
    compressed, err := ec.compressor.Compress(embedding)
    if err != nil {
        return fmt.Errorf("向量压缩失败: %w", err)
    }
    
    // 序列化缓存条目
    entry := &EmbeddingCacheEntry{
        Text:        text,
        Embedding:   compressed,
        CreatedAt:   time.Now(),
        TTL:         ttl,
        OriginalSize: len(embedding) * 4, // float32 = 4 bytes
        CompressedSize: len(compressed),
    }
    
    serialized, err := json.Marshal(entry)
    if err != nil {
        return fmt.Errorf("序列化失败: %w", err)
    }
    
    // 存储到缓存系统
    return ec.cacheSystem.set(key, serialized, ttl)
}

func (ec *EmbeddingCache) generateKey(text string) string {
    // 使用MD5生成一致的键
    hasher := md5.New()
    hasher.Write([]byte(text))
    hash := hex.EncodeToString(hasher.Sum(nil))
    
    return fmt.Sprintf("embedding:%s", hash)
}

func (ec *EmbeddingCache) BatchGetEmbeddings(
    ctx context.Context, 
    texts []string) (map[string][]float32, []string) {
    
    cached := make(map[string][]float32)
    missing := make([]string, 0)
    
    // 批量生成键
    keys := make([]string, len(texts))
    for i, text := range texts {
        keys[i] = ec.generateKey(text)
    }
    
    // 批量查询缓存
    results := ec.cacheSystem.batchGet(keys)
    
    for i, text := range texts {
        if result, exists := results[keys[i]]; exists {
            if embedding, ok := ec.deserializeEmbedding(result); ok {
                cached[text] = embedding
            } else {
                missing = append(missing, text)
            }
        } else {
            missing = append(missing, text)
        }
    }
    
    // 更新批量指标
    hitCount := len(cached)
    missCount := len(missing)
    ec.cacheSystem.metrics.RecordBatchOperation("embedding", hitCount, missCount)
    
    return cached, missing
}

func (ec *EmbeddingCache) BatchSetEmbeddings(
    ctx context.Context,
    embeddings map[string][]float32,
    ttl time.Duration) error {
    
    entries := make(map[string][]byte)
    
    for text, embedding := range embeddings {
        key := ec.generateKey(text)
        
        // 压缩和序列化
        compressed, err := ec.compressor.Compress(embedding)
        if err != nil {
            log.Warn("向量压缩失败", zap.String("text", text), zap.Error(err))
            continue
        }
        
        entry := &EmbeddingCacheEntry{
            Text:           text,
            Embedding:      compressed,
            CreatedAt:      time.Now(),
            TTL:            ttl,
            OriginalSize:   len(embedding) * 4,
            CompressedSize: len(compressed),
        }
        
        serialized, err := json.Marshal(entry)
        if err != nil {
            log.Warn("序列化失败", zap.String("text", text), zap.Error(err))
            continue
        }
        
        entries[key] = serialized
    }
    
    // 批量存储
    return ec.cacheSystem.batchSet(entries, ttl)
}
```

### 🗜️ 向量压缩优化

```go
// internal/cache/vector_compressor.go
type VectorCompressor struct {
    config *CompressionConfig
}

type CompressionConfig struct {
    Algorithm    string  `yaml:"algorithm"`     // "quantization", "pca", "gzip"
    Precision    int     `yaml:"precision"`     // 8 (8-bit quantization)
    CompressionRatio float64 `yaml:"compression_ratio"` // 0.25 (4:1)
}

func NewVectorCompressor() *VectorCompressor {
    return &VectorCompressor{
        config: &CompressionConfig{
            Algorithm:        "quantization",
            Precision:        8,
            CompressionRatio: 0.25,
        },
    }
}

func (vc *VectorCompressor) Compress(vector []float32) ([]byte, error) {
    switch vc.config.Algorithm {
    case "quantization":
        return vc.quantizeVector(vector)
    case "pca":
        return vc.pcaCompress(vector)
    case "gzip":
        return vc.gzipCompress(vector)
    default:
        return vc.rawCompress(vector)
    }
}

func (vc *VectorCompressor) Decompress(data []byte) ([]float32, error) {
    switch vc.config.Algorithm {
    case "quantization":
        return vc.dequantizeVector(data)
    case "pca":
        return vc.pcaDecompress(data)
    case "gzip":
        return vc.gzipDecompress(data)
    default:
        return vc.rawDecompress(data)
    }
}

func (vc *VectorCompressor) quantizeVector(vector []float32) ([]byte, error) {
    if len(vector) == 0 {
        return nil, nil
    }
    
    // 找到向量的最小值和最大值
    minVal, maxVal := vector[0], vector[0]
    for _, v := range vector {
        if v < minVal {
            minVal = v
        }
        if v > maxVal {
            maxVal = v
        }
    }
    
    // 计算量化参数
    scale := (maxVal - minVal) / 255.0
    
    // 创建量化结果
    result := make([]byte, 8+len(vector)) // 8 bytes for minVal + scale, rest for quantized values
    
    // 存储量化参数
    binary.LittleEndian.PutUint32(result[0:4], math.Float32bits(minVal))
    binary.LittleEndian.PutUint32(result[4:8], math.Float32bits(scale))
    
    // 量化向量值
    for i, v := range vector {
        if scale > 0 {
            quantized := uint8((v - minVal) / scale)
            result[8+i] = quantized
        } else {
            result[8+i] = 0
        }
    }
    
    return result, nil
}

func (vc *VectorCompressor) dequantizeVector(data []byte) ([]float32, error) {
    if len(data) < 8 {
        return nil, fmt.Errorf("数据长度不足")
    }
    
    // 解析量化参数
    minVal := math.Float32frombits(binary.LittleEndian.Uint32(data[0:4]))
    scale := math.Float32frombits(binary.LittleEndian.Uint32(data[4:8]))
    
    // 反量化向量
    vectorSize := len(data) - 8
    result := make([]float32, vectorSize)
    
    for i := 0; i < vectorSize; i++ {
        quantized := data[8+i]
        result[i] = minVal + float32(quantized)*scale
    }
    
    return result, nil
}

func (vc *VectorCompressor) EstimateCompressionRatio(vector []float32) float64 {
    originalSize := len(vector) * 4 // float32 = 4 bytes
    
    switch vc.config.Algorithm {
    case "quantization":
        compressedSize := 8 + len(vector) // 8 bytes metadata + 1 byte per value
        return float64(compressedSize) / float64(originalSize)
    case "pca":
        reducedSize := int(float64(len(vector)) * vc.config.CompressionRatio)
        return float64(reducedSize*4) / float64(originalSize)
    default:
        return 1.0
    }
}
```

---

## 🏃 搜索结果缓存

### 🔍 语义缓存策略

```go
// internal/cache/search_cache.go
type SearchCache struct {
    cacheSystem     *VectorCacheSystem
    similarityCache *SimilarityCache
    resultRanker    *ResultRanker
}

type SearchCacheEntry struct {
    Query           string           `json:"query"`
    QueryVector     []float32        `json:"query_vector"`
    Results         []*SearchResult  `json:"results"`
    Metadata        *SearchMetadata  `json:"metadata"`
    CreatedAt       time.Time        `json:"created_at"`
    ExpiresAt       time.Time        `json:"expires_at"`
    AccessCount     int              `json:"access_count"`
    SimilarQueries  []string         `json:"similar_queries"`
}

type SearchMetadata struct {
    SearchType      string    `json:"search_type"`
    ConnectionID    int64     `json:"connection_id"`
    UserID          int64     `json:"user_id"`
    ResponseTime    time.Duration `json:"response_time"`
    ResultCount     int       `json:"result_count"`
    SimilarityThreshold float64 `json:"similarity_threshold"`
}

func NewSearchCache(cacheSystem *VectorCacheSystem) *SearchCache {
    return &SearchCache{
        cacheSystem:     cacheSystem,
        similarityCache: NewSimilarityCache(),
        resultRanker:    NewResultRanker(),
    }
}

func (sc *SearchCache) GetSearchResults(
    ctx context.Context,
    query string,
    queryVector []float32,
    searchType string) (*SearchCacheResult, bool) {
    
    // 1. 尝试精确匹配
    exactKey := sc.generateExactKey(query, searchType)
    if cached, exists := sc.cacheSystem.get(exactKey); exists {
        if result, ok := sc.deserializeSearchResult(cached); ok {
            sc.recordCacheHit("exact", result)
            return result, true
        }
    }
    
    // 2. 尝试语义相似匹配
    if semanticResult := sc.findSimilarCachedQuery(queryVector, searchType); semanticResult != nil {
        sc.recordCacheHit("semantic", semanticResult)
        return semanticResult, true
    }
    
    sc.recordCacheMiss(searchType)
    return nil, false
}

func (sc *SearchCache) findSimilarCachedQuery(
    queryVector []float32,
    searchType string) *SearchCacheResult {
    
    // 获取候选缓存条目
    candidates := sc.getCandidateEntries(searchType)
    
    var bestMatch *SearchCacheEntry
    var bestSimilarity float64
    
    for _, candidate := range candidates {
        // 计算语义相似度
        similarity := sc.calculateVectorSimilarity(queryVector, candidate.QueryVector)
        
        if similarity > 0.9 && similarity > bestSimilarity { // 90%以上相似度
            bestMatch = candidate
            bestSimilarity = similarity
        }
    }
    
    if bestMatch != nil {
        // 重新排序结果以适应当前查询
        rerankedResults := sc.resultRanker.RerankForQuery(bestMatch.Results, queryVector)
        
        return &SearchCacheResult{
            Results:      rerankedResults,
            Source:       "semantic_cache",
            Similarity:   bestSimilarity,
            OriginalQuery: bestMatch.Query,
            CacheAge:     time.Since(bestMatch.CreatedAt),
        }
    }
    
    return nil
}

func (sc *SearchCache) SetSearchResults(
    ctx context.Context,
    query string,
    queryVector []float32,
    results []*SearchResult,
    metadata *SearchMetadata,
    ttl time.Duration) error {
    
    entry := &SearchCacheEntry{
        Query:       query,
        QueryVector: queryVector,
        Results:     results,
        Metadata:    metadata,
        CreatedAt:   time.Now(),
        ExpiresAt:   time.Now().Add(ttl),
        AccessCount: 0,
    }
    
    // 找到相似查询以建立关联
    entry.SimilarQueries = sc.findSimilarQueries(queryVector)
    
    // 生成缓存键
    exactKey := sc.generateExactKey(query, metadata.SearchType)
    semanticKey := sc.generateSemanticKey(queryVector, metadata.SearchType)
    
    // 序列化条目
    serialized, err := json.Marshal(entry)
    if err != nil {
        return fmt.Errorf("序列化搜索结果失败: %w", err)
    }
    
    // 存储到精确匹配缓存
    if err := sc.cacheSystem.set(exactKey, serialized, ttl); err != nil {
        return err
    }
    
    // 存储到语义匹配缓存
    return sc.cacheSystem.set(semanticKey, serialized, ttl)
}

func (sc *SearchCache) InvalidateRelatedCache(
    ctx context.Context,
    connectionID int64,
    affectedTables []string) error {
    
    // 构建失效模式
    patterns := make([]string, 0, len(affectedTables))
    for _, table := range affectedTables {
        patterns = append(patterns, fmt.Sprintf("search:*:conn_%d:*table_%s*", connectionID, table))
    }
    
    // 批量失效相关缓存
    return sc.cacheSystem.invalidateByPatterns(patterns)
}

func (sc *SearchCache) generateExactKey(query, searchType string) string {
    hasher := md5.New()
    hasher.Write([]byte(fmt.Sprintf("%s:%s", query, searchType)))
    hash := hex.EncodeToString(hasher.Sum(nil))
    
    return fmt.Sprintf("search:exact:%s", hash)
}

func (sc *SearchCache) generateSemanticKey(vector []float32, searchType string) string {
    // 使用向量的hash作为语义键的一部分
    vectorHash := sc.hashVector(vector)
    return fmt.Sprintf("search:semantic:%s:%s", searchType, vectorHash)
}
```

### 📈 智能预取策略

```go
// internal/cache/prefetch_strategy.go
type PrefetchStrategy struct {
    cacheSystem    *VectorCacheSystem
    usageAnalyzer  *UsageAnalyzer
    predictor      *QueryPredictor
    scheduler      *PrefetchScheduler
}

type PrefetchConfig struct {
    Enabled         bool    `yaml:"enabled"`         // true
    PrefetchRatio   float64 `yaml:"prefetch_ratio"`  // 0.2 (20%资源用于预取)
    MinConfidence   float64 `yaml:"min_confidence"`  // 0.7
    MaxPrefetchSize int     `yaml:"max_prefetch_size"` // 100
    TriggerThreshold int    `yaml:"trigger_threshold"` // 5 (访问5次后触发预取)
}

func NewPrefetchStrategy(cacheSystem *VectorCacheSystem) *PrefetchStrategy {
    return &PrefetchStrategy{
        cacheSystem:   cacheSystem,
        usageAnalyzer: NewUsageAnalyzer(),
        predictor:     NewQueryPredictor(),
        scheduler:     NewPrefetchScheduler(),
    }
}

func (ps *PrefetchStrategy) StartPrefetching() {
    ticker := time.NewTicker(10 * time.Minute)
    defer ticker.Stop()
    
    for {
        select {
        case <-ticker.C:
            ps.performPrefetch()
        }
    }
}

func (ps *PrefetchStrategy) performPrefetch() {
    // 1. 分析用户访问模式
    patterns := ps.usageAnalyzer.AnalyzeAccessPatterns()
    
    // 2. 预测下一步可能的查询
    predictions := ps.predictor.PredictNextQueries(patterns)
    
    // 3. 选择高置信度的预测进行预取
    candidates := ps.selectPrefetchCandidates(predictions)
    
    // 4. 执行预取任务
    ps.scheduler.SchedulePrefetchTasks(candidates)
}

func (ps *PrefetchStrategy) selectPrefetchCandidates(
    predictions []*QueryPrediction) []*PrefetchCandidate {
    
    var candidates []*PrefetchCandidate
    
    for _, pred := range predictions {
        if pred.Confidence < ps.config.MinConfidence {
            continue
        }
        
        // 检查缓存中是否已存在
        if ps.isAlreadyCached(pred.Query) {
            continue
        }
        
        candidate := &PrefetchCandidate{
            Query:       pred.Query,
            QueryType:   pred.QueryType,
            Confidence:  pred.Confidence,
            Priority:    ps.calculatePriority(pred),
            EstimatedCost: ps.estimateComputationCost(pred),
        }
        
        candidates = append(candidates, candidate)
    }
    
    // 按优先级排序
    sort.Slice(candidates, func(i, j int) bool {
        return candidates[i].Priority > candidates[j].Priority
    })
    
    // 限制预取数量
    if len(candidates) > ps.config.MaxPrefetchSize {
        candidates = candidates[:ps.config.MaxPrefetchSize]
    }
    
    return candidates
}

func (ps *PrefetchStrategy) OnQueryExecuted(query string, results []*SearchResult) {
    // 记录查询执行，用于模式分析
    ps.usageAnalyzer.RecordQuery(query, results)
    
    // 触发相关查询的预取
    go ps.triggerRelatedPrefetch(query, results)
}

func (ps *PrefetchStrategy) triggerRelatedPrefetch(query string, results []*SearchResult) {
    // 基于当前查询结果，预测用户可能的后续查询
    relatedQueries := ps.predictor.PredictRelatedQueries(query, results)
    
    for _, relatedQuery := range relatedQueries {
        if !ps.isAlreadyCached(relatedQuery.Query) {
            ps.scheduler.ScheduleImmediatePrefetch(relatedQuery)
        }
    }
}
```

---

## 💡 性能优化策略

### ⚡ 批量操作优化

```go
// internal/cache/batch_operations.go
type BatchOperationManager struct {
    cacheSystem    *VectorCacheSystem
    batchConfig    *BatchConfig
    operationQueue chan *BatchOperation
    workers        []*BatchWorker
    aggregator     *OperationAggregator
}

type BatchConfig struct {
    MaxBatchSize    int           `yaml:"max_batch_size"`    // 100
    MaxWaitTime     time.Duration `yaml:"max_wait_time"`     // 10ms
    WorkerCount     int           `yaml:"worker_count"`      // 4
    AggregateWindow time.Duration `yaml:"aggregate_window"`  // 1ms
}

type BatchOperation struct {
    Type        OperationType `json:"type"`
    Keys        []string      `json:"keys"`
    Values      [][]byte      `json:"values"`
    TTL         time.Duration `json:"ttl"`
    ResponseCh  chan *BatchResponse `json:"-"`
    SubmittedAt time.Time     `json:"submitted_at"`
}

type BatchResponse struct {
    Results []interface{} `json:"results"`
    Errors  []error       `json:"errors"`
    Latency time.Duration `json:"latency"`
}

func NewBatchOperationManager(cacheSystem *VectorCacheSystem) *BatchOperationManager {
    bom := &BatchOperationManager{
        cacheSystem:    cacheSystem,
        batchConfig:    loadBatchConfig(),
        operationQueue: make(chan *BatchOperation, 1000),
        aggregator:     NewOperationAggregator(),
    }
    
    // 启动工作线程
    for i := 0; i < bom.batchConfig.WorkerCount; i++ {
        worker := NewBatchWorker(i, bom.cacheSystem, bom.operationQueue)
        bom.workers = append(bom.workers, worker)
        go worker.Start()
    }
    
    // 启动操作聚合器
    go bom.aggregator.Start()
    
    return bom
}

func (bom *BatchOperationManager) BatchGet(keys []string) (*BatchResponse, error) {
    operation := &BatchOperation{
        Type:        OperationTypeGet,
        Keys:        keys,
        ResponseCh:  make(chan *BatchResponse, 1),
        SubmittedAt: time.Now(),
    }
    
    // 提交到队列
    select {
    case bom.operationQueue <- operation:
        // 等待响应
        response := <-operation.ResponseCh
        return response, nil
    case <-time.After(bom.batchConfig.MaxWaitTime * 2):
        return nil, fmt.Errorf("批量操作超时")
    }
}

func (bom *BatchOperationManager) BatchSet(
    entries map[string][]byte,
    ttl time.Duration) (*BatchResponse, error) {
    
    keys := make([]string, 0, len(entries))
    values := make([][]byte, 0, len(entries))
    
    for key, value := range entries {
        keys = append(keys, key)
        values = append(values, value)
    }
    
    operation := &BatchOperation{
        Type:        OperationTypeSet,
        Keys:        keys,
        Values:      values,
        TTL:         ttl,
        ResponseCh:  make(chan *BatchResponse, 1),
        SubmittedAt: time.Now(),
    }
    
    select {
    case bom.operationQueue <- operation:
        response := <-operation.ResponseCh
        return response, nil
    case <-time.After(bom.batchConfig.MaxWaitTime * 2):
        return nil, fmt.Errorf("批量操作超时")
    }
}

type BatchWorker struct {
    id             int
    cacheSystem    *VectorCacheSystem
    operationQueue <-chan *BatchOperation
    batchBuffer    []*BatchOperation
    lastFlush      time.Time
}

func (bw *BatchWorker) Start() {
    ticker := time.NewTicker(1 * time.Millisecond)
    defer ticker.Stop()
    
    for {
        select {
        case operation := <-bw.operationQueue:
            bw.batchBuffer = append(bw.batchBuffer, operation)
            
            // 检查是否需要立即刷新
            if bw.shouldFlush() {
                bw.flushBatch()
            }
            
        case <-ticker.C:
            // 定期刷新
            if len(bw.batchBuffer) > 0 && time.Since(bw.lastFlush) > 5*time.Millisecond {
                bw.flushBatch()
            }
        }
    }
}

func (bw *BatchWorker) shouldFlush() bool {
    return len(bw.batchBuffer) >= 50 || // 批量大小达到阈值
           time.Since(bw.lastFlush) > 10*time.Millisecond // 等待时间达到阈值
}

func (bw *BatchWorker) flushBatch() {
    if len(bw.batchBuffer) == 0 {
        return
    }
    
    start := time.Now()
    
    // 按操作类型分组
    getBatch := make([]*BatchOperation, 0)
    setBatch := make([]*BatchOperation, 0)
    
    for _, op := range bw.batchBuffer {
        switch op.Type {
        case OperationTypeGet:
            getBatch = append(getBatch, op)
        case OperationTypeSet:
            setBatch = append(setBatch, op)
        }
    }
    
    // 执行批量GET操作
    if len(getBatch) > 0 {
        bw.executeBatchGet(getBatch)
    }
    
    // 执行批量SET操作
    if len(setBatch) > 0 {
        bw.executeBatchSet(setBatch)
    }
    
    // 清空缓冲区
    bw.batchBuffer = bw.batchBuffer[:0]
    bw.lastFlush = time.Now()
    
    // 记录批量操作指标
    bw.cacheSystem.metrics.RecordBatchFlush(len(getBatch)+len(setBatch), time.Since(start))
}
```

### 🔄 连接池优化

```go
// internal/cache/connection_pool.go
type ConnectionPoolManager struct {
    pools   map[string]*ConnectionPool
    config  *PoolConfig
    monitor *PoolMonitor
    mu      sync.RWMutex
}

type PoolConfig struct {
    // Redis连接池配置
    Redis struct {
        MaxIdle     int           `yaml:"max_idle"`     // 10
        MaxActive   int           `yaml:"max_active"`   // 100
        IdleTimeout time.Duration `yaml:"idle_timeout"` // 5m
        Wait        bool          `yaml:"wait"`         // true
        MaxConnLifetime time.Duration `yaml:"max_conn_lifetime"` // 1h
    } `yaml:"redis"`
    
    // 连接健康检查
    HealthCheck struct {
        Enabled  bool          `yaml:"enabled"`  // true
        Interval time.Duration `yaml:"interval"` // 30s
        Timeout  time.Duration `yaml:"timeout"`  // 5s
    } `yaml:"health_check"`
}

type ConnectionPool struct {
    name       string
    pool       *redis.Pool
    config     *PoolConfig
    metrics    *PoolMetrics
    healthChecker *HealthChecker
}

func NewConnectionPoolManager(config *PoolConfig) *ConnectionPoolManager {
    return &ConnectionPoolManager{
        pools:   make(map[string]*ConnectionPool),
        config:  config,
        monitor: NewPoolMonitor(),
    }
}

func (cpm *ConnectionPoolManager) GetOrCreatePool(name, address string) *ConnectionPool {
    cpm.mu.RLock()
    if pool, exists := cpm.pools[name]; exists {
        cpm.mu.RUnlock()
        return pool
    }
    cpm.mu.RUnlock()
    
    cpm.mu.Lock()
    defer cpm.mu.Unlock()
    
    // 双重检查
    if pool, exists := cpm.pools[name]; exists {
        return pool
    }
    
    // 创建新连接池
    pool := &ConnectionPool{
        name:    name,
        config:  cpm.config,
        metrics: NewPoolMetrics(name),
    }
    
    pool.pool = &redis.Pool{
        MaxIdle:         cpm.config.Redis.MaxIdle,
        MaxActive:       cpm.config.Redis.MaxActive,
        IdleTimeout:     cpm.config.Redis.IdleTimeout,
        Wait:            cpm.config.Redis.Wait,
        MaxConnLifetime: cpm.config.Redis.MaxConnLifetime,
        Dial: func() (redis.Conn, error) {
            return redis.Dial("tcp", address,
                redis.DialConnectTimeout(5*time.Second),
                redis.DialReadTimeout(3*time.Second),
                redis.DialWriteTimeout(3*time.Second),
            )
        },
        TestOnBorrow: func(c redis.Conn, t time.Time) error {
            if time.Since(t) < 30*time.Second {
                return nil
            }
            _, err := c.Do("PING")
            return err
        },
    }
    
    // 启动健康检查
    if cpm.config.HealthCheck.Enabled {
        pool.healthChecker = NewHealthChecker(pool)
        go pool.healthChecker.Start()
    }
    
    cpm.pools[name] = pool
    return pool
}

func (cp *ConnectionPool) GetConnection() redis.Conn {
    start := time.Now()
    conn := cp.pool.Get()
    
    // 记录获取连接的延迟
    cp.metrics.RecordConnectionAcquisition(time.Since(start))
    
    return &instrumentedConnection{
        Conn:    conn,
        pool:    cp,
        startTime: time.Now(),
    }
}

type instrumentedConnection struct {
    redis.Conn
    pool      *ConnectionPool
    startTime time.Time
}

func (ic *instrumentedConnection) Close() error {
    // 记录连接使用时间
    ic.pool.metrics.RecordConnectionUsage(time.Since(ic.startTime))
    
    return ic.Conn.Close()
}

func (ic *instrumentedConnection) Do(commandName string, args ...interface{}) (interface{}, error) {
    start := time.Now()
    result, err := ic.Conn.Do(commandName, args...)
    duration := time.Since(start)
    
    // 记录命令执行指标
    ic.pool.metrics.RecordCommand(commandName, duration, err == nil)
    
    return result, err
}
```

---

## 📊 性能监控系统

### 📈 缓存指标监控

```go
// internal/cache/cache_metrics.go
type CacheMetrics struct {
    // 基础指标
    hitCount    *prometheus.CounterVec
    missCount   *prometheus.CounterVec
    setCount    *prometheus.CounterVec
    deleteCount *prometheus.CounterVec
    
    // 延迟指标
    operationDuration *prometheus.HistogramVec
    cacheSize         *prometheus.GaugeVec
    
    // 命中率指标
    hitRate    *prometheus.GaugeVec
    missRate   *prometheus.GaugeVec
    
    // 内存使用指标
    memoryUsage    *prometheus.GaugeVec
    evictionCount  *prometheus.CounterVec
    
    // 批量操作指标
    batchOperationDuration *prometheus.HistogramVec
    batchSize              *prometheus.HistogramVec
}

func NewCacheMetrics() *CacheMetrics {
    return &CacheMetrics{
        hitCount: prometheus.NewCounterVec(
            prometheus.CounterOpts{
                Name: "cache_hits_total",
                Help: "Total cache hits",
            },
            []string{"cache_type", "cache_level"},
        ),
        missCount: prometheus.NewCounterVec(
            prometheus.CounterOpts{
                Name: "cache_misses_total",
                Help: "Total cache misses",
            },
            []string{"cache_type", "cache_level"},
        ),
        operationDuration: prometheus.NewHistogramVec(
            prometheus.HistogramOpts{
                Name: "cache_operation_duration_seconds",
                Help: "Cache operation duration",
                Buckets: []float64{0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1},
            },
            []string{"operation", "cache_level"},
        ),
        cacheSize: prometheus.NewGaugeVec(
            prometheus.GaugeOpts{
                Name: "cache_size_entries",
                Help: "Current cache size in entries",
            },
            []string{"cache_type", "cache_level"},
        ),
        hitRate: prometheus.NewGaugeVec(
            prometheus.GaugeOpts{
                Name: "cache_hit_rate",
                Help: "Cache hit rate",
            },
            []string{"cache_type", "cache_level"},
        ),
    }
}

func (cm *CacheMetrics) RecordHit(cacheType string, level int) {
    cm.hitCount.WithLabelValues(cacheType, fmt.Sprintf("L%d", level)).Inc()
    cm.updateHitRate(cacheType, level)
}

func (cm *CacheMetrics) RecordMiss(cacheType string, level int) {
    cm.missCount.WithLabelValues(cacheType, fmt.Sprintf("L%d", level)).Inc()
    cm.updateHitRate(cacheType, level)
}

func (cm *CacheMetrics) updateHitRate(cacheType string, level int) {
    levelStr := fmt.Sprintf("L%d", level)
    
    hits := getCounterValue(cm.hitCount.WithLabelValues(cacheType, levelStr))
    misses := getCounterValue(cm.missCount.WithLabelValues(cacheType, levelStr))
    
    if hits+misses > 0 {
        hitRate := hits / (hits + misses)
        cm.hitRate.WithLabelValues(cacheType, levelStr).Set(hitRate)
    }
}

// 性能报告生成
func (cm *CacheMetrics) GeneratePerformanceReport() *PerformanceReport {
    report := &PerformanceReport{
        Timestamp: time.Now(),
        Metrics:   make(map[string]interface{}),
    }
    
    // 收集L1缓存指标
    l1Metrics := cm.collectL1Metrics()
    report.Metrics["l1_cache"] = l1Metrics
    
    // 收集L2缓存指标
    l2Metrics := cm.collectL2Metrics()
    report.Metrics["l2_cache"] = l2Metrics
    
    // 收集L3缓存指标
    l3Metrics := cm.collectL3Metrics()
    report.Metrics["l3_cache"] = l3Metrics
    
    // 计算整体性能指标
    overallMetrics := cm.calculateOverallMetrics(l1Metrics, l2Metrics, l3Metrics)
    report.Metrics["overall"] = overallMetrics
    
    return report
}
```

### 📋 Grafana仪表板

```yaml
# monitoring/grafana/cache-dashboard.yaml
dashboard:
  title: "向量缓存性能监控"
  panels:
    - title: "缓存命中率"
      type: "graph"
      targets:
        - expr: "cache_hit_rate"
          legendFormat: "{{cache_type}} - {{cache_level}}"
      yAxes:
        - min: 0
          max: 1
          unit: "percentunit"
    
    - title: "缓存操作延迟"
      type: "graph"
      targets:
        - expr: "histogram_quantile(0.95, rate(cache_operation_duration_seconds_bucket[5m]))"
          legendFormat: "P95延迟"
        - expr: "histogram_quantile(0.50, rate(cache_operation_duration_seconds_bucket[5m]))"
          legendFormat: "P50延迟"
      yAxes:
        - unit: "s"
    
    - title: "缓存大小"
      type: "graph"
      targets:
        - expr: "cache_size_entries"
          legendFormat: "{{cache_type}} - {{cache_level}}"
      yAxes:
        - unit: "short"
    
    - title: "内存使用率"
      type: "singlestat"
      targets:
        - expr: "sum(cache_memory_usage_bytes) / sum(cache_memory_limit_bytes)"
      valueMaps:
        - value: "null"
          text: "N/A"
      thresholds: "0.7,0.9"
      colors: ["green", "yellow", "red"]
      format: "percentunit"
```

---

## 🛠️ 调优建议

### 1. 缓存配置优化

```yaml
# config/cache_optimization.yaml
cache_tuning:
  # L1内存缓存优化
  l1_optimization:
    max_size: 10000           # 根据内存容量调整
    evict_policy: "lru"       # LRU最适合热点数据
    ttl: "1h"                 # 短TTL保证数据新鲜度
    
  # L2 Redis缓存优化  
  l2_optimization:
    connection_pool_size: 100  # 根据并发量调整
    max_retries: 3
    retry_delay: "100ms"
    compression: true          # 启用压缩节省网络带宽
    
  # L3持久化缓存优化
  l3_optimization:
    storage_path: "/ssd/cache" # 使用SSD提升性能
    compression: true
    background_cleanup: true
    
  # 预热策略优化
  warmup_optimization:
    common_queries_file: "common_queries.txt"
    warmup_concurrency: 5
    warmup_timeout: "30s"
```

### 2. 监控告警配置

```yaml
# config/cache_alerts.yaml
cache_alerts:
  hit_rate_low:
    threshold: 0.7
    severity: "warning"
    duration: "5m"
    
  memory_usage_high:
    threshold: 0.85
    severity: "critical"
    duration: "2m"
    
  latency_high:
    threshold: "50ms"
    severity: "warning"
    duration: "5m"
    
  error_rate_high:
    threshold: 0.05
    severity: "critical"
    duration: "1m"
```

---

<div align="center">

**⚡ 向量缓存成功关键：多层架构 + 智能预取 + 性能监控**

</div>