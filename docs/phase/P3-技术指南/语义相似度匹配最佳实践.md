# ğŸ¯ è¯­ä¹‰ç›¸ä¼¼åº¦åŒ¹é…æœ€ä½³å®è·µ

<div align="center">

![Semantic Similarity](https://img.shields.io/badge/Semantic_Similarity-Best_Practices-blue.svg)
![Accuracy](https://img.shields.io/badge/Accuracy-90%25+-green.svg)
![Algorithm](https://img.shields.io/badge/Algorithm-Cosine_Similarity-orange.svg)

**Chat2SQL P3é˜¶æ®µ - è¯­ä¹‰ç›¸ä¼¼åº¦åŒ¹é…ç®—æ³•ä¼˜åŒ–ä¸æœ€ä½³å®è·µæŒ‡å—**

</div>

## ğŸ“‹ æ¦‚è¿°

æœ¬æ–‡æ¡£ä¸“é—¨é’ˆå¯¹Chat2SQLç³»ç»Ÿä¸­è¯­ä¹‰ç›¸ä¼¼åº¦åŒ¹é…çš„ç®—æ³•é€‰æ‹©ã€å‚æ•°è°ƒä¼˜ã€å‡†ç¡®ç‡æå‡å’ŒA/Bæµ‹è¯•ç­–ç•¥ï¼Œæä¾›ç§‘å­¦çš„ç›¸ä¼¼åº¦åŒ¹é…è§£å†³æ–¹æ¡ˆã€‚

## ğŸ¯ åŒ¹é…ç›®æ ‡

### æ ¸å¿ƒæŒ‡æ ‡
- âœ… **åŒ¹é…å‡†ç¡®ç‡**ï¼šSchemaåŒ¹é… > 90%ï¼ŒæŸ¥è¯¢åŒ¹é… > 85%
- âœ… **å¬å›ç‡**ï¼šç›¸å…³ç»“æœå‘ç°ç‡ > 95%
- âœ… **ç²¾ç¡®ç‡**ï¼šæ— å…³ç»“æœè¿‡æ»¤ç‡ > 90%
- âœ… **å“åº”æ—¶é—´**ï¼šç›¸ä¼¼åº¦è®¡ç®— < 10ms

### ä¸šåŠ¡åœºæ™¯
| åŒ¹é…åœºæ™¯ | ç›¸ä¼¼åº¦é˜ˆå€¼ | å‡†ç¡®ç‡è¦æ±‚ | åº”ç”¨ç­–ç•¥ |
|---------|-----------|----------|----------|
| **Schemaç²¾ç¡®åŒ¹é…** | > 0.85 | > 95% | é«˜ç²¾åº¦ç­–ç•¥ |
| **æŸ¥è¯¢å†å²æ£€ç´¢** | > 0.75 | > 85% | å¹³è¡¡ç­–ç•¥ |
| **ä¸Šä¸‹æ–‡æ¨è** | > 0.65 | > 80% | é«˜å¬å›ç­–ç•¥ |

---

## ğŸ§® ç›¸ä¼¼åº¦ç®—æ³•å®ç°

### ğŸ“Š å¤šç®—æ³•æ”¯æŒæ¶æ„

```go
// internal/similarity/similarity_engine.go
package similarity

import (
    "math"
    "sort"
)

type SimilarityEngine struct {
    config    *SimilarityConfig
    metrics   *SimilarityMetrics
    algorithms map[AlgorithmType]SimilarityAlgorithm
}

type SimilarityConfig struct {
    // é»˜è®¤ç®—æ³•
    DefaultAlgorithm AlgorithmType `yaml:"default_algorithm"` // "cosine"
    
    // ç®—æ³•ç‰¹å®šé…ç½®
    Cosine struct {
        NormalizationEnabled bool `yaml:"normalization_enabled"` // true
    } `yaml:"cosine"`
    
    Euclidean struct {
        MaxDistance float64 `yaml:"max_distance"` // 2.0
    } `yaml:"euclidean"`
    
    Dot struct {
        NormalizationRequired bool `yaml:"normalization_required"` // true
    } `yaml:"dot"`
    
    // æ··åˆç®—æ³•
    Hybrid struct {
        Enabled     bool            `yaml:"enabled"`      // false
        Weights     map[string]float64 `yaml:"weights"`   // {"cosine": 0.7, "jaccard": 0.3}
        Aggregation string          `yaml:"aggregation"`  // "weighted_average"
    } `yaml:"hybrid"`
}

type AlgorithmType string

const (
    CosineSimilarity     AlgorithmType = "cosine"
    EuclideanSimilarity  AlgorithmType = "euclidean"
    DotProductSimilarity AlgorithmType = "dot_product"
    JaccardSimilarity    AlgorithmType = "jaccard"
    HybridSimilarity     AlgorithmType = "hybrid"
)

type SimilarityAlgorithm interface {
    Calculate(vec1, vec2 []float32) (float64, error)
    Name() string
    RequiresNormalization() bool
}
```

### ğŸ”¢ ä½™å¼¦ç›¸ä¼¼åº¦å®ç°

```go
// internal/similarity/cosine.go
type CosineSimilarityAlgorithm struct {
    config *SimilarityConfig
}

func NewCosineSimilarityAlgorithm(config *SimilarityConfig) *CosineSimilarityAlgorithm {
    return &CosineSimilarityAlgorithm{config: config}
}

func (csa *CosineSimilarityAlgorithm) Calculate(vec1, vec2 []float32) (float64, error) {
    if len(vec1) != len(vec2) {
        return 0, fmt.Errorf("å‘é‡ç»´åº¦ä¸åŒ¹é…: %d vs %d", len(vec1), len(vec2))
    }
    
    if len(vec1) == 0 {
        return 0, fmt.Errorf("å‘é‡ä¸ºç©º")
    }
    
    // è®¡ç®—ç‚¹ç§¯å’Œæ¨¡é•¿
    var dotProduct, norm1, norm2 float64
    
    for i := 0; i < len(vec1); i++ {
        v1, v2 := float64(vec1[i]), float64(vec2[i])
        dotProduct += v1 * v2
        norm1 += v1 * v1
        norm2 += v2 * v2
    }
    
    // å¤„ç†é›¶å‘é‡
    if norm1 == 0 || norm2 == 0 {
        return 0, nil
    }
    
    // è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
    similarity := dotProduct / (math.Sqrt(norm1) * math.Sqrt(norm2))
    
    // ç¡®ä¿ç»“æœåœ¨[0,1]èŒƒå›´å†…
    similarity = math.Max(0, math.Min(1, similarity))
    
    return similarity, nil
}

func (csa *CosineSimilarityAlgorithm) Name() string {
    return "cosine"
}

func (csa *CosineSimilarityAlgorithm) RequiresNormalization() bool {
    return false // ä½™å¼¦ç›¸ä¼¼åº¦æœ¬èº«å°±æ˜¯å½’ä¸€åŒ–çš„
}

// æ‰¹é‡è®¡ç®—ä¼˜åŒ–ç‰ˆæœ¬
func (csa *CosineSimilarityAlgorithm) BatchCalculate(
    queryVec []float32,
    candidateVecs [][]float32) ([]float64, error) {
    
    if len(candidateVecs) == 0 {
        return nil, nil
    }
    
    results := make([]float64, len(candidateVecs))
    
    // é¢„è®¡ç®—æŸ¥è¯¢å‘é‡çš„æ¨¡é•¿
    var queryNorm float64
    for _, v := range queryVec {
        queryNorm += float64(v) * float64(v)
    }
    queryNorm = math.Sqrt(queryNorm)
    
    if queryNorm == 0 {
        return results, nil // å…¨éƒ¨è¿”å›0
    }
    
    // å¹¶è¡Œè®¡ç®—ç›¸ä¼¼åº¦
    for i, candidateVec := range candidateVecs {
        if len(candidateVec) != len(queryVec) {
            results[i] = 0
            continue
        }
        
        var dotProduct, candidateNorm float64
        for j := 0; j < len(queryVec); j++ {
            qv, cv := float64(queryVec[j]), float64(candidateVec[j])
            dotProduct += qv * cv
            candidateNorm += cv * cv
        }
        
        candidateNorm = math.Sqrt(candidateNorm)
        if candidateNorm == 0 {
            results[i] = 0
        } else {
            similarity := dotProduct / (queryNorm * candidateNorm)
            results[i] = math.Max(0, math.Min(1, similarity))
        }
    }
    
    return results, nil
}
```

### ğŸ”„ æ··åˆç›¸ä¼¼åº¦ç®—æ³•

```go
// internal/similarity/hybrid.go
type HybridSimilarityAlgorithm struct {
    config     *SimilarityConfig
    algorithms map[string]SimilarityAlgorithm
    weights    map[string]float64
}

func NewHybridSimilarityAlgorithm(
    config *SimilarityConfig,
    algorithms map[string]SimilarityAlgorithm) *HybridSimilarityAlgorithm {
    
    return &HybridSimilarityAlgorithm{
        config:     config,
        algorithms: algorithms,
        weights:    config.Hybrid.Weights,
    }
}

func (hsa *HybridSimilarityAlgorithm) Calculate(vec1, vec2 []float32) (float64, error) {
    var weightedSum float64
    var totalWeight float64
    
    for algName, algorithm := range hsa.algorithms {
        weight, exists := hsa.weights[algName]
        if !exists {
            continue
        }
        
        similarity, err := algorithm.Calculate(vec1, vec2)
        if err != nil {
            // è®°å½•é”™è¯¯ä½†ç»§ç»­è®¡ç®—å…¶ä»–ç®—æ³•
            log.Warn("æ··åˆç®—æ³•è®¡ç®—å¤±è´¥", 
                zap.String("algorithm", algName), 
                zap.Error(err))
            continue
        }
        
        weightedSum += similarity * weight
        totalWeight += weight
    }
    
    if totalWeight == 0 {
        return 0, fmt.Errorf("æ²¡æœ‰æœ‰æ•ˆçš„ç›¸ä¼¼åº¦ç®—æ³•")
    }
    
    return weightedSum / totalWeight, nil
}

func (hsa *HybridSimilarityAlgorithm) CalculateWithDetails(
    vec1, vec2 []float32) (*DetailedSimilarity, error) {
    
    details := &DetailedSimilarity{
        AlgorithmResults: make(map[string]float64),
    }
    
    var weightedSum float64
    var totalWeight float64
    
    for algName, algorithm := range hsa.algorithms {
        weight, exists := hsa.weights[algName]
        if !exists {
            continue
        }
        
        similarity, err := algorithm.Calculate(vec1, vec2)
        if err != nil {
            details.Errors = append(details.Errors, 
                fmt.Sprintf("%s: %v", algName, err))
            continue
        }
        
        details.AlgorithmResults[algName] = similarity
        weightedSum += similarity * weight
        totalWeight += weight
    }
    
    if totalWeight == 0 {
        return details, fmt.Errorf("æ²¡æœ‰æœ‰æ•ˆçš„ç›¸ä¼¼åº¦ç®—æ³•")
    }
    
    details.FinalSimilarity = weightedSum / totalWeight
    details.UsedAlgorithms = len(details.AlgorithmResults)
    
    return details, nil
}

type DetailedSimilarity struct {
    FinalSimilarity   float64             `json:"final_similarity"`
    AlgorithmResults  map[string]float64  `json:"algorithm_results"`
    UsedAlgorithms    int                 `json:"used_algorithms"`
    Errors           []string             `json:"errors,omitempty"`
}
```

---

## ğŸ“ˆ é˜ˆå€¼åŠ¨æ€è°ƒä¼˜

### ğŸ›ï¸ è‡ªé€‚åº”é˜ˆå€¼è°ƒæ•´

```go
// internal/similarity/adaptive_threshold.go
type AdaptiveThresholdManager struct {
    config         *AdaptiveConfig
    metrics        *ThresholdMetrics
    thresholds     map[string]*ThresholdState
    evaluator      *ThresholdEvaluator
    mu             sync.RWMutex
}

type AdaptiveConfig struct {
    // åŸºç¡€é…ç½®
    Enabled              bool    `yaml:"enabled"`               // true
    EvaluationInterval   time.Duration `yaml:"evaluation_interval"` // 1h
    MinSamples          int     `yaml:"min_samples"`           // 100
    
    // è°ƒæ•´ç­–ç•¥
    AdjustmentStep      float64 `yaml:"adjustment_step"`       // 0.05
    MaxAdjustment       float64 `yaml:"max_adjustment"`        // 0.2
    StabilityThreshold  float64 `yaml:"stability_threshold"`   // 0.02
    
    // ç›®æ ‡æŒ‡æ ‡
    TargetPrecision     float64 `yaml:"target_precision"`      // 0.9
    TargetRecall        float64 `yaml:"target_recall"`         // 0.85
    TargetF1Score       float64 `yaml:"target_f1_score"`       // 0.875
}

type ThresholdState struct {
    CurrentThreshold  float64   `json:"current_threshold"`
    OriginalThreshold float64   `json:"original_threshold"`
    LastAdjustment    time.Time `json:"last_adjustment"`
    AdjustmentHistory []ThresholdAdjustment `json:"adjustment_history"`
    Performance       *ThresholdPerformance `json:"performance"`
    StabilityCounter  int       `json:"stability_counter"`
}

type ThresholdAdjustment struct {
    Timestamp        time.Time `json:"timestamp"`
    OldThreshold     float64   `json:"old_threshold"`
    NewThreshold     float64   `json:"new_threshold"`
    Reason           string    `json:"reason"`
    PerformanceDelta *PerformanceDelta `json:"performance_delta"`
}

func NewAdaptiveThresholdManager(config *AdaptiveConfig) *AdaptiveThresholdManager {
    return &AdaptiveThresholdManager{
        config:     config,
        metrics:    NewThresholdMetrics(),
        thresholds: make(map[string]*ThresholdState),
        evaluator:  NewThresholdEvaluator(),
    }
}

func (atm *AdaptiveThresholdManager) StartAdaptation() {
    if !atm.config.Enabled {
        return
    }
    
    ticker := time.NewTicker(atm.config.EvaluationInterval)
    defer ticker.Stop()
    
    for {
        select {
        case <-ticker.C:
            atm.evaluateAndAdjustThresholds()
        }
    }
}

func (atm *AdaptiveThresholdManager) evaluateAndAdjustThresholds() {
    atm.mu.Lock()
    defer atm.mu.Unlock()
    
    for searchType, state := range atm.thresholds {
        // æ”¶é›†æ€§èƒ½æ•°æ®
        performance, err := atm.evaluator.EvaluateThreshold(searchType, state.CurrentThreshold)
        if err != nil {
            log.Error("é˜ˆå€¼è¯„ä¼°å¤±è´¥", 
                zap.String("search_type", searchType), 
                zap.Error(err))
            continue
        }
        
        // æ£€æŸ¥æ˜¯å¦éœ€è¦è°ƒæ•´
        adjustment := atm.calculateAdjustment(performance)
        if adjustment == 0 {
            state.StabilityCounter++
            continue
        }
        
        // åº”ç”¨è°ƒæ•´
        oldThreshold := state.CurrentThreshold
        newThreshold := atm.applyAdjustment(state.CurrentThreshold, adjustment)
        
        // éªŒè¯è°ƒæ•´çš„æœ‰æ•ˆæ€§
        if atm.validateAdjustment(oldThreshold, newThreshold, performance) {
            atm.recordThresholdAdjustment(state, oldThreshold, newThreshold, adjustment, performance)
            state.CurrentThreshold = newThreshold
            state.StabilityCounter = 0
            
            log.Info("é˜ˆå€¼è°ƒæ•´", 
                zap.String("search_type", searchType),
                zap.Float64("old_threshold", oldThreshold),
                zap.Float64("new_threshold", newThreshold),
                zap.Float64("adjustment", adjustment))
        }
    }
}

func (atm *AdaptiveThresholdManager) calculateAdjustment(performance *ThresholdPerformance) float64 {
    // è®¡ç®—å½“å‰æ€§èƒ½ä¸ç›®æ ‡çš„å·®è·
    precisionGap := performance.Precision - atm.config.TargetPrecision
    recallGap := performance.Recall - atm.config.TargetRecall
    f1Gap := performance.F1Score - atm.config.TargetF1Score
    
    // æƒé‡åˆ†é…
    const (
        precisionWeight = 0.4
        recallWeight    = 0.4
        f1Weight        = 0.2
    )
    
    // è®¡ç®—ç»¼åˆè°ƒæ•´ä¿¡å·
    adjustmentSignal := precisionWeight*precisionGap + 
                       recallWeight*recallGap + 
                       f1Weight*f1Gap
    
    // å†³å®šè°ƒæ•´æ–¹å‘å’Œå¤§å°
    var adjustment float64
    
    if math.Abs(adjustmentSignal) < atm.config.StabilityThreshold {
        // æ€§èƒ½ç¨³å®šï¼Œä¸éœ€è¦è°ƒæ•´
        return 0
    }
    
    if adjustmentSignal > 0 {
        // æ€§èƒ½è¶…è¿‡ç›®æ ‡ï¼Œå¯ä»¥é€‚å½“é™ä½é˜ˆå€¼ä»¥æé«˜å¬å›ç‡
        adjustment = -atm.config.AdjustmentStep
    } else {
        // æ€§èƒ½ä½äºç›®æ ‡ï¼Œéœ€è¦æé«˜é˜ˆå€¼ä»¥æé«˜ç²¾ç¡®ç‡
        adjustment = atm.config.AdjustmentStep
    }
    
    // é™åˆ¶è°ƒæ•´å¹…åº¦
    if math.Abs(adjustment) > atm.config.MaxAdjustment {
        if adjustment > 0 {
            adjustment = atm.config.MaxAdjustment
        } else {
            adjustment = -atm.config.MaxAdjustment
        }
    }
    
    return adjustment
}

func (atm *AdaptiveThresholdManager) applyAdjustment(currentThreshold, adjustment float64) float64 {
    newThreshold := currentThreshold + adjustment
    
    // ç¡®ä¿é˜ˆå€¼åœ¨åˆç†èŒƒå›´å†…
    const (
        minThreshold = 0.1
        maxThreshold = 0.95
    )
    
    if newThreshold < minThreshold {
        newThreshold = minThreshold
    } else if newThreshold > maxThreshold {
        newThreshold = maxThreshold
    }
    
    return newThreshold
}
```

### ğŸ“Š A/Bæµ‹è¯•æ¡†æ¶

```go
// internal/similarity/ab_testing.go
type ABTestingFramework struct {
    config       *ABTestConfig
    experiments  map[string]*Experiment
    splitter     *TrafficSplitter
    analyzer     *ResultAnalyzer
    mu           sync.RWMutex
}

type ABTestConfig struct {
    Enabled              bool          `yaml:"enabled"`               // true
    DefaultTrafficSplit  float64       `yaml:"default_traffic_split"` // 0.5
    MinSampleSize        int           `yaml:"min_sample_size"`       // 1000
    TestDuration         time.Duration `yaml:"test_duration"`         // 168h (7å¤©)
    SignificanceLevel    float64       `yaml:"significance_level"`    // 0.05
}

type Experiment struct {
    ID               string           `json:"id"`
    Name             string           `json:"name"`
    Description      string           `json:"description"`
    Status           ExperimentStatus `json:"status"`
    StartTime        time.Time        `json:"start_time"`
    EndTime          time.Time        `json:"end_time"`
    
    // å®éªŒé…ç½®
    ControlGroup     *ExperimentGroup `json:"control_group"`
    TreatmentGroups  []*ExperimentGroup `json:"treatment_groups"`
    TrafficSplit     map[string]float64 `json:"traffic_split"`
    
    // ç»“æœç»Ÿè®¡
    Results          *ExperimentResults `json:"results"`
    
    // å…ƒæ•°æ®
    CreatedBy        string    `json:"created_by"`
    UpdatedAt        time.Time `json:"updated_at"`
}

type ExperimentGroup struct {
    Name             string                 `json:"name"`
    SimilarityConfig *SimilarityConfig      `json:"similarity_config"`
    ThresholdConfig  map[string]float64     `json:"threshold_config"`
    Participants     int                    `json:"participants"`
    Metrics          *GroupMetrics          `json:"metrics"`
}

type ExperimentResults struct {
    SampleSize       map[string]int         `json:"sample_size"`
    Metrics          map[string]*GroupMetrics `json:"metrics"`
    StatisticalTests map[string]*StatTest   `json:"statistical_tests"`
    Winner           string                 `json:"winner"`
    Confidence       float64               `json:"confidence"`
    Summary          string                `json:"summary"`
}

func (abt *ABTestingFramework) CreateExperiment(config *ExperimentConfig) (*Experiment, error) {
    abt.mu.Lock()
    defer abt.mu.Unlock()
    
    experiment := &Experiment{
        ID:          generateExperimentID(),
        Name:        config.Name,
        Description: config.Description,
        Status:      ExperimentStatusPending,
        CreatedBy:   config.CreatedBy,
        UpdatedAt:   time.Now(),
        
        ControlGroup:    config.ControlGroup,
        TreatmentGroups: config.TreatmentGroups,
        TrafficSplit:    config.TrafficSplit,
    }
    
    // éªŒè¯å®éªŒé…ç½®
    if err := abt.validateExperiment(experiment); err != nil {
        return nil, err
    }
    
    abt.experiments[experiment.ID] = experiment
    
    log.Info("A/Bæµ‹è¯•å®éªŒåˆ›å»º", 
        zap.String("experiment_id", experiment.ID),
        zap.String("name", experiment.Name))
    
    return experiment, nil
}

func (abt *ABTestingFramework) StartExperiment(experimentID string) error {
    abt.mu.Lock()
    defer abt.mu.Unlock()
    
    experiment, exists := abt.experiments[experimentID]
    if !exists {
        return fmt.Errorf("å®éªŒä¸å­˜åœ¨: %s", experimentID)
    }
    
    experiment.Status = ExperimentStatusRunning
    experiment.StartTime = time.Now()
    experiment.EndTime = experiment.StartTime.Add(abt.config.TestDuration)
    
    // é…ç½®æµé‡åˆ†é…
    abt.splitter.ConfigureExperiment(experiment)
    
    log.Info("A/Bæµ‹è¯•å®éªŒå¯åŠ¨", 
        zap.String("experiment_id", experimentID),
        zap.Time("end_time", experiment.EndTime))
    
    return nil
}

func (abt *ABTestingFramework) GetAssignedGroup(
    experimentID string, 
    userID int64) (*ExperimentGroup, error) {
    
    experiment, exists := abt.experiments[experimentID]
    if !exists {
        return nil, fmt.Errorf("å®éªŒä¸å­˜åœ¨: %s", experimentID)
    }
    
    if experiment.Status != ExperimentStatusRunning {
        return experiment.ControlGroup, nil // é»˜è®¤ä½¿ç”¨å¯¹ç…§ç»„
    }
    
    // æ ¹æ®ç”¨æˆ·IDè¿›è¡Œåˆ†ç»„
    groupName := abt.splitter.AssignGroup(experimentID, userID)
    
    if groupName == experiment.ControlGroup.Name {
        return experiment.ControlGroup, nil
    }
    
    for _, group := range experiment.TreatmentGroups {
        if group.Name == groupName {
            return group, nil
        }
    }
    
    return experiment.ControlGroup, nil // é»˜è®¤è¿”å›å¯¹ç…§ç»„
}

func (abt *ABTestingFramework) RecordExperimentResult(
    experimentID string,
    groupName string,
    result *SearchResult) error {
    
    experiment, exists := abt.experiments[experimentID]
    if !exists || experiment.Status != ExperimentStatusRunning {
        return nil // å¿½ç•¥ä¸å­˜åœ¨æˆ–æœªè¿è¡Œçš„å®éªŒ
    }
    
    // æ›´æ–°å¯¹åº”ç»„çš„æŒ‡æ ‡
    var targetGroup *ExperimentGroup
    if experiment.ControlGroup.Name == groupName {
        targetGroup = experiment.ControlGroup
    } else {
        for _, group := range experiment.TreatmentGroups {
            if group.Name == groupName {
                targetGroup = group
                break
            }
        }
    }
    
    if targetGroup == nil {
        return fmt.Errorf("å®éªŒç»„ä¸å­˜åœ¨: %s", groupName)
    }
    
    // æ›´æ–°æŒ‡æ ‡
    targetGroup.Participants++
    abt.updateGroupMetrics(targetGroup, result)
    
    return nil
}

func (abt *ABTestingFramework) AnalyzeExperiment(experimentID string) (*ExperimentResults, error) {
    experiment, exists := abt.experiments[experimentID]
    if !exists {
        return nil, fmt.Errorf("å®éªŒä¸å­˜åœ¨: %s", experimentID)
    }
    
    // æ£€æŸ¥æ ·æœ¬é‡æ˜¯å¦è¶³å¤Ÿ
    totalSamples := experiment.ControlGroup.Participants
    for _, group := range experiment.TreatmentGroups {
        totalSamples += group.Participants
    }
    
    if totalSamples < abt.config.MinSampleSize {
        return nil, fmt.Errorf("æ ·æœ¬é‡ä¸è¶³: %d < %d", totalSamples, abt.config.MinSampleSize)
    }
    
    // æ‰§è¡Œç»Ÿè®¡åˆ†æ
    results := &ExperimentResults{
        SampleSize: make(map[string]int),
        Metrics:    make(map[string]*GroupMetrics),
        StatisticalTests: make(map[string]*StatTest),
    }
    
    // æ”¶é›†å„ç»„æ•°æ®
    results.SampleSize[experiment.ControlGroup.Name] = experiment.ControlGroup.Participants
    results.Metrics[experiment.ControlGroup.Name] = experiment.ControlGroup.Metrics
    
    for _, group := range experiment.TreatmentGroups {
        results.SampleSize[group.Name] = group.Participants
        results.Metrics[group.Name] = group.Metrics
        
        // æ‰§è¡Œç»Ÿè®¡æ£€éªŒ
        statTest := abt.analyzer.PerformTTest(
            experiment.ControlGroup.Metrics,
            group.Metrics,
            abt.config.SignificanceLevel,
        )
        results.StatisticalTests[group.Name] = statTest
    }
    
    // ç¡®å®šè·èƒœè€…
    winner, confidence := abt.determineWinner(results)
    results.Winner = winner
    results.Confidence = confidence
    results.Summary = abt.generateResultSummary(results)
    
    experiment.Results = results
    
    return results, nil
}
```

---

## ğŸ“ ç›¸ä¼¼åº¦è¯„ä¼°ä½“ç³»

### ğŸ¯ è¯„ä¼°æŒ‡æ ‡å®šä¹‰

```go
// internal/similarity/evaluation.go
type SimilarityEvaluator struct {
    groundTruth  map[string]*GroundTruthDataset
    metrics      *EvaluationMetrics
    testSuite    []*EvaluationCase
}

type GroundTruthDataset struct {
    Name        string                    `json:"name"`
    Description string                    `json:"description"`
    TestCases   []*GroundTruthCase       `json:"test_cases"`
    CreatedAt   time.Time                `json:"created_at"`
    UpdatedAt   time.Time                `json:"updated_at"`
}

type GroundTruthCase struct {
    ID              string    `json:"id"`
    Query           string    `json:"query"`
    RelevantItems   []string  `json:"relevant_items"`
    IrrelevantItems []string  `json:"irrelevant_items"`
    ExpectedRanking []string  `json:"expected_ranking"`
    Difficulty      int       `json:"difficulty"`  // 1-5
    Domain          string    `json:"domain"`
    Tags            []string  `json:"tags"`
}

type EvaluationMetrics struct {
    // åŸºç¡€æŒ‡æ ‡
    Precision    float64 `json:"precision"`
    Recall       float64 `json:"recall"`
    F1Score      float64 `json:"f1_score"`
    
    // æ’åºæŒ‡æ ‡
    MAP          float64 `json:"map"`          // Mean Average Precision
    NDCG         float64 `json:"ndcg"`         // Normalized Discounted Cumulative Gain
    MRR          float64 `json:"mrr"`          // Mean Reciprocal Rank
    
    // é˜ˆå€¼ç›¸å…³æŒ‡æ ‡
    OptimalThreshold float64 `json:"optimal_threshold"`
    ThresholdPrecision map[string]float64 `json:"threshold_precision"`
    ThresholdRecall    map[string]float64 `json:"threshold_recall"`
    
    // æ€§èƒ½æŒ‡æ ‡
    AvgLatency   time.Duration `json:"avg_latency"`
    Throughput   float64       `json:"throughput"`
}

func (se *SimilarityEvaluator) RunComprehensiveEvaluation(
    algorithm SimilarityAlgorithm,
    thresholds []float64) (*ComprehensiveEvaluation, error) {
    
    evaluation := &ComprehensiveEvaluation{
        Algorithm:     algorithm.Name(),
        StartTime:     time.Now(),
        TestCases:     len(se.testSuite),
        Thresholds:    thresholds,
    }
    
    // å¯¹æ¯ä¸ªé˜ˆå€¼è¿›è¡Œè¯„ä¼°
    for _, threshold := range thresholds {
        thresholdResult := se.evaluateThreshold(algorithm, threshold)
        evaluation.ThresholdResults[fmt.Sprintf("%.2f", threshold)] = thresholdResult
    }
    
    // æ‰¾åˆ°æœ€ä¼˜é˜ˆå€¼
    optimalThreshold, optimalMetrics := se.findOptimalThreshold(evaluation.ThresholdResults)
    evaluation.OptimalThreshold = optimalThreshold
    evaluation.OptimalMetrics = optimalMetrics
    
    // ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š
    evaluation.Report = se.generateEvaluationReport(evaluation)
    evaluation.EndTime = time.Now()
    evaluation.Duration = evaluation.EndTime.Sub(evaluation.StartTime)
    
    return evaluation, nil
}

func (se *SimilarityEvaluator) evaluateThreshold(
    algorithm SimilarityAlgorithm,
    threshold float64) *ThresholdEvaluation {
    
    var tp, fp, fn, tn int
    var totalQueries int
    var avgPrecisions []float64
    var reciprocalRanks []float64
    var ndcgScores []float64
    
    for _, testCase := range se.testSuite {
        result := se.evaluateSingleCase(algorithm, threshold, testCase)
        
        tp += result.TruePositive
        fp += result.FalsePositive
        fn += result.FalseNegative
        tn += result.TrueNegative
        totalQueries++
        
        if result.AveragePrecision > 0 {
            avgPrecisions = append(avgPrecisions, result.AveragePrecision)
        }
        if result.ReciprocalRank > 0 {
            reciprocalRanks = append(reciprocalRanks, result.ReciprocalRank)
        }
        if result.NDCG > 0 {
            ndcgScores = append(ndcgScores, result.NDCG)
        }
    }
    
    // è®¡ç®—åŸºç¡€æŒ‡æ ‡
    precision := float64(tp) / float64(tp+fp)
    recall := float64(tp) / float64(tp+fn)
    f1Score := 2 * precision * recall / (precision + recall)
    
    if tp+fp == 0 {
        precision = 0
    }
    if tp+fn == 0 {
        recall = 0
    }
    if precision+recall == 0 {
        f1Score = 0
    }
    
    // è®¡ç®—é«˜çº§æŒ‡æ ‡
    mapScore := se.calculateMean(avgPrecisions)
    mrrScore := se.calculateMean(reciprocalRanks)
    ndcgScore := se.calculateMean(ndcgScores)
    
    return &ThresholdEvaluation{
        Threshold:    threshold,
        Precision:    precision,
        Recall:       recall,
        F1Score:      f1Score,
        MAP:          mapScore,
        MRR:          mrrScore,
        NDCG:         ndcgScore,
        TotalQueries: totalQueries,
        TruePositive: tp,
        FalsePositive: fp,
        FalseNegative: fn,
        TrueNegative: tn,
    }
}

func (se *SimilarityEvaluator) evaluateSingleCase(
    algorithm SimilarityAlgorithm,
    threshold float64,
    testCase *GroundTruthCase) *SingleCaseResult {
    
    result := &SingleCaseResult{
        CaseID: testCase.ID,
        Query:  testCase.Query,
    }
    
    // æ¨¡æ‹Ÿæœç´¢è¿‡ç¨‹ï¼ˆè¿™é‡Œéœ€è¦å®é™…çš„æœç´¢é€»è¾‘ï¼‰
    searchResults := se.simulateSearch(algorithm, threshold, testCase)
    
    // è®¡ç®—æ··æ·†çŸ©é˜µ
    relevantSet := make(map[string]bool)
    for _, item := range testCase.RelevantItems {
        relevantSet[item] = true
    }
    
    var retrievedRelevant []string
    var retrievedIrrelevant []string
    
    for _, item := range searchResults {
        if relevantSet[item.ID] {
            result.TruePositive++
            retrievedRelevant = append(retrievedRelevant, item.ID)
        } else {
            result.FalsePositive++
            retrievedIrrelevant = append(retrievedIrrelevant, item.ID)
        }
    }
    
    // è®¡ç®—é—æ¼çš„ç›¸å…³é¡¹
    retrievedSet := make(map[string]bool)
    for _, item := range searchResults {
        retrievedSet[item.ID] = true
    }
    
    for _, relevantItem := range testCase.RelevantItems {
        if !retrievedSet[relevantItem] {
            result.FalseNegative++
        }
    }
    
    // è®¡ç®—Average Precision
    result.AveragePrecision = se.calculateAveragePrecision(searchResults, relevantSet)
    
    // è®¡ç®—Reciprocal Rank
    result.ReciprocalRank = se.calculateReciprocalRank(searchResults, relevantSet)
    
    // è®¡ç®—NDCG
    result.NDCG = se.calculateNDCG(searchResults, testCase.ExpectedRanking)
    
    return result
}

func (se *SimilarityEvaluator) calculateAveragePrecision(
    results []*SearchResultItem,
    relevantSet map[string]bool) float64 {
    
    var precisionSum float64
    var relevantCount int
    
    for i, item := range results {
        if relevantSet[item.ID] {
            relevantCount++
            precision := float64(relevantCount) / float64(i+1)
            precisionSum += precision
        }
    }
    
    if relevantCount == 0 {
        return 0
    }
    
    return precisionSum / float64(len(relevantSet))
}

func (se *SimilarityEvaluator) calculateReciprocalRank(
    results []*SearchResultItem,
    relevantSet map[string]bool) float64 {
    
    for i, item := range results {
        if relevantSet[item.ID] {
            return 1.0 / float64(i+1)
        }
    }
    
    return 0
}

func (se *SimilarityEvaluator) calculateNDCG(
    results []*SearchResultItem,
    expectedRanking []string) float64 {
    
    if len(expectedRanking) == 0 {
        return 0
    }
    
    // åˆ›å»ºç†æƒ³æ’åºçš„ç›¸å…³æ€§åˆ†æ•°
    idealRelevance := make(map[string]float64)
    for i, item := range expectedRanking {
        idealRelevance[item] = float64(len(expectedRanking) - i)
    }
    
    // è®¡ç®—DCG
    var dcg float64
    for i, item := range results {
        relevance := idealRelevance[item.ID]
        dcg += relevance / math.Log2(float64(i+2))
    }
    
    // è®¡ç®—IDCG
    var idcg float64
    sortedRelevance := make([]float64, 0, len(idealRelevance))
    for _, relevance := range idealRelevance {
        sortedRelevance = append(sortedRelevance, relevance)
    }
    sort.Float64s(sortedRelevance)
    
    // åè½¬æ’åºä»¥è·å¾—é™åº
    for i := len(sortedRelevance)/2 - 1; i >= 0; i-- {
        opp := len(sortedRelevance) - 1 - i
        sortedRelevance[i], sortedRelevance[opp] = sortedRelevance[opp], sortedRelevance[i]
    }
    
    for i, relevance := range sortedRelevance {
        idcg += relevance / math.Log2(float64(i+2))
    }
    
    if idcg == 0 {
        return 0
    }
    
    return dcg / idcg
}
```

---

## ğŸª åœ¨çº¿è¯„ä¼°ç³»ç»Ÿ

### ğŸ“Š å®æ—¶è´¨é‡ç›‘æ§

```go
// internal/similarity/online_evaluation.go
type OnlineEvaluationSystem struct {
    config          *OnlineConfig
    feedbackStore   *FeedbackStore
    metrics         *OnlineMetrics
    alertManager    *AlertManager
    qualityTracker  *QualityTracker
}

type OnlineConfig struct {
    // è¯„ä¼°çª—å£
    EvaluationWindow time.Duration `yaml:"evaluation_window"` // 1h
    SlidingWindow    time.Duration `yaml:"sliding_window"`    // 15m
    
    // è´¨é‡é˜ˆå€¼
    MinPrecision     float64 `yaml:"min_precision"`     // 0.85
    MinRecall        float64 `yaml:"min_recall"`        // 0.80
    MinF1Score       float64 `yaml:"min_f1_score"`      // 0.82
    
    // å‘Šè­¦é…ç½®
    AlertThreshold   float64 `yaml:"alert_threshold"`   // 0.05 (ä¸‹é™5%)
    AlertCooldown    time.Duration `yaml:"alert_cooldown"` // 30m
}

type UserFeedback struct {
    QueryID      string    `json:"query_id"`
    UserID       int64     `json:"user_id"`
    Query        string    `json:"query"`
    Results      []string  `json:"results"`
    Ratings      map[string]int `json:"ratings"`  // result_id -> rating (1-5)
    IsRelevant   map[string]bool `json:"is_relevant"`
    Timestamp    time.Time `json:"timestamp"`
    Source       string    `json:"source"`  // "explicit", "implicit"
}

func (oes *OnlineEvaluationSystem) ProcessUserFeedback(feedback *UserFeedback) {
    // å­˜å‚¨åé¦ˆæ•°æ®
    oes.feedbackStore.Store(feedback)
    
    // æ›´æ–°å®æ—¶æŒ‡æ ‡
    oes.updateRealTimeMetrics(feedback)
    
    // æ£€æŸ¥è´¨é‡é˜ˆå€¼
    oes.checkQualityThresholds()
    
    // è®°å½•ç”¨æˆ·è¡Œä¸ºæ¨¡å¼
    oes.recordUserBehavior(feedback)
}

func (oes *OnlineEvaluationSystem) updateRealTimeMetrics(feedback *UserFeedback) {
    window := oes.config.SlidingWindow
    
    // è®¡ç®—å½“å‰çª—å£çš„æŒ‡æ ‡
    windowFeedbacks := oes.feedbackStore.GetRecentFeedbacks(window)
    
    var tp, fp, fn int
    for _, fb := range windowFeedbacks {
        for resultID, isRelevant := range fb.IsRelevant {
            if oes.wasResultReturned(fb.QueryID, resultID) {
                if isRelevant {
                    tp++
                } else {
                    fp++
                }
            } else if isRelevant {
                fn++
            }
        }
    }
    
    // è®¡ç®—æŒ‡æ ‡
    precision := float64(tp) / float64(tp+fp)
    recall := float64(tp) / float64(tp+fn)
    f1Score := 2 * precision * recall / (precision + recall)
    
    if tp+fp == 0 {
        precision = 0
    }
    if tp+fn == 0 {
        recall = 0
    }
    if precision+recall == 0 {
        f1Score = 0
    }
    
    // æ›´æ–°æŒ‡æ ‡
    oes.metrics.UpdatePrecision(precision)
    oes.metrics.UpdateRecall(recall)
    oes.metrics.UpdateF1Score(f1Score)
}

func (oes *OnlineEvaluationSystem) checkQualityThresholds() {
    currentMetrics := oes.metrics.GetCurrentMetrics()
    
    alerts := make([]*QualityAlert, 0)
    
    // æ£€æŸ¥ç²¾ç¡®ç‡
    if currentMetrics.Precision < oes.config.MinPrecision {
        alerts = append(alerts, &QualityAlert{
            Type:        "precision_degradation",
            Severity:    "high",
            Current:     currentMetrics.Precision,
            Threshold:   oes.config.MinPrecision,
            Description: fmt.Sprintf("ç²¾ç¡®ç‡é™è‡³ %.3fï¼Œä½äºé˜ˆå€¼ %.3f", 
                        currentMetrics.Precision, oes.config.MinPrecision),
        })
    }
    
    // æ£€æŸ¥å¬å›ç‡
    if currentMetrics.Recall < oes.config.MinRecall {
        alerts = append(alerts, &QualityAlert{
            Type:        "recall_degradation", 
            Severity:    "high",
            Current:     currentMetrics.Recall,
            Threshold:   oes.config.MinRecall,
            Description: fmt.Sprintf("å¬å›ç‡é™è‡³ %.3fï¼Œä½äºé˜ˆå€¼ %.3f",
                        currentMetrics.Recall, oes.config.MinRecall),
        })
    }
    
    // æ£€æŸ¥F1åˆ†æ•°
    if currentMetrics.F1Score < oes.config.MinF1Score {
        alerts = append(alerts, &QualityAlert{
            Type:        "f1_degradation",
            Severity:    "medium", 
            Current:     currentMetrics.F1Score,
            Threshold:   oes.config.MinF1Score,
            Description: fmt.Sprintf("F1åˆ†æ•°é™è‡³ %.3fï¼Œä½äºé˜ˆå€¼ %.3f",
                        currentMetrics.F1Score, oes.config.MinF1Score),
        })
    }
    
    // å‘é€å‘Šè­¦
    for _, alert := range alerts {
        oes.alertManager.SendAlert(alert)
    }
}

func (oes *OnlineEvaluationSystem) GenerateQualityReport() *QualityReport {
    endTime := time.Now()
    startTime := endTime.Add(-oes.config.EvaluationWindow)
    
    // æ”¶é›†åé¦ˆæ•°æ®
    feedbacks := oes.feedbackStore.GetFeedbacksInRange(startTime, endTime)
    
    // è®¡ç®—æ•´ä½“æŒ‡æ ‡
    overallMetrics := oes.calculateOverallMetrics(feedbacks)
    
    // æŒ‰æ—¶é—´æ®µåˆ†æ
    timeSegments := oes.analyzeByTimeSegments(feedbacks)
    
    // æŒ‰æŸ¥è¯¢ç±»å‹åˆ†æ
    queryTypeAnalysis := oes.analyzeByQueryType(feedbacks)
    
    // ç”¨æˆ·æ»¡æ„åº¦åˆ†æ
    satisfactionAnalysis := oes.analyzeSatisfaction(feedbacks)
    
    return &QualityReport{
        TimeRange:            fmt.Sprintf("%s - %s", startTime.Format("2006-01-02 15:04"), endTime.Format("2006-01-02 15:04")),
        TotalFeedbacks:       len(feedbacks),
        OverallMetrics:       overallMetrics,
        TimeSegmentAnalysis:  timeSegments,
        QueryTypeAnalysis:    queryTypeAnalysis,
        SatisfactionAnalysis: satisfactionAnalysis,
        GeneratedAt:          time.Now(),
    }
}
```

---

## ğŸ› ï¸ ä¼˜åŒ–å»ºè®®

### 1. ç›¸ä¼¼åº¦ç®—æ³•é€‰æ‹©æŒ‡å—

```yaml
# config/similarity_algorithm_guide.yaml
algorithm_selection:
  scenarios:
    high_precision_search:
      recommended: "cosine"
      threshold: 0.85
      use_case: "Schemaç²¾ç¡®åŒ¹é…"
      
    balanced_search:
      recommended: "hybrid"
      algorithms: ["cosine", "jaccard"]
      weights: {"cosine": 0.7, "jaccard": 0.3}
      threshold: 0.75
      use_case: "é€šç”¨æŸ¥è¯¢æ£€ç´¢"
      
    high_recall_search:
      recommended: "cosine"
      threshold: 0.65
      use_case: "ä¸Šä¸‹æ–‡æ¨è"
      
    real_time_search:
      recommended: "cosine"
      optimization: "batch_calculation"
      use_case: "é«˜å¹¶å‘åœºæ™¯"
```

### 2. æ€§èƒ½ä¼˜åŒ–é…ç½®

```yaml
# config/similarity_performance.yaml
performance_optimization:
  # æ‰¹é‡è®¡ç®—
  batch_processing:
    enabled: true
    batch_size: 100
    max_concurrent: 10
    
  # å‘é‡ç¼“å­˜
  vector_caching:
    enabled: true
    cache_size: 10000
    ttl: "1h"
    
  # é¢„è®¡ç®—ä¼˜åŒ–
  precomputation:
    enabled: true
    common_queries: 1000
    update_interval: "6h"
    
  # è¿‘ä¼¼ç®—æ³•
  approximation:
    enabled: false
    error_tolerance: 0.01
    speed_improvement: 5x
```

---

<div align="center">

**ğŸ¯ è¯­ä¹‰ç›¸ä¼¼åº¦åŒ¹é…æˆåŠŸå…³é”®ï¼šç®—æ³•ä¼˜åŒ– + é˜ˆå€¼è°ƒä¼˜ + è´¨é‡ç›‘æ§**

</div>