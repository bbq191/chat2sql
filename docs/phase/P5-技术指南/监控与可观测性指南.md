# 👁️ 监控与可观测性指南

## 🎯 技术概述

完整的可观测性体系为Chat2SQL提供了全链路监控能力，通过指标、日志、追踪三大支柱实现系统透明化管理。本指南详细介绍P5阶段第2周的监控与可观测性实现策略。

### ✨ 核心价值

| 功能特性 | 技术实现 | 业务价值 | 性能提升 |
|---------|---------|---------|---------| 
| **指标监控** | Prometheus + Grafana | 实时性能监控 | 问题发现时间减少90% |
| **链路追踪** | Jaeger + OpenTelemetry | 分布式调用分析 | 问题定位效率提升80% |
| **日志聚合** | Loki + Promtail | 集中化日志管理 | 故障排查速度提升70% |
| **智能告警** | AlertManager + PagerDuty | 预警和自动化响应 | 故障响应时间减少85% |

### 🎁 监控场景

- **性能监控**：API响应时间、数据库连接、资源使用率
- **业务监控**：SQL查询准确率、AI模型性能、用户行为分析
- **安全监控**：访问异常、权限变更、安全事件追踪
- **基础设施监控**：K8s集群、节点状态、网络流量

---

## 📊 Prometheus监控体系

### 📦 Prometheus Operator部署

```yaml
# prometheus-operator.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: monitoring
---
# Prometheus CRD配置
apiVersion: monitoring.coreos.com/v1
kind: Prometheus
metadata:
  name: chat2sql-prometheus
  namespace: monitoring
spec:
  replicas: 2
  retention: 30d
  storage:
    volumeClaimTemplate:
      spec:
        storageClassName: chat2sql-ssd
        accessModes: ["ReadWriteOnce"]
        resources:
          requests:
            storage: 100Gi
  serviceMonitorSelector:
    matchLabels:
      team: chat2sql
  ruleSelector:
    matchLabels:
      team: chat2sql
  alerting:
    alertmanagers:
    - namespace: monitoring
      name: alertmanager-main
      port: web
  resources:
    requests:
      memory: 2Gi
      cpu: 1000m
    limits:
      memory: 4Gi
      cpu: 2000m
  securityContext:
    runAsNonRoot: true
    runAsUser: 65534
    fsGroup: 65534
---
# Grafana配置
apiVersion: apps/v1
kind: Deployment
metadata:
  name: grafana
  namespace: monitoring
spec:
  replicas: 1
  selector:
    matchLabels:
      app: grafana
  template:
    metadata:
      labels:
        app: grafana
    spec:
      containers:
      - name: grafana
        image: grafana/grafana:10.2.0
        ports:
        - containerPort: 3000
        env:
        - name: GF_SECURITY_ADMIN_PASSWORD
          valueFrom:
            secretKeyRef:
              name: grafana-secret
              key: admin-password
        - name: GF_AUTH_ANONYMOUS_ENABLED
          value: "false"
        - name: GF_AUTH_BASIC_ENABLED
          value: "true"
        volumeMounts:
        - name: grafana-storage
          mountPath: /var/lib/grafana
        - name: grafana-config
          mountPath: /etc/grafana/provisioning
        resources:
          requests:
            memory: 512Mi
            cpu: 250m
          limits:
            memory: 1Gi
            cpu: 500m
      volumes:
      - name: grafana-storage
        persistentVolumeClaim:
          claimName: grafana-pvc
      - name: grafana-config
        configMap:
          name: grafana-config
```

### 🎯 ServiceMonitor配置

```yaml
# chat2sql-servicemonitor.yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: chat2sql-backend
  namespace: monitoring
  labels:
    team: chat2sql
spec:
  selector:
    matchLabels:
      app: chat2sql-backend
  namespaceSelector:
    matchNames:
    - chat2sql
  endpoints:
  - port: metrics
    interval: 15s
    path: /metrics
    honorLabels: true
---
# PostgreSQL ServiceMonitor
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: postgresql-exporter
  namespace: monitoring
  labels:
    team: chat2sql
spec:
  selector:
    matchLabels:
      app: postgresql-exporter
  endpoints:
  - port: metrics
    interval: 30s
    path: /metrics
---
# Redis ServiceMonitor
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: redis-exporter
  namespace: monitoring
  labels:
    team: chat2sql
spec:
  selector:
    matchLabels:
      app: redis-exporter
  endpoints:
  - port: metrics
    interval: 30s
    path: /metrics
```

### 📈 自定义指标收集

```go
// Go应用指标收集
package monitoring

import (
    "github.com/prometheus/client_golang/prometheus"
    "github.com/prometheus/client_golang/prometheus/promauto"
    "time"
)

// Chat2SQL业务指标
var (
    // SQL查询相关指标
    sqlQueryDuration = promauto.NewHistogramVec(
        prometheus.HistogramOpts{
            Name: "chat2sql_query_duration_seconds",
            Help: "SQL查询执行时间分布",
            Buckets: []float64{0.1, 0.5, 1.0, 2.0, 5.0, 10.0, 30.0},
        },
        []string{"query_type", "status"},
    )
    
    sqlQueryTotal = promauto.NewCounterVec(
        prometheus.CounterOpts{
            Name: "chat2sql_query_total",
            Help: "SQL查询总数",
        },
        []string{"query_type", "status"},
    )
    
    // AI模型相关指标
    aiModelInference = promauto.NewHistogramVec(
        prometheus.HistogramOpts{
            Name: "chat2sql_ai_inference_duration_seconds",
            Help: "AI模型推理时间分布",
            Buckets: []float64{0.1, 0.5, 1.0, 3.0, 10.0, 30.0},
        },
        []string{"model_name", "model_provider"},
    )
    
    aiModelAccuracy = promauto.NewGaugeVec(
        prometheus.GaugeOpts{
            Name: "chat2sql_ai_accuracy_rate",
            Help: "AI模型准确率",
        },
        []string{"model_name", "time_window"},
    )
    
    // 系统资源指标
    activeDatabaseConnections = promauto.NewGaugeVec(
        prometheus.GaugeOpts{
            Name: "chat2sql_db_connections_active",
            Help: "活跃数据库连接数",
        },
        []string{"database", "pool"},
    )
    
    cacheHitRate = promauto.NewGaugeVec(
        prometheus.GaugeOpts{
            Name: "chat2sql_cache_hit_rate",
            Help: "缓存命中率",
        },
        []string{"cache_type", "cache_name"},
    )
)

// 指标收集器
type MetricsCollector struct {
    registry prometheus.Registerer
}

func NewMetricsCollector() *MetricsCollector {
    return &MetricsCollector{
        registry: prometheus.DefaultRegisterer,
    }
}

// 记录SQL查询指标
func (mc *MetricsCollector) RecordSQLQuery(queryType, status string, duration time.Duration) {
    sqlQueryDuration.WithLabelValues(queryType, status).Observe(duration.Seconds())
    sqlQueryTotal.WithLabelValues(queryType, status).Inc()
}

// 记录AI推理指标
func (mc *MetricsCollector) RecordAIInference(modelName, provider string, duration time.Duration) {
    aiModelInference.WithLabelValues(modelName, provider).Observe(duration.Seconds())
}

// 更新AI准确率
func (mc *MetricsCollector) UpdateAIAccuracy(modelName, timeWindow string, accuracy float64) {
    aiModelAccuracy.WithLabelValues(modelName, timeWindow).Set(accuracy)
}

// 更新数据库连接数
func (mc *MetricsCollector) UpdateDatabaseConnections(database, pool string, count int) {
    activeDatabaseConnections.WithLabelValues(database, pool).Set(float64(count))
}

// 更新缓存命中率
func (mc *MetricsCollector) UpdateCacheHitRate(cacheType, cacheName string, hitRate float64) {
    cacheHitRate.WithLabelValues(cacheType, cacheName).Set(hitRate)
}
```

### 🔧 PrometheusRule告警规则

```yaml
# chat2sql-prometheus-rules.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: chat2sql-rules
  namespace: monitoring
  labels:
    team: chat2sql
spec:
  groups:
  - name: chat2sql.business
    interval: 30s
    rules:
    # SQL查询性能告警
    - alert: HighSQLQueryLatency
      expr: |
        histogram_quantile(0.95, 
          rate(chat2sql_query_duration_seconds_bucket[5m])
        ) > 10
      for: 2m
      labels:
        severity: warning
        component: backend
      annotations:
        summary: "SQL查询延迟过高"
        description: "95%的SQL查询延迟超过10秒，当前值: {{ $value }}s"
        
    # AI模型准确率告警
    - alert: LowAIAccuracy
      expr: |
        chat2sql_ai_accuracy_rate < 0.85
      for: 5m
      labels:
        severity: critical
        component: ai-model
      annotations:
        summary: "AI模型准确率下降"
        description: "AI模型准确率低于85%，当前值: {{ $value }}"
        
    # 数据库连接池告警
    - alert: DatabaseConnectionPoolExhaustion
      expr: |
        chat2sql_db_connections_active / 100 > 0.9
      for: 1m
      labels:
        severity: warning
        component: database
      annotations:
        summary: "数据库连接池即将耗尽"
        description: "数据库连接池使用率超过90%，当前: {{ $value }}%"
        
  - name: chat2sql.infrastructure
    interval: 30s
    rules:
    # Pod重启告警
    - alert: PodCrashLooping
      expr: |
        rate(kube_pod_container_status_restarts_total[15m]) > 0
      for: 5m
      labels:
        severity: critical
        component: kubernetes
      annotations:
        summary: "Pod频繁重启"
        description: "Pod {{ $labels.pod }} 在命名空间 {{ $labels.namespace }} 中频繁重启"
        
    # 内存使用告警
    - alert: HighMemoryUsage
      expr: |
        (container_memory_working_set_bytes / container_spec_memory_limit_bytes) > 0.9
      for: 5m
      labels:
        severity: warning
        component: resources
      annotations:
        summary: "容器内存使用率过高"
        description: "容器 {{ $labels.container }} 内存使用率超过90%"
        
    # CPU使用告警
    - alert: HighCPUUsage
      expr: |
        rate(container_cpu_usage_seconds_total[5m]) > 0.8
      for: 10m
      labels:
        severity: warning
        component: resources
      annotations:
        summary: "容器CPU使用率过高"
        description: "容器 {{ $labels.container }} CPU使用率超过80%"
```

---

## 🔍 Jaeger分布式链路追踪

### 📦 Jaeger Operator部署

```yaml
# jaeger-operator.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: observability
---
apiVersion: jaegertracing.io/v1
kind: Jaeger
metadata:
  name: chat2sql-jaeger
  namespace: observability
spec:
  strategy: production
  storage:
    type: elasticsearch
    elasticsearch:
      nodeCount: 3
      storage:
        storageClassName: chat2sql-ssd
        size: 50Gi
      resources:
        requests:
          memory: 2Gi
          cpu: 1000m
        limits:
          memory: 4Gi
          cpu: 2000m
  collector:
    replicas: 3
    resources:
      requests:
        memory: 512Mi
        cpu: 250m
      limits:
        memory: 1Gi
        cpu: 500m
  query:
    replicas: 2
    resources:
      requests:
        memory: 512Mi
        cpu: 250m
      limits:
        memory: 1Gi
        cpu: 500m
  agent:
    strategy: DaemonSet
    resources:
      requests:
        memory: 128Mi
        cpu: 100m
      limits:
        memory: 256Mi
        cpu: 200m
---
# Jaeger Service配置
apiVersion: v1
kind: Service
metadata:
  name: jaeger-query
  namespace: observability
spec:
  selector:
    app: jaeger
    app.kubernetes.io/component: query
  ports:
  - port: 16686
    targetPort: 16686
    name: query-http
  type: ClusterIP
```

### 🎯 OpenTelemetry配置

```go
// Go应用OpenTelemetry集成
package tracing

import (
    "context"
    "go.opentelemetry.io/otel"
    "go.opentelemetry.io/otel/attribute"
    "go.opentelemetry.io/otel/exporters/jaeger"
    "go.opentelemetry.io/otel/propagation"
    "go.opentelemetry.io/otel/sdk/resource"
    "go.opentelemetry.io/otel/sdk/trace"
    semconv "go.opentelemetry.io/otel/semconv/v1.12.0"
    oteltrace "go.opentelemetry.io/otel/trace"
)

// 初始化追踪
func InitTracing(serviceName string) func() {
    // 创建Jaeger exporter
    exp, err := jaeger.New(jaeger.WithCollectorEndpoint(jaeger.WithEndpoint("http://jaeger-collector:14268/api/traces")))
    if err != nil {
        panic(err)
    }

    // 创建资源
    res, err := resource.Merge(
        resource.Default(),
        resource.NewWithAttributes(
            semconv.SchemaURL,
            semconv.ServiceNameKey.String(serviceName),
            semconv.ServiceVersionKey.String("1.0.0"),
            attribute.String("environment", "production"),
        ),
    )
    if err != nil {
        panic(err)
    }

    // 创建追踪提供者
    tp := trace.NewTracerProvider(
        trace.WithBatcher(exp),
        trace.WithResource(res),
        trace.WithSampler(trace.AlwaysSample()),
    )

    // 设置全局追踪提供者
    otel.SetTracerProvider(tp)
    
    // 设置全局传播器
    otel.SetTextMapPropagator(propagation.TraceContext{})

    return func() {
        if err := tp.Shutdown(context.Background()); err != nil {
            panic(err)
        }
    }
}

// Chat2SQL追踪器
type Chat2SQLTracer struct {
    tracer oteltrace.Tracer
}

func NewChat2SQLTracer() *Chat2SQLTracer {
    return &Chat2SQLTracer{
        tracer: otel.Tracer("chat2sql"),
    }
}

// 追踪SQL查询
func (t *Chat2SQLTracer) TraceSQLQuery(ctx context.Context, query string) (context.Context, oteltrace.Span) {
    ctx, span := t.tracer.Start(ctx, "sql.query",
        oteltrace.WithAttributes(
            attribute.String("db.statement", query),
            attribute.String("db.system", "postgresql"),
            attribute.String("component", "database"),
        ),
    )
    return ctx, span
}

// 追踪AI推理
func (t *Chat2SQLTracer) TraceAIInference(ctx context.Context, model, prompt string) (context.Context, oteltrace.Span) {
    ctx, span := t.tracer.Start(ctx, "ai.inference",
        oteltrace.WithAttributes(
            attribute.String("ai.model", model),
            attribute.String("ai.prompt.length", fmt.Sprintf("%d", len(prompt))),
            attribute.String("component", "ai"),
        ),
    )
    return ctx, span
}

// 追踪HTTP请求
func (t *Chat2SQLTracer) TraceHTTPRequest(ctx context.Context, method, url string) (context.Context, oteltrace.Span) {
    ctx, span := t.tracer.Start(ctx, fmt.Sprintf("http.%s", strings.ToLower(method)),
        oteltrace.WithAttributes(
            attribute.String("http.method", method),
            attribute.String("http.url", url),
            attribute.String("component", "http"),
        ),
    )
    return ctx, span
}

// 记录错误
func (t *Chat2SQLTracer) RecordError(span oteltrace.Span, err error) {
    span.RecordError(err)
    span.SetStatus(codes.Error, err.Error())
}
```

### 📊 分布式追踪中间件

```go
// HTTP追踪中间件
func TracingMiddleware(tracer *Chat2SQLTracer) gin.HandlerFunc {
    return func(c *gin.Context) {
        ctx, span := tracer.TraceHTTPRequest(
            c.Request.Context(),
            c.Request.Method,
            c.Request.URL.String(),
        )
        defer span.End()

        // 设置追踪上下文
        c.Request = c.Request.WithContext(ctx)
        
        // 添加追踪ID到响应头
        if spanCtx := span.SpanContext(); spanCtx.IsValid() {
            c.Header("X-Trace-ID", spanCtx.TraceID().String())
        }

        c.Next()

        // 记录响应状态
        span.SetAttributes(
            attribute.Int("http.status_code", c.Writer.Status()),
            attribute.String("http.route", c.FullPath()),
        )

        if c.Writer.Status() >= 400 {
            span.SetStatus(codes.Error, fmt.Sprintf("HTTP %d", c.Writer.Status()))
        }
    }
}

// 数据库追踪中间件
func (db *Database) TracedQuery(ctx context.Context, query string, args ...interface{}) (*sql.Rows, error) {
    tracer := NewChat2SQLTracer()
    ctx, span := tracer.TraceSQLQuery(ctx, query)
    defer span.End()

    start := time.Now()
    rows, err := db.QueryContext(ctx, query, args...)
    duration := time.Since(start)

    span.SetAttributes(
        attribute.String("db.operation", "query"),
        attribute.Float64("db.duration_ms", float64(duration.Nanoseconds())/1e6),
        attribute.Int("db.rows_affected", getRowCount(rows)),
    )

    if err != nil {
        tracer.RecordError(span, err)
    }

    return rows, err
}
```

---

## 📝 Loki日志聚合系统

### 📦 Loki部署配置

```yaml
# loki-stack.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: loki-config
  namespace: observability
data:
  loki.yaml: |
    auth_enabled: false
    server:
      http_listen_port: 3100
      grpc_listen_port: 9096
    
    common:
      path_prefix: /loki
      storage:
        filesystem:
          chunks_directory: /loki/chunks
          rules_directory: /loki/rules
      replication_factor: 1
      ring:
        instance_addr: 127.0.0.1
        kvstore:
          store: inmemory
    
    schema_config:
      configs:
        - from: 2020-10-24
          store: boltdb-shipper
          object_store: filesystem
          schema: v11
          index:
            prefix: index_
            period: 24h
    
    storage_config:
      boltdb_shipper:
        active_index_directory: /loki/boltdb-shipper-active
        cache_location: /loki/boltdb-shipper-cache
        cache_ttl: 24h
        shared_store: filesystem
      filesystem:
        directory: /loki/chunks
    
    compactor:
      working_directory: /loki/boltdb-shipper-compactor
      shared_store: filesystem
    
    limits_config:
      retention_period: 720h  # 30天
      ingestion_rate_mb: 16
      ingestion_burst_size_mb: 32
    
    chunk_store_config:
      max_look_back_period: 0s
    
    table_manager:
      retention_deletes_enabled: true
      retention_period: 720h
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: loki
  namespace: observability
spec:
  serviceName: loki-headless
  replicas: 3
  selector:
    matchLabels:
      app: loki
  template:
    metadata:
      labels:
        app: loki
    spec:
      containers:
      - name: loki
        image: grafana/loki:2.9.0
        ports:
        - containerPort: 3100
          name: http
        - containerPort: 9096
          name: grpc
        volumeMounts:
        - name: config
          mountPath: /etc/loki
        - name: storage
          mountPath: /loki
        args:
        - -config.file=/etc/loki/loki.yaml
        resources:
          requests:
            memory: 1Gi
            cpu: 500m
          limits:
            memory: 2Gi
            cpu: 1000m
      volumes:
      - name: config
        configMap:
          name: loki-config
  volumeClaimTemplates:
  - metadata:
      name: storage
    spec:
      accessModes: ["ReadWriteOnce"]
      storageClassName: chat2sql-ssd
      resources:
        requests:
          storage: 50Gi
```

### 🎯 Promtail日志收集

```yaml
# promtail-daemonset.yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: promtail
  namespace: observability
spec:
  selector:
    matchLabels:
      app: promtail
  template:
    metadata:
      labels:
        app: promtail
    spec:
      serviceAccountName: promtail
      containers:
      - name: promtail
        image: grafana/promtail:2.9.0
        args:
        - -config.file=/etc/promtail/config.yml
        volumeMounts:
        - name: config
          mountPath: /etc/promtail
        - name: varlog
          mountPath: /var/log
          readOnly: true
        - name: varlibdockercontainers
          mountPath: /var/lib/docker/containers
          readOnly: true
        ports:
        - containerPort: 3101
          name: http-metrics
        resources:
          requests:
            memory: 128Mi
            cpu: 100m
          limits:
            memory: 256Mi
            cpu: 200m
      volumes:
      - name: config
        configMap:
          name: promtail-config
      - name: varlog
        hostPath:
          path: /var/log
      - name: varlibdockercontainers
        hostPath:
          path: /var/lib/docker/containers
      tolerations:
      - effect: NoSchedule
        operator: Exists
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: promtail-config
  namespace: observability
data:
  config.yml: |
    server:
      http_listen_port: 3101
      grpc_listen_port: 0
    
    positions:
      filename: /tmp/positions.yaml
    
    clients:
      - url: http://loki:3100/loki/api/v1/push
    
    scrape_configs:
    # Kubernetes Pod日志
    - job_name: kubernetes-pods
      kubernetes_sd_configs:
      - role: pod
      relabel_configs:
      - source_labels:
        - __meta_kubernetes_pod_annotation_prometheus_io_scrape
        action: keep
        regex: true
      - source_labels:
        - __meta_kubernetes_pod_annotation_prometheus_io_path
        action: replace
        target_label: __metrics_path__
        regex: (.+)
      - source_labels:
        - __address__
        - __meta_kubernetes_pod_annotation_prometheus_io_port
        action: replace
        regex: ([^:]+)(?::\d+)?;(\d+)
        replacement: $1:$2
        target_label: __address__
      - action: labelmap
        regex: __meta_kubernetes_pod_label_(.+)
      - source_labels:
        - __meta_kubernetes_namespace
        action: replace
        target_label: kubernetes_namespace
      - source_labels:
        - __meta_kubernetes_pod_name
        action: replace
        target_label: kubernetes_pod_name
    
    # Chat2SQL应用日志
    - job_name: chat2sql-logs
      static_configs:
      - targets:
        - localhost
        labels:
          job: chat2sql
          __path__: /var/log/containers/*chat2sql*.log
      pipeline_stages:
      - json:
          expressions:
            timestamp: time
            level: level
            message: msg
            service: service
      - timestamp:
          source: timestamp
          format: RFC3339
      - labels:
          level:
          service:
```

### 📊 结构化日志配置

```go
// Go应用结构化日志
package logging

import (
    "context"
    "github.com/sirupsen/logrus"
    "go.opentelemetry.io/otel/trace"
)

// 结构化日志器
type StructuredLogger struct {
    logger *logrus.Logger
}

func NewStructuredLogger() *StructuredLogger {
    logger := logrus.New()
    logger.SetFormatter(&logrus.JSONFormatter{
        TimestampFormat: "2006-01-02T15:04:05.000Z07:00",
        FieldMap: logrus.FieldMap{
            logrus.FieldKeyTime:  "timestamp",
            logrus.FieldKeyLevel: "level",
            logrus.FieldKeyMsg:   "message",
        },
    })
    
    return &StructuredLogger{logger: logger}
}

// 记录SQL查询日志
func (l *StructuredLogger) LogSQLQuery(ctx context.Context, query string, duration time.Duration, err error) {
    fields := logrus.Fields{
        "component":     "database",
        "operation":     "sql_query",
        "query_hash":    hashQuery(query),
        "duration_ms":   duration.Milliseconds(),
        "query_length":  len(query),
    }
    
    // 添加追踪信息
    if span := trace.SpanFromContext(ctx); span.SpanContext().IsValid() {
        fields["trace_id"] = span.SpanContext().TraceID().String()
        fields["span_id"] = span.SpanContext().SpanID().String()
    }
    
    if err != nil {
        fields["error"] = err.Error()
        l.logger.WithFields(fields).Error("SQL查询失败")
    } else {
        l.logger.WithFields(fields).Info("SQL查询完成")
    }
}

// 记录AI推理日志
func (l *StructuredLogger) LogAIInference(ctx context.Context, model, prompt string, tokens int, duration time.Duration) {
    fields := logrus.Fields{
        "component":      "ai",
        "operation":      "inference",
        "model":          model,
        "prompt_length":  len(prompt),
        "tokens_used":    tokens,
        "duration_ms":    duration.Milliseconds(),
    }
    
    // 添加追踪信息
    if span := trace.SpanFromContext(ctx); span.SpanContext().IsValid() {
        fields["trace_id"] = span.SpanContext().TraceID().String()
        fields["span_id"] = span.SpanContext().SpanID().String()
    }
    
    l.logger.WithFields(fields).Info("AI推理完成")
}

// 记录用户操作日志
func (l *StructuredLogger) LogUserAction(ctx context.Context, userID, action string, metadata map[string]interface{}) {
    fields := logrus.Fields{
        "component": "user_action",
        "user_id":   userID,
        "action":    action,
        "metadata":  metadata,
    }
    
    l.logger.WithFields(fields).Info("用户操作记录")
}

// 记录安全事件
func (l *StructuredLogger) LogSecurityEvent(ctx context.Context, eventType, userID, ipAddress string, details map[string]interface{}) {
    fields := logrus.Fields{
        "component":   "security",
        "event_type":  eventType,
        "user_id":     userID,
        "ip_address":  ipAddress,
        "details":     details,
        "severity":    "warning",
    }
    
    l.logger.WithFields(fields).Warn("安全事件检测")
}

// 查询哈希生成
func hashQuery(query string) string {
    // 简单的查询哈希，生产环境应使用更安全的哈希
    h := sha256.Sum256([]byte(query))
    return hex.EncodeToString(h[:8]) // 只取前8字节
}
```

---

## 🚨 AlertManager智能告警

### 📦 AlertManager配置

```yaml
# alertmanager.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: alertmanager-config
  namespace: monitoring
data:
  alertmanager.yml: |
    global:
      smtp_smarthost: 'smtp.gmail.com:587'
      smtp_from: 'alerts@chat2sql.com'
      smtp_auth_username: 'alerts@chat2sql.com'
      smtp_auth_password: 'smtp-password'
    
    # 路由配置
    route:
      group_by: ['alertname', 'cluster', 'service']
      group_wait: 10s
      group_interval: 10s
      repeat_interval: 1h
      receiver: 'web.hook'
      routes:
      # 关键业务告警
      - match:
          severity: critical
        receiver: 'critical-alerts'
        group_wait: 0s
        repeat_interval: 15m
      # 安全告警
      - match:
          component: security
        receiver: 'security-team'
        group_wait: 0s
        repeat_interval: 5m
      # 基础设施告警
      - match:
          component: kubernetes
        receiver: 'infrastructure-team'
        repeat_interval: 30m
    
    # 抑制规则
    inhibit_rules:
    - source_match:
        severity: 'critical'
      target_match:
        severity: 'warning'
      equal: ['alertname', 'cluster', 'service']
    
    receivers:
    # 默认接收器
    - name: 'web.hook'
      webhook_configs:
      - url: 'http://webhook-service:8080/alerts'
        send_resolved: true
    
    # 关键告警接收器
    - name: 'critical-alerts'
      email_configs:
      - to: 'oncall@chat2sql.com'
        subject: '🚨 Chat2SQL关键告警: {{ .GroupLabels.alertname }}'
        body: |
          {{ range .Alerts }}
          告警: {{ .Annotations.summary }}
          描述: {{ .Annotations.description }}
          标签: {{ range .Labels.SortedPairs }}{{ .Name }}={{ .Value }} {{ end }}
          时间: {{ .StartsAt }}
          {{ end }}
      slack_configs:
      - api_url: 'https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK'
        channel: '#critical-alerts'
        title: '🚨 Chat2SQL关键告警'
        text: '{{ range .Alerts }}{{ .Annotations.summary }}{{ end }}'
      pagerduty_configs:
      - service_key: 'your-pagerduty-service-key'
        description: '{{ range .Alerts }}{{ .Annotations.summary }}{{ end }}'
    
    # 安全团队接收器
    - name: 'security-team'
      email_configs:
      - to: 'security@chat2sql.com'
        subject: '🔒 Chat2SQL安全告警: {{ .GroupLabels.alertname }}'
      slack_configs:
      - api_url: 'https://hooks.slack.com/services/YOUR/SECURITY/WEBHOOK'
        channel: '#security-alerts'
        title: '🔒 安全事件检测'
    
    # 基础设施团队接收器
    - name: 'infrastructure-team'
      email_configs:
      - to: 'infra@chat2sql.com'
        subject: '⚠️ Chat2SQL基础设施告警: {{ .GroupLabels.alertname }}'
      slack_configs:
      - api_url: 'https://hooks.slack.com/services/YOUR/INFRA/WEBHOOK'
        channel: '#infrastructure-alerts'
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: alertmanager
  namespace: monitoring
spec:
  replicas: 3
  selector:
    matchLabels:
      app: alertmanager
  template:
    metadata:
      labels:
        app: alertmanager
    spec:
      containers:
      - name: alertmanager
        image: prom/alertmanager:v0.26.0
        ports:
        - containerPort: 9093
        volumeMounts:
        - name: config
          mountPath: /etc/alertmanager
        - name: storage
          mountPath: /alertmanager
        args:
        - --config.file=/etc/alertmanager/alertmanager.yml
        - --storage.path=/alertmanager
        - --web.external-url=https://alertmanager.chat2sql.com
        - --cluster.listen-address=0.0.0.0:9094
        - --cluster.peer=alertmanager-0.alertmanager:9094
        - --cluster.peer=alertmanager-1.alertmanager:9094
        - --cluster.peer=alertmanager-2.alertmanager:9094
        resources:
          requests:
            memory: 256Mi
            cpu: 100m
          limits:
            memory: 512Mi
            cpu: 200m
      volumes:
      - name: config
        configMap:
          name: alertmanager-config
      - name: storage
        persistentVolumeClaim:
          claimName: alertmanager-storage
```

### 🎯 智能告警脚本

```go
// 智能告警处理器
package alerting

import (
    "context"
    "encoding/json"
    "fmt"
    "net/http"
    "time"
)

// 告警消息结构
type Alert struct {
    Status       string            `json:"status"`
    Labels       map[string]string `json:"labels"`
    Annotations  map[string]string `json:"annotations"`
    StartsAt     time.Time         `json:"startsAt"`
    EndsAt       time.Time         `json:"endsAt"`
    GeneratorURL string            `json:"generatorURL"`
}

type AlertMessage struct {
    Receiver          string  `json:"receiver"`
    Status            string  `json:"status"`
    Alerts            []Alert `json:"alerts"`
    GroupLabels       map[string]string `json:"groupLabels"`
    CommonLabels      map[string]string `json:"commonLabels"`
    CommonAnnotations map[string]string `json:"commonAnnotations"`
    ExternalURL       string  `json:"externalURL"`
}

// 智能告警处理器
type IntelligentAlertHandler struct {
    slackClient  *SlackClient
    emailClient  *EmailClient
    ticketClient *TicketingClient
}

func NewIntelligentAlertHandler() *IntelligentAlertHandler {
    return &IntelligentAlertHandler{
        slackClient:  NewSlackClient(),
        emailClient:  NewEmailClient(),
        ticketClient: NewTicketingClient(),
    }
}

// 处理告警Webhook
func (h *IntelligentAlertHandler) HandleWebhook(w http.ResponseWriter, r *http.Request) {
    var alertMsg AlertMessage
    if err := json.NewDecoder(r.Body).Decode(&alertMsg); err != nil {
        http.Error(w, "Invalid JSON", http.StatusBadRequest)
        return
    }

    ctx := r.Context()
    
    for _, alert := range alertMsg.Alerts {
        if err := h.processAlert(ctx, alert); err != nil {
            log.Printf("处理告警失败: %v", err)
        }
    }

    w.WriteHeader(http.StatusOK)
}

// 处理单个告警
func (h *IntelligentAlertHandler) processAlert(ctx context.Context, alert Alert) error {
    severity := alert.Labels["severity"]
    component := alert.Labels["component"]
    
    // 基于严重性和组件进行智能路由
    switch severity {
    case "critical":
        return h.handleCriticalAlert(ctx, alert)
    case "warning":
        return h.handleWarningAlert(ctx, alert)
    default:
        return h.handleInfoAlert(ctx, alert)
    }
}

// 处理关键告警
func (h *IntelligentAlertHandler) handleCriticalAlert(ctx context.Context, alert Alert) error {
    // 立即通知
    if err := h.slackClient.SendUrgentAlert(alert); err != nil {
        return fmt.Errorf("发送Slack紧急告警失败: %w", err)
    }
    
    // 创建故障单
    ticketID, err := h.ticketClient.CreateIncident(alert)
    if err != nil {
        return fmt.Errorf("创建故障单失败: %w", err)
    }
    
    // 触发自动化修复
    if err := h.triggerAutoRemediation(ctx, alert); err != nil {
        log.Printf("自动化修复失败: %v", err)
    }
    
    log.Printf("关键告警处理完成，故障单ID: %s", ticketID)
    return nil
}

// 触发自动化修复
func (h *IntelligentAlertHandler) triggerAutoRemediation(ctx context.Context, alert Alert) error {
    alertName := alert.Labels["alertname"]
    
    switch alertName {
    case "PodCrashLooping":
        return h.restartPod(ctx, alert.Labels["pod"], alert.Labels["namespace"])
    case "HighMemoryUsage":
        return h.scaleUpDeployment(ctx, alert.Labels["deployment"], alert.Labels["namespace"])
    case "DatabaseConnectionPoolExhaustion":
        return h.restartDatabaseConnection(ctx)
    default:
        log.Printf("没有为告警 %s 配置自动修复", alertName)
        return nil
    }
}

// 重启Pod
func (h *IntelligentAlertHandler) restartPod(ctx context.Context, podName, namespace string) error {
    log.Printf("自动重启Pod: %s/%s", namespace, podName)
    // 实现Pod重启逻辑
    return nil
}

// 扩容Deployment
func (h *IntelligentAlertHandler) scaleUpDeployment(ctx context.Context, deployment, namespace string) error {
    log.Printf("自动扩容Deployment: %s/%s", namespace, deployment)
    // 实现Deployment扩容逻辑
    return nil
}
```

---

## 📚 最佳实践总结

### ✅ 推荐做法

1. **监控指标设计**
   - 业务指标优先于技术指标
   - 使用SLI/SLO驱动告警阈值
   - 实现多维度标签化

2. **日志管理**
   - 结构化日志统一格式
   - 敏感信息脱敏处理
   - 合理设置日志保留期

3. **告警优化**
   - 避免告警风暴
   - 实现告警分级和路由
   - 建立告警闭环流程

4. **链路追踪**
   - 合理设置采样率
   - 关键路径100%追踪
   - 避免追踪开销过大

### ❌ 避免的陷阱

1. **指标过载**
   - 避免收集无用指标
   - 控制指标基数增长

2. **告警疲劳**
   - 避免设置过低阈值
   - 减少无效告警

3. **存储成本**
   - 合理设置数据保留期
   - 使用分层存储策略

---

## 🔗 相关资源

- **Prometheus官方文档**：https://prometheus.io/docs/
- **Jaeger官方文档**：https://www.jaegertracing.io/docs/
- **Loki官方文档**：https://grafana.com/docs/loki/
- **OpenTelemetry官方文档**：https://opentelemetry.io/docs/

---

💡 **实施建议**：按照第2周的开发计划，先部署基础监控系统，然后逐步添加业务指标、链路追踪和智能告警，确保监控覆盖率达到100%。