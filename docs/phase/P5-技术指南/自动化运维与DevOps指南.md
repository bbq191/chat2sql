# üîÑ Ëá™Âä®ÂåñËøêÁª¥‰∏éDevOpsÊåáÂçó

## üéØ ÊäÄÊúØÊ¶ÇËø∞

Ëá™Âä®ÂåñËøêÁª¥‰ΩìÁ≥ª‰∏∫Chat2SQLÊèê‰æõ‰∫ÜÂÆåÊï¥ÁöÑDevOpsËÉΩÂäõÔºåÈÄöËøáCI/CDÊµÅÊ∞¥Á∫ø„ÄÅËá™Âä®ÂåñÈÉ®ÁΩ≤„ÄÅÊïÖÈöúËá™ÊÑàÁ≠âÊäÄÊúØÂÆûÁé∞È´òÊïàËøêÁª¥„ÄÇÊú¨ÊåáÂçóËØ¶ÁªÜ‰ªãÁªçP5Èò∂ÊÆµÁ¨¨4Âë®ÁöÑËá™Âä®ÂåñËøêÁª¥‰∏éDevOpsÂÆûÁé∞Á≠ñÁï•„ÄÇ

### ‚ú® Ê†∏ÂøÉ‰ª∑ÂÄº

| ÂäüËÉΩÁâπÊÄß | ÊäÄÊúØÂÆûÁé∞ | ‰∏öÂä°‰ª∑ÂÄº | ÊïàÁéáÊèêÂçá |
|---------|---------|---------|---------| 
| **CI/CDÊµÅÊ∞¥Á∫ø** | GitHub Actions + GitOps | Âø´ÈÄüËø≠‰ª£ÈÉ®ÁΩ≤ | ÈÉ®ÁΩ≤ÊïàÁéáÊèêÂçá80% |
| **Ëá™Âä®ÂåñÂ§á‰ªΩ** | CronJob + S3 + Velero | Êï∞ÊçÆÂÆâÂÖ®‰øùÈöú | ÊÅ¢Â§çÊó∂Èó¥ÂáèÂ∞ë90% |
| **ÊïÖÈöúËá™ÊÑà** | Kubernetes + Ëá™ÂÆö‰πâÊéßÂà∂Âô® | Á≥ªÁªüÁ®≥ÂÆöÊÄß | ÊïÖÈöúÊÅ¢Â§çÊó∂Èó¥ÂáèÂ∞ë85% |
| **ÊÄßËÉΩ‰ºòÂåñ** | HPA/VPA + Êô∫ËÉΩË∞ÉÂ∫¶ | ËµÑÊ∫êÂà©Áî®‰ºòÂåñ | ÊàêÊú¨ËäÇÁúÅ40% |

### üéÅ ËøêÁª¥Âú∫ÊôØ

- **ÊåÅÁª≠ÈõÜÊàê**Ôºö‰ª£Á†ÅÊèê‰∫§Ëá™Âä®Ëß¶ÂèëÊûÑÂª∫„ÄÅÊµãËØï„ÄÅÈÉ®ÁΩ≤ÊµÅÁ®ã
- **ÁéØÂ¢ÉÁÆ°ÁêÜ**ÔºöÂ§öÁéØÂ¢ÉËá™Âä®ÂåñÈÉ®ÁΩ≤„ÄÅÈÖçÁΩÆÁÆ°ÁêÜ„ÄÅÁâàÊú¨ÊéßÂà∂
- **ÁõëÊéßÂëäË≠¶**ÔºöÂÖ®Êñπ‰ΩçÁõëÊéß„ÄÅÊô∫ËÉΩÂëäË≠¶„ÄÅËá™Âä®ÂåñÂìçÂ∫î
- **ÁÅæÈöæÊÅ¢Â§ç**ÔºöÊï∞ÊçÆÂ§á‰ªΩ„ÄÅÊïÖÈöúÂàáÊç¢„ÄÅ‰∏öÂä°ËøûÁª≠ÊÄß‰øùÈöú

---

## üöÄ CI/CDÊµÅÊ∞¥Á∫ø

### üì¶ GitHub ActionsÂ∑•‰ΩúÊµÅ

```yaml
# .github/workflows/ci-cd.yml
name: Chat2SQL CI/CD Pipeline

on:
  push:
    branches: [main, develop]
    tags: ['v*']
  pull_request:
    branches: [main, develop]

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: chat2sql/backend
  HELM_CHART_PATH: ./charts/chat2sql

jobs:
  # ‰ª£Á†ÅË¥®ÈáèÊ£ÄÊü•
  code-quality:
    runs-on: ubuntu-latest
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Setup Go
      uses: actions/setup-go@v4
      with:
        go-version: '1.23'
        
    - name: Cache Go modules
      uses: actions/cache@v3
      with:
        path: ~/go/pkg/mod
        key: ${{ runner.os }}-go-${{ hashFiles('**/go.sum') }}
        
    - name: Run golangci-lint
      uses: golangci/golangci-lint-action@v3
      with:
        version: latest
        args: --timeout=5m
        
    - name: Run tests
      run: |
        go test -v -race -coverprofile=coverage.out ./...
        go tool cover -html=coverage.out -o coverage.html
        
    - name: Upload coverage
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.out
        
    - name: Security scan
      uses: securecodewarrior/github-action-add-sarif@v1
      with:
        sarif-file: gosec-report.sarif

  # ÊûÑÂª∫ÂíåÊé®ÈÄÅÈïúÂÉè
  build-and-push:
    needs: code-quality
    runs-on: ubuntu-latest
    outputs:
      image-digest: ${{ steps.build.outputs.digest }}
      image-tag: ${{ steps.meta.outputs.tags }}
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up QEMU
      uses: docker/setup-qemu-action@v3
      
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3
      
    - name: Login to Container Registry
      uses: docker/login-action@v3
      with:
        registry: ${{ env.REGISTRY }}
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}
        
    - name: Extract metadata
      id: meta
      uses: docker/metadata-action@v5
      with:
        images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
        tags: |
          type=ref,event=branch
          type=ref,event=pr
          type=semver,pattern={{version}}
          type=semver,pattern={{major}}.{{minor}}
          type=sha,prefix=commit-
          
    - name: Build and push
      id: build
      uses: docker/build-push-action@v5
      with:
        context: .
        platforms: linux/amd64,linux/arm64
        push: true
        tags: ${{ steps.meta.outputs.tags }}
        labels: ${{ steps.meta.outputs.labels }}
        cache-from: type=gha
        cache-to: type=gha,mode=max
        build-args: |
          VERSION=${{ github.ref_name }}
          COMMIT=${{ github.sha }}
          BUILD_TIME=${{ github.event.head_commit.timestamp }}

  # ÂÆπÂô®ÂÆâÂÖ®Êâ´Êèè
  security-scan:
    needs: build-and-push
    runs-on: ubuntu-latest
    steps:
    - name: Run Trivy vulnerability scanner
      uses: aquasecurity/trivy-action@master
      with:
        image-ref: ${{ needs.build-and-push.outputs.image-tag }}
        format: 'sarif'
        output: 'trivy-results.sarif'
        
    - name: Upload Trivy scan results
      uses: github/codeql-action/upload-sarif@v2
      with:
        sarif_file: 'trivy-results.sarif'

  # Helm ChartÈ™åËØÅ
  helm-validation:
    runs-on: ubuntu-latest
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Helm
      uses: azure/setup-helm@v3
      with:
        version: 'v3.15.0'
        
    - name: Lint Helm Chart
      run: |
        helm dependency update ${{ env.HELM_CHART_PATH }}
        helm lint ${{ env.HELM_CHART_PATH }}
        
    - name: Template Helm Chart
      run: |
        helm template test ${{ env.HELM_CHART_PATH }} \
          --values ${{ env.HELM_CHART_PATH }}/values-test.yaml > rendered.yaml
        kubectl --dry-run=server --validate=true apply -f rendered.yaml

  # ÈÉ®ÁΩ≤Âà∞ÂºÄÂèëÁéØÂ¢É
  deploy-dev:
    if: github.ref == 'refs/heads/develop'
    needs: [build-and-push, helm-validation, security-scan]
    runs-on: ubuntu-latest
    environment: development
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Configure kubectl
      uses: azure/k8s-set-context@v3
      with:
        method: kubeconfig
        kubeconfig: ${{ secrets.KUBE_CONFIG_DEV }}
        
    - name: Deploy to development
      run: |
        helm upgrade --install chat2sql-dev ${{ env.HELM_CHART_PATH }} \
          --namespace chat2sql-dev \
          --create-namespace \
          --values ${{ env.HELM_CHART_PATH }}/values-dev.yaml \
          --set image.tag=${{ github.sha }} \
          --wait --timeout=10m
          
    - name: Run smoke tests
      run: |
        kubectl wait --for=condition=ready pod -l app=chat2sql-backend -n chat2sql-dev --timeout=300s
        kubectl exec -n chat2sql-dev deployment/chat2sql-backend -- /app/healthcheck
        
    - name: Deploy status notification
      uses: 8398a7/action-slack@v3
      with:
        status: ${{ job.status }}
        channel: '#deployments'
        webhook_url: ${{ secrets.SLACK_WEBHOOK }}

  # ÈÉ®ÁΩ≤Âà∞Áîü‰∫ßÁéØÂ¢É
  deploy-prod:
    if: startsWith(github.ref, 'refs/tags/v')
    needs: [build-and-push, helm-validation, security-scan]
    runs-on: ubuntu-latest
    environment: production
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Configure kubectl
      uses: azure/k8s-set-context@v3
      with:
        method: kubeconfig
        kubeconfig: ${{ secrets.KUBE_CONFIG_PROD }}
        
    - name: Create backup
      run: |
        kubectl create job --from=cronjob/postgresql-backup backup-pre-deploy-$(date +%Y%m%d-%H%M%S) -n chat2sql
        
    - name: Deploy to production
      run: |
        helm upgrade --install chat2sql-prod ${{ env.HELM_CHART_PATH }} \
          --namespace chat2sql \
          --values ${{ env.HELM_CHART_PATH }}/values-prod.yaml \
          --set image.tag=${{ github.ref_name }} \
          --wait --timeout=15m
          
    - name: Run production tests
      run: |
        kubectl wait --for=condition=ready pod -l app=chat2sql-backend -n chat2sql --timeout=600s
        ./scripts/production-health-check.sh
        
    - name: Rollback on failure
      if: failure()
      run: |
        helm rollback chat2sql-prod -n chat2sql
        
    - name: Production deployment notification
      uses: 8398a7/action-slack@v3
      with:
        status: ${{ job.status }}
        channel: '#production-deployments'
        webhook_url: ${{ secrets.SLACK_WEBHOOK }}
```

### üéØ GitOpsÂ∑•‰ΩúÊµÅ

```yaml
# .github/workflows/gitops.yml
name: GitOps Sync

on:
  push:
    branches: [main]
    paths: ['manifests/**', 'charts/**']

jobs:
  sync-gitops:
    runs-on: ubuntu-latest
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Setup ArgoCD CLI
      run: |
        curl -sSL https://github.com/argoproj/argo-cd/releases/latest/download/argocd-linux-amd64 -o argocd
        chmod +x argocd
        sudo mv argocd /usr/local/bin/
        
    - name: Login to ArgoCD
      run: |
        argocd login ${{ secrets.ARGOCD_SERVER }} \
          --username ${{ secrets.ARGOCD_USERNAME }} \
          --password ${{ secrets.ARGOCD_PASSWORD }} \
          --insecure
          
    - name: Sync applications
      run: |
        argocd app sync chat2sql-prod --prune
        argocd app wait chat2sql-prod --timeout 600
        
    - name: Check application health
      run: |
        argocd app get chat2sql-prod -o json | jq '.status.health.status'
        
    - name: Notification
      if: always()
      uses: 8398a7/action-slack@v3
      with:
        status: ${{ job.status }}
        text: "GitOps sync completed for Chat2SQL"
        webhook_url: ${{ secrets.SLACK_WEBHOOK }}
```

---

## üíæ Ëá™Âä®ÂåñÂ§á‰ªΩ‰∏éÊÅ¢Â§ç

### üì¶ PostgreSQLËá™Âä®ÂåñÂ§á‰ªΩ

```yaml
# postgresql-backup-cronjob.yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: postgresql-backup
  namespace: chat2sql
spec:
  schedule: "0 2 * * *"  # ÊØèÂ§©ÂáåÊô®2ÁÇπ
  timeZone: "UTC"
  concurrencyPolicy: Forbid
  successfulJobsHistoryLimit: 7
  failedJobsHistoryLimit: 3
  jobTemplate:
    spec:
      template:
        metadata:
          labels:
            app: postgresql-backup
        spec:
          restartPolicy: OnFailure
          serviceAccountName: backup-service-account
          containers:
          - name: backup
            image: postgres:17-alpine
            env:
            - name: PGHOST
              value: postgresql.chat2sql.svc.cluster.local
            - name: PGPORT
              value: "5432"
            - name: PGDATABASE
              value: chat2sql
            - name: PGUSER
              valueFrom:
                secretKeyRef:
                  name: postgresql-backup-secret
                  key: username
            - name: PGPASSWORD
              valueFrom:
                secretKeyRef:
                  name: postgresql-backup-secret
                  key: password
            - name: AWS_ACCESS_KEY_ID
              valueFrom:
                secretKeyRef:
                  name: s3-backup-secret
                  key: access-key-id
            - name: AWS_SECRET_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  name: s3-backup-secret
                  key: secret-access-key
            - name: S3_BUCKET
              value: chat2sql-backups
            - name: S3_REGION
              value: us-west-2
            command:
            - /bin/bash
            - -c
            - |
              set -e
              
              BACKUP_DATE=$(date +%Y%m%d_%H%M%S)
              BACKUP_FILE="chat2sql_backup_${BACKUP_DATE}.sql"
              
              echo "ÂºÄÂßãÂ§á‰ªΩÊï∞ÊçÆÂ∫ì..."
              
              # ÂàõÂª∫Êï∞ÊçÆÂ∫ìÂ§á‰ªΩ
              pg_dump --verbose --no-owner --no-privileges \
                --format=custom \
                --file=/tmp/${BACKUP_FILE} \
                ${PGDATABASE}
              
              # ÂéãÁº©Â§á‰ªΩÊñá‰ª∂
              gzip /tmp/${BACKUP_FILE}
              BACKUP_FILE="${BACKUP_FILE}.gz"
              
              # ÂÆâË£ÖAWS CLI
              apk add --no-cache aws-cli
              
              # ‰∏ä‰º†Âà∞S3
              echo "‰∏ä‰º†Â§á‰ªΩÂà∞S3..."
              aws s3 cp /tmp/${BACKUP_FILE} \
                s3://${S3_BUCKET}/postgresql/${BACKUP_FILE} \
                --region ${S3_REGION}
              
              # È™åËØÅ‰∏ä‰º†
              aws s3 ls s3://${S3_BUCKET}/postgresql/${BACKUP_FILE} --region ${S3_REGION}
              
              echo "Â§á‰ªΩÂÆåÊàê: ${BACKUP_FILE}"
              
              # Ê∏ÖÁêÜÊú¨Âú∞Êñá‰ª∂
              rm -f /tmp/${BACKUP_FILE}
              
              # Âà†Èô§30Â§©ÂâçÁöÑÂ§á‰ªΩ
              aws s3 ls s3://${S3_BUCKET}/postgresql/ --region ${S3_REGION} | \
                while read -r line; do
                  backup_date=$(echo $line | awk '{print $1" "$2}')
                  backup_file=$(echo $line | awk '{print $4}')
                  if [[ $(date -d "$backup_date" +%s) -lt $(date -d "30 days ago" +%s) ]]; then
                    echo "Âà†Èô§ËøáÊúüÂ§á‰ªΩ: $backup_file"
                    aws s3 rm s3://${S3_BUCKET}/postgresql/$backup_file --region ${S3_REGION}
                  fi
                done
            resources:
              requests:
                memory: 512Mi
                cpu: 250m
              limits:
                memory: 1Gi
                cpu: 500m
          - name: metrics-exporter
            image: prom/node-exporter:latest
            ports:
            - containerPort: 9100
            command: ["/bin/node_exporter", "--web.listen-address=:9100"]
```

### üîÑ VeleroÈõÜÁæ§Â§á‰ªΩ

```yaml
# velero-backup-schedule.yaml
apiVersion: velero.io/v1
kind: Schedule
metadata:
  name: chat2sql-daily-backup
  namespace: velero
spec:
  schedule: "0 3 * * *"  # ÊØèÂ§©ÂáåÊô®3ÁÇπ
  template:
    metadata:
      labels:
        backup-type: daily
    includedNamespaces:
    - chat2sql
    - monitoring
    - vault-system
    excludedResources:
    - events
    - events.events.k8s.io
    - backups.velero.io
    - restores.velero.io
    storageLocation: default
    volumeSnapshotLocations:
    - default
    ttl: 720h  # 30Â§©
    hooks:
      resources:
      - name: postgresql-backup-hook
        includedNamespaces:
        - chat2sql
        includedResources:
        - pods
        labelSelector:
          matchLabels:
            app: postgresql
        pre:
        - exec:
            container: postgresql
            command:
            - /bin/bash
            - -c
            - |
              echo "ÂºÄÂßãÊï∞ÊçÆÂ∫ì‰∏ÄËá¥ÊÄßÊ£ÄÊü•..."
              psql -c "CHECKPOINT;" -d chat2sql
              psql -c "SELECT pg_start_backup('velero-backup', true);" -d chat2sql
        post:
        - exec:
            container: postgresql
            command:
            - /bin/bash
            - -c
            - |
              psql -c "SELECT pg_stop_backup();" -d chat2sql
              echo "Êï∞ÊçÆÂ∫ìÂ§á‰ªΩÈí©Â≠êÂÆåÊàê"
---
# Âë®Â§á‰ªΩ
apiVersion: velero.io/v1
kind: Schedule
metadata:
  name: chat2sql-weekly-backup
  namespace: velero
spec:
  schedule: "0 4 * * 0"  # ÊØèÂë®Êó•ÂáåÊô®4ÁÇπ
  template:
    metadata:
      labels:
        backup-type: weekly
    includedNamespaces:
    - chat2sql
    - monitoring
    - vault-system
    - istio-system
    - kube-system
    storageLocation: default
    ttl: 2160h  # 90Â§©
```

### üìä Â§á‰ªΩÊÅ¢Â§çËÑöÊú¨

```bash
#!/bin/bash
# restore-database.sh

set -e

BACKUP_DATE=${1:-$(date +%Y%m%d)}
S3_BUCKET="chat2sql-backups"
S3_REGION="us-west-2"
NAMESPACE="chat2sql"

echo "üîÑ ÂºÄÂßãÊÅ¢Â§çChat2SQLÊï∞ÊçÆÂ∫ìÂ§á‰ªΩ..."

# È™åËØÅÂèÇÊï∞
if [[ -z "$BACKUP_DATE" ]]; then
    echo "‚ùå ÈîôËØØ: ËØ∑Êèê‰æõÂ§á‰ªΩÊó•Êúü (Ê†ºÂºè: YYYYMMDD)"
    exit 1
fi

# Êü•ÊâæÂ§á‰ªΩÊñá‰ª∂
echo "üìã Êü•ÊâæÂ§á‰ªΩÊñá‰ª∂..."
BACKUP_FILE=$(aws s3 ls s3://${S3_BUCKET}/postgresql/ --region ${S3_REGION} | \
    grep "${BACKUP_DATE}" | tail -1 | awk '{print $4}')

if [[ -z "$BACKUP_FILE" ]]; then
    echo "‚ùå ÈîôËØØ: Êâæ‰∏çÂà∞Êó•Êúü ${BACKUP_DATE} ÁöÑÂ§á‰ªΩÊñá‰ª∂"
    echo "ÂèØÁî®Â§á‰ªΩ:"
    aws s3 ls s3://${S3_BUCKET}/postgresql/ --region ${S3_REGION}
    exit 1
fi

echo "‚úÖ ÊâæÂà∞Â§á‰ªΩÊñá‰ª∂: ${BACKUP_FILE}"

# Á°ÆËÆ§ÊÅ¢Â§çÊìç‰Ωú
read -p "‚ö†Ô∏è  Á°ÆËÆ§Ë¶ÅÊÅ¢Â§çÊï∞ÊçÆÂ∫ìÂà∞ ${BACKUP_DATE} ÁöÑÁä∂ÊÄÅÂêó? (y/N): " confirm
if [[ $confirm != [yY] ]]; then
    echo "‚ùå ÊÅ¢Â§çÊìç‰ΩúÂ∑≤ÂèñÊ∂à"
    exit 0
fi

# ÂàõÂª∫ÊÅ¢Â§ç‰Ωú‰∏ö
echo "üöÄ ÂàõÂª∫ÊÅ¢Â§ç‰Ωú‰∏ö..."
cat <<EOF | kubectl apply -f -
apiVersion: batch/v1
kind: Job
metadata:
  name: postgresql-restore-${BACKUP_DATE}
  namespace: ${NAMESPACE}
spec:
  template:
    spec:
      restartPolicy: Never
      containers:
      - name: restore
        image: postgres:17-alpine
        env:
        - name: PGHOST
          value: postgresql.chat2sql.svc.cluster.local
        - name: PGPORT
          value: "5432"
        - name: PGDATABASE
          value: chat2sql
        - name: PGUSER
          valueFrom:
            secretKeyRef:
              name: postgresql-backup-secret
              key: username
        - name: PGPASSWORD
          valueFrom:
            secretKeyRef:
              name: postgresql-backup-secret
              key: password
        - name: AWS_ACCESS_KEY_ID
          valueFrom:
            secretKeyRef:
              name: s3-backup-secret
              key: access-key-id
        - name: AWS_SECRET_ACCESS_KEY
          valueFrom:
            secretKeyRef:
              name: s3-backup-secret
              key: secret-access-key
        command:
        - /bin/bash
        - -c
        - |
          set -e
          
          # ÂÆâË£ÖAWS CLI
          apk add --no-cache aws-cli
          
          # ‰∏ãËΩΩÂ§á‰ªΩÊñá‰ª∂
          echo "üì• ‰∏ãËΩΩÂ§á‰ªΩÊñá‰ª∂..."
          aws s3 cp s3://${S3_BUCKET}/postgresql/${BACKUP_FILE} \
            /tmp/${BACKUP_FILE} --region ${S3_REGION}
          
          # Ëß£ÂéãÂ§á‰ªΩÊñá‰ª∂
          gunzip /tmp/${BACKUP_FILE}
          BACKUP_FILE=\${BACKUP_FILE%.gz}
          
          # ÂÅúÊ≠¢Â∫îÁî®ËøûÊé•
          echo "‚è∏Ô∏è  ÂÅúÊ≠¢Â∫îÁî®ËøûÊé•..."
          kubectl scale deployment chat2sql-backend --replicas=0 -n ${NAMESPACE} || true
          
          # Á≠âÂæÖËøûÊé•ÂÖ≥Èó≠
          sleep 30
          
          # ÂàõÂª∫ÊÅ¢Â§çÂâçÂ§á‰ªΩ
          echo "üíæ ÂàõÂª∫ÊÅ¢Â§çÂâçÂ§á‰ªΩ..."
          pg_dump --format=custom --file=/tmp/pre_restore_backup.sql \${PGDATABASE}
          
          # ÊÅ¢Â§çÊï∞ÊçÆÂ∫ì
          echo "üîÑ ÊÅ¢Â§çÊï∞ÊçÆÂ∫ì..."
          pg_restore --verbose --clean --if-exists \
            --no-owner --no-privileges \
            --dbname=\${PGDATABASE} /tmp/\${BACKUP_FILE}
          
          # È™åËØÅÊÅ¢Â§ç
          echo "‚úÖ È™åËØÅÊï∞ÊçÆÂ∫ìÊÅ¢Â§ç..."
          psql -c "SELECT COUNT(*) FROM users;" -d \${PGDATABASE}
          psql -c "SELECT version();" -d \${PGDATABASE}
          
          # ÈáçÊñ∞ÂêØÂä®Â∫îÁî®
          echo "üöÄ ÈáçÊñ∞ÂêØÂä®Â∫îÁî®..."
          kubectl scale deployment chat2sql-backend --replicas=3 -n ${NAMESPACE}
          
          echo "‚úÖ Êï∞ÊçÆÂ∫ìÊÅ¢Â§çÂÆåÊàê!"
        resources:
          requests:
            memory: 1Gi
            cpu: 500m
          limits:
            memory: 2Gi
            cpu: 1000m
EOF

# Á≠âÂæÖ‰Ωú‰∏öÂÆåÊàê
echo "‚è≥ Á≠âÂæÖÊÅ¢Â§ç‰Ωú‰∏öÂÆåÊàê..."
kubectl wait --for=condition=complete job/postgresql-restore-${BACKUP_DATE} \
  -n ${NAMESPACE} --timeout=1800s

# Ê£ÄÊü•‰Ωú‰∏öÁä∂ÊÄÅ
JOB_STATUS=$(kubectl get job postgresql-restore-${BACKUP_DATE} \
  -n ${NAMESPACE} -o jsonpath='{.status.conditions[0].type}')

if [[ "$JOB_STATUS" == "Complete" ]]; then
    echo "‚úÖ Êï∞ÊçÆÂ∫ìÊÅ¢Â§çÊàêÂäüÂÆåÊàê!"
    
    # ËøêË°åÂÅ•Â∫∑Ê£ÄÊü•
    echo "üîç ËøêË°åÂ∫îÁî®ÂÅ•Â∫∑Ê£ÄÊü•..."
    kubectl wait --for=condition=ready pod -l app=chat2sql-backend \
      -n ${NAMESPACE} --timeout=300s
    
    kubectl exec -n ${NAMESPACE} deployment/chat2sql-backend -- \
      /app/healthcheck
    
    echo "üéâ ÊÅ¢Â§çÊìç‰ΩúÂÆåÂÖ®ÊàêÂäü!"
else
    echo "‚ùå ÊÅ¢Â§ç‰Ωú‰∏öÂ§±Ë¥•"
    kubectl logs job/postgresql-restore-${BACKUP_DATE} -n ${NAMESPACE}
    exit 1
fi

# Ê∏ÖÁêÜÊÅ¢Â§ç‰Ωú‰∏ö
read -p "üßπ Âà†Èô§ÊÅ¢Â§ç‰Ωú‰∏ö? (Y/n): " cleanup
if [[ $cleanup != [nN] ]]; then
    kubectl delete job postgresql-restore-${BACKUP_DATE} -n ${NAMESPACE}
    echo "‚úÖ Ê∏ÖÁêÜÂÆåÊàê"
fi
```

---

## üéØ ÊïÖÈöúËá™ÊÑà‰∏éËá™Âä®ÂåñËøêÁª¥

### üì¶ Ëá™ÂÆö‰πâÊéßÂà∂Âô®

```go
// ÊïÖÈöúËá™ÊÑàÊéßÂà∂Âô®
package controller

import (
    "context"
    "fmt"
    "time"
    
    appsv1 "k8s.io/api/apps/v1"
    corev1 "k8s.io/api/core/v1"
    metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
    "k8s.io/apimachinery/pkg/runtime"
    "k8s.io/client-go/kubernetes"
    ctrl "sigs.k8s.io/controller-runtime"
    "sigs.k8s.io/controller-runtime/pkg/client"
)

// Ëá™ÊÑàÊéßÂà∂Âô®
type SelfHealingController struct {
    client.Client
    Scheme    *runtime.Scheme
    K8sClient kubernetes.Interface
    metrics   *PrometheusMetrics
}

// PodÁä∂ÊÄÅÊ£ÄÊü•ÂíåËá™ÊÑà
func (r *SelfHealingController) Reconcile(ctx context.Context, req ctrl.Request) (ctrl.Result, error) {
    log := ctrl.Log.WithValues("pod", req.NamespacedName)
    
    // Ëé∑ÂèñPod
    var pod corev1.Pod
    if err := r.Get(ctx, req.NamespacedName, &pod); err != nil {
        return ctrl.Result{}, client.IgnoreNotFound(err)
    }
    
    // Ê£ÄÊü•PodÁä∂ÊÄÅ
    if r.isPodFailing(&pod) {
        log.Info("Ê£ÄÊµãÂà∞PodÊïÖÈöú", "pod", pod.Name)
        
        if err := r.healPod(ctx, &pod); err != nil {
            log.Error(err, "PodËá™ÊÑàÂ§±Ë¥•")
            r.metrics.RecordHealingFailure(pod.Namespace, pod.Name)
            return ctrl.Result{RequeueAfter: time.Minute * 5}, err
        }
        
        r.metrics.RecordHealingSuccess(pod.Namespace, pod.Name)
        log.Info("PodËá™ÊÑàÊàêÂäü", "pod", pod.Name)
    }
    
    return ctrl.Result{RequeueAfter: time.Minute * 2}, nil
}

// Ê£ÄÊü•PodÊòØÂê¶ÊïÖÈöú
func (r *SelfHealingController) isPodFailing(pod *corev1.Pod) bool {
    // Ê£ÄÊü•ÈáçÂêØÊ¨°Êï∞
    for _, containerStatus := range pod.Status.ContainerStatuses {
        if containerStatus.RestartCount > 5 {
            return true
        }
        
        // Ê£ÄÊü•ÂÆπÂô®Áä∂ÊÄÅ
        if containerStatus.State.Waiting != nil {
            reason := containerStatus.State.Waiting.Reason
            if reason == "CrashLoopBackOff" || reason == "ImagePullBackOff" {
                return true
            }
        }
    }
    
    // Ê£ÄÊü•PodÈò∂ÊÆµ
    if pod.Status.Phase == corev1.PodFailed {
        return true
    }
    
    // Ê£ÄÊü•ËµÑÊ∫ê‰ΩøÁî®ÊÉÖÂÜµ
    if r.isResourceExhausted(pod) {
        return true
    }
    
    return false
}

// ÊâßË°åPodËá™ÊÑà
func (r *SelfHealingController) healPod(ctx context.Context, pod *corev1.Pod) error {
    log := ctrl.Log.WithValues("pod", pod.Name)
    
    // Ëé∑ÂèñDeployment
    deployment, err := r.getOwnerDeployment(ctx, pod)
    if err != nil {
        return fmt.Errorf("Ëé∑ÂèñDeploymentÂ§±Ë¥•: %w", err)
    }
    
    if deployment == nil {
        log.Info("Pod‰∏çÊòØDeploymentÁÆ°ÁêÜÔºåË∑≥ËøáËá™ÊÑà")
        return nil
    }
    
    // Ê£ÄÊü•ÊòØÂê¶ÈúÄË¶ÅÊâ©ÂÆπ
    if r.shouldScaleUp(deployment) {
        if err := r.scaleUpDeployment(ctx, deployment); err != nil {
            return fmt.Errorf("Êâ©ÂÆπDeploymentÂ§±Ë¥•: %w", err)
        }
        log.Info("Â∑≤Êâ©ÂÆπDeployment", "deployment", deployment.Name)
    }
    
    // ÈáçÂêØÂ§±Ë¥•ÁöÑPod
    if err := r.restartPod(ctx, pod); err != nil {
        return fmt.Errorf("ÈáçÂêØPodÂ§±Ë¥•: %w", err)
    }
    
    // ÂèëÈÄÅÂëäË≠¶ÈÄöÁü•
    r.sendHealingNotification(pod, "PodËá™ÊÑàÊìç‰ΩúÂ∑≤ÊâßË°å")
    
    return nil
}

// ÈáçÂêØPod
func (r *SelfHealingController) restartPod(ctx context.Context, pod *corev1.Pod) error {
    // Âà†Èô§PodÔºåËÆ©DeploymentÈáçÊñ∞ÂàõÂª∫
    if err := r.Delete(ctx, pod); err != nil {
        return fmt.Errorf("Âà†Èô§PodÂ§±Ë¥•: %w", err)
    }
    
    // Á≠âÂæÖÊñ∞PodÂêØÂä®
    time.Sleep(30 * time.Second)
    
    // È™åËØÅÊñ∞PodÁä∂ÊÄÅ
    return r.waitForPodReady(ctx, pod.Namespace, pod.Labels)
}

// Êâ©ÂÆπDeployment
func (r *SelfHealingController) scaleUpDeployment(ctx context.Context, deployment *appsv1.Deployment) error {
    if deployment.Spec.Replicas == nil {
        return fmt.Errorf("DeploymentÂâØÊú¨Êï∞‰∏∫Á©∫")
    }
    
    currentReplicas := *deployment.Spec.Replicas
    newReplicas := currentReplicas + 1
    
    // ÈôêÂà∂ÊúÄÂ§ßÂâØÊú¨Êï∞
    if newReplicas > 10 {
        return fmt.Errorf("Â∑≤ËææÂà∞ÊúÄÂ§ßÂâØÊú¨Êï∞ÈôêÂà∂")
    }
    
    deployment.Spec.Replicas = &newReplicas
    
    if err := r.Update(ctx, deployment); err != nil {
        return fmt.Errorf("Êõ¥Êñ∞DeploymentÂ§±Ë¥•: %w", err)
    }
    
    return nil
}

// Ê£ÄÊü•ÊòØÂê¶ÈúÄË¶ÅÊâ©ÂÆπ
func (r *SelfHealingController) shouldScaleUp(deployment *appsv1.Deployment) bool {
    if deployment.Spec.Replicas == nil {
        return false
    }
    
    currentReplicas := *deployment.Spec.Replicas
    readyReplicas := deployment.Status.ReadyReplicas
    
    // Â¶ÇÊûúÂ∞±Áª™ÂâØÊú¨Êï∞Â∞ë‰∫éÊúüÊúõÂâØÊú¨Êï∞ÁöÑ50%ÔºåÂàôÊâ©ÂÆπ
    return float64(readyReplicas) < float64(currentReplicas)*0.5
}
```

### üîß Ëá™Âä®ÂåñËøêÁª¥ËÑöÊú¨

```bash
#!/bin/bash
# auto-ops.sh - Ëá™Âä®ÂåñËøêÁª¥ËÑöÊú¨

set -e

NAMESPACE="chat2sql"
PROMETHEUS_URL="http://prometheus.monitoring.svc.cluster.local:9090"
SLACK_WEBHOOK_URL="https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK"

# Ê£ÄÊü•Á≥ªÁªüÂÅ•Â∫∑Áä∂ÊÄÅ
check_system_health() {
    echo "üîç Ê£ÄÊü•Á≥ªÁªüÂÅ•Â∫∑Áä∂ÊÄÅ..."
    
    # Ê£ÄÊü•PodÁä∂ÊÄÅ
    failed_pods=$(kubectl get pods -n $NAMESPACE --field-selector=status.phase=Failed -o name)
    if [[ -n "$failed_pods" ]]; then
        echo "‚ö†Ô∏è  ÂèëÁé∞Â§±Ë¥•ÁöÑPod:"
        echo "$failed_pods"
        
        # Ëá™Âä®Ê∏ÖÁêÜÂ§±Ë¥•ÁöÑPod
        echo "$failed_pods" | xargs kubectl delete -n $NAMESPACE
        send_notification "üßπ Â∑≤Ê∏ÖÁêÜÂ§±Ë¥•ÁöÑPod: $failed_pods"
    fi
    
    # Ê£ÄÊü•ËµÑÊ∫ê‰ΩøÁî®ÊÉÖÂÜµ
    check_resource_usage
    
    # Ê£ÄÊü•Â≠òÂÇ®Á©∫Èó¥
    check_storage_usage
    
    # Ê£ÄÊü•ÁΩëÁªúËøûÊé•
    check_network_connectivity
}

# Ê£ÄÊü•ËµÑÊ∫ê‰ΩøÁî®ÊÉÖÂÜµ
check_resource_usage() {
    echo "üìä Ê£ÄÊü•ËµÑÊ∫ê‰ΩøÁî®ÊÉÖÂÜµ..."
    
    # Êü•ËØ¢PrometheusÊåáÊ†á
    cpu_usage=$(curl -s "${PROMETHEUS_URL}/api/v1/query?query=avg(rate(container_cpu_usage_seconds_total{namespace=\"$NAMESPACE\"}[5m]))" | \
        jq -r '.data.result[0].value[1]' 2>/dev/null || echo "0")
    
    memory_usage=$(curl -s "${PROMETHEUS_URL}/api/v1/query?query=avg(container_memory_working_set_bytes{namespace=\"$NAMESPACE\"})/1024/1024/1024" | \
        jq -r '.data.result[0].value[1]' 2>/dev/null || echo "0")
    
    # CPU‰ΩøÁî®ÁéáÊ£ÄÊü•
    if (( $(echo "$cpu_usage > 0.8" | bc -l) )); then
        echo "‚ö†Ô∏è  CPU‰ΩøÁî®ÁéáËøáÈ´ò: ${cpu_usage}"
        auto_scale_up "high-cpu"
    fi
    
    # ÂÜÖÂ≠ò‰ΩøÁî®ÁéáÊ£ÄÊü•
    if (( $(echo "$memory_usage > 8" | bc -l) )); then
        echo "‚ö†Ô∏è  ÂÜÖÂ≠ò‰ΩøÁî®ÁéáËøáÈ´ò: ${memory_usage}GB"
        auto_scale_up "high-memory"
    fi
}

# Ëá™Âä®Êâ©ÂÆπ
auto_scale_up() {
    local reason=$1
    echo "üìà Ëß¶ÂèëËá™Âä®Êâ©ÂÆπ: $reason"
    
    deployments=$(kubectl get deployments -n $NAMESPACE -o name)
    for deployment in $deployments; do
        current_replicas=$(kubectl get $deployment -n $NAMESPACE -o jsonpath='{.spec.replicas}')
        max_replicas=10
        
        if [[ $current_replicas -lt $max_replicas ]]; then
            new_replicas=$((current_replicas + 1))
            kubectl scale $deployment --replicas=$new_replicas -n $NAMESPACE
            echo "‚úÖ Êâ©ÂÆπ $deployment: $current_replicas -> $new_replicas"
            
            send_notification "üìà Ëá™Âä®Êâ©ÂÆπ: $deployment ($reason)"
        fi
    done
}

# Ê£ÄÊü•Â≠òÂÇ®‰ΩøÁî®ÊÉÖÂÜµ
check_storage_usage() {
    echo "üíæ Ê£ÄÊü•Â≠òÂÇ®‰ΩøÁî®ÊÉÖÂÜµ..."
    
    # Ê£ÄÊü•PVC‰ΩøÁî®ÊÉÖÂÜµ
    pvcs=$(kubectl get pvc -n $NAMESPACE -o json)
    echo "$pvcs" | jq -r '.items[] | select(.status.capacity.storage) | "\(.metadata.name) \(.status.capacity.storage)"' | \
    while read pvc_name capacity; do
        # ËøôÈáåÂèØ‰ª•Ê∑ªÂä†Â≠òÂÇ®‰ΩøÁî®ÁéáÊ£ÄÊü•ÈÄªËæë
        echo "PVC: $pvc_name, ÂÆπÈáè: $capacity"
    done
    
    # Ê£ÄÊü•ËäÇÁÇπÂ≠òÂÇ®Á©∫Èó¥
    kubectl top nodes | awk 'NR>1 {if($5+0 > 80) print "‚ö†Ô∏è  ËäÇÁÇπÂ≠òÂÇ®‰ΩøÁî®ÁéáËøáÈ´ò: " $1 " " $5}'
}

# Ê£ÄÊü•ÁΩëÁªúËøûÊé•
check_network_connectivity() {
    echo "üåê Ê£ÄÊü•ÁΩëÁªúËøûÊé•..."
    
    # Ê£ÄÊü•ÊúçÂä°Èó¥ËøûÊé•
    kubectl exec -n $NAMESPACE deployment/chat2sql-backend -- \
        nc -zv postgresql.chat2sql.svc.cluster.local 5432 || \
        echo "‚ùå Êï∞ÊçÆÂ∫ìËøûÊé•Â§±Ë¥•"
    
    kubectl exec -n $NAMESPACE deployment/chat2sql-backend -- \
        nc -zv redis.chat2sql.svc.cluster.local 6379 || \
        echo "‚ùå RedisËøûÊé•Â§±Ë¥•"
}

# Ëá™Âä®Ê∏ÖÁêÜËµÑÊ∫ê
cleanup_resources() {
    echo "üßπ Ê∏ÖÁêÜËøáÊúüËµÑÊ∫ê..."
    
    # Ê∏ÖÁêÜÂÆåÊàêÁöÑJob
    kubectl delete jobs -n $NAMESPACE --field-selector=status.successful=1 \
        $(kubectl get jobs -n $NAMESPACE -o jsonpath='{.items[?(@.status.completionTime<"'$(date -d '7 days ago' -Iseconds)'")].metadata.name}') 2>/dev/null || true
    
    # Ê∏ÖÁêÜËøáÊúüÁöÑPod
    kubectl delete pods -n $NAMESPACE --field-selector=status.phase=Succeeded \
        $(kubectl get pods -n $NAMESPACE -o jsonpath='{.items[?(@.status.startTime<"'$(date -d '1 day ago' -Iseconds)'")].metadata.name}') 2>/dev/null || true
    
    # Ê∏ÖÁêÜËøáÊúüÁöÑSecretÔºà‰∏¥Êó∂ËØÅ‰π¶Á≠âÔºâ
    kubectl get secrets -n $NAMESPACE -o json | jq -r '.items[] | select(.metadata.annotations."cert-manager.io/certificate-name") | select(.metadata.creationTimestamp < "'$(date -d '30 days ago' -Iseconds)'") | .metadata.name' | \
    xargs -I {} kubectl delete secret {} -n $NAMESPACE 2>/dev/null || true
}

# Êï∞ÊçÆÂ∫ìÁª¥Êä§
database_maintenance() {
    echo "üóÑÔ∏è  ÊâßË°åÊï∞ÊçÆÂ∫ìÁª¥Êä§..."
    
    # Êï∞ÊçÆÂ∫ìËøûÊé•Êï∞Ê£ÄÊü•
    active_connections=$(kubectl exec -n $NAMESPACE deployment/postgresql -- \
        psql -t -c "SELECT count(*) FROM pg_stat_activity WHERE state = 'active';" | tr -d ' ')
    
    if [[ $active_connections -gt 80 ]]; then
        echo "‚ö†Ô∏è  Êï∞ÊçÆÂ∫ìËøûÊé•Êï∞ËøáÂ§ö: $active_connections"
        # ÁªàÊ≠¢ÈïøÊó∂Èó¥ËøêË°åÁöÑÊü•ËØ¢
        kubectl exec -n $NAMESPACE deployment/postgresql -- \
            psql -c "SELECT pg_terminate_backend(pid) FROM pg_stat_activity WHERE state = 'active' AND query_start < now() - interval '10 minutes';"
    fi
    
    # Êï∞ÊçÆÂ∫ìÁªüËÆ°‰ø°ÊÅØÊõ¥Êñ∞
    kubectl exec -n $NAMESPACE deployment/postgresql -- \
        psql -c "ANALYZE;" chat2sql
    
    # Ê∏ÖÁêÜËøáÊúüÁöÑÊü•ËØ¢ÂéÜÂè≤
    kubectl exec -n $NAMESPACE deployment/postgresql -- \
        psql -c "DELETE FROM query_history WHERE created_at < now() - interval '90 days';" chat2sql
}

# ÂèëÈÄÅÈÄöÁü•
send_notification() {
    local message=$1
    local timestamp=$(date '+%Y-%m-%d %H:%M:%S')
    
    curl -X POST -H 'Content-type: application/json' \
        --data "{\"text\":\"[$timestamp] Chat2SQLËá™Âä®ËøêÁª¥: $message\"}" \
        $SLACK_WEBHOOK_URL || true
}

# ‰∏ªÂáΩÊï∞
main() {
    echo "üöÄ ÂºÄÂßãËá™Âä®ÂåñËøêÁª¥Ê£ÄÊü• - $(date)"
    
    check_system_health
    cleanup_resources
    database_maintenance
    
    echo "‚úÖ Ëá™Âä®ÂåñËøêÁª¥Ê£ÄÊü•ÂÆåÊàê - $(date)"
    send_notification "‚úÖ Ëá™Âä®ÂåñËøêÁª¥Ê£ÄÊü•ÂÆåÊàê"
}

# Â¶ÇÊûúËÑöÊú¨Ë¢´Áõ¥Êé•ÊâßË°å
if [[ "${BASH_SOURCE[0]}" == "${0}" ]]; then
    main "$@"
fi
```

---

## üìä ÊÄßËÉΩ‰ºòÂåñ‰∏éÊô∫ËÉΩÊâ©Áº©ÂÆπ

### üì¶ KEDAËá™ÂÆö‰πâÊâ©Áº©ÂÆπ

```yaml
# keda-scaledobject.yaml
apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: chat2sql-backend-scaler
  namespace: chat2sql
spec:
  scaleTargetRef:
    name: chat2sql-backend
  minReplicaCount: 2
  maxReplicaCount: 20
  cooldownPeriod: 300
  pollingInterval: 30
  triggers:
  # Âü∫‰∫éCPU‰ΩøÁî®Áéá
  - type: cpu
    metadata:
      type: Utilization
      value: "70"
  # Âü∫‰∫éÂÜÖÂ≠ò‰ΩøÁî®Áéá
  - type: memory
    metadata:
      type: Utilization
      value: "80"
  # Âü∫‰∫éHTTPËØ∑Ê±ÇÈòüÂàóÈïøÂ∫¶
  - type: prometheus
    metadata:
      serverAddress: http://prometheus.monitoring.svc.cluster.local:9090
      metricName: http_requests_per_second
      threshold: "50"
      query: sum(rate(http_requests_total{job="chat2sql-backend"}[2m]))
  # Âü∫‰∫éÊï∞ÊçÆÂ∫ìËøûÊé•Êï∞
  - type: prometheus
    metadata:
      serverAddress: http://prometheus.monitoring.svc.cluster.local:9090
      metricName: database_connections_active
      threshold: "80"
      query: sum(chat2sql_db_connections_active{pool="main"})
  # Âü∫‰∫éAIÊé®ÁêÜÈòüÂàóÈïøÂ∫¶
  - type: redis
    metadata:
      address: redis.chat2sql.svc.cluster.local:6379
      listName: ai_inference_queue
      listLength: "10"
      enableTLS: "false"
---
# Êï∞ÊçÆÂ∫ìÊâ©Áº©ÂÆπ
apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: postgresql-readonly-scaler
  namespace: chat2sql
spec:
  scaleTargetRef:
    name: postgresql-readonly
  minReplicaCount: 1
  maxReplicaCount: 5
  triggers:
  - type: prometheus
    metadata:
      serverAddress: http://prometheus.monitoring.svc.cluster.local:9090
      metricName: database_cpu_usage
      threshold: "60"
      query: avg(rate(container_cpu_usage_seconds_total{pod=~"postgresql-readonly-.*"}[5m])) * 100
```

### üéØ VPAÈÖçÁΩÆ

```yaml
# vpa-recommender.yaml
apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: chat2sql-backend-vpa
  namespace: chat2sql
spec:
  targetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: chat2sql-backend
  updatePolicy:
    updateMode: "Auto"
  resourcePolicy:
    containerPolicies:
    - containerName: chat2sql
      minAllowed:
        cpu: 100m
        memory: 256Mi
      maxAllowed:
        cpu: 2000m
        memory: 4Gi
      controlledResources: ["cpu", "memory"]
      controlledValues: RequestsAndLimits
---
# PostgreSQL VPA
apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: postgresql-vpa
  namespace: chat2sql
spec:
  targetRef:
    apiVersion: apps/v1
    kind: StatefulSet
    name: postgresql
  updatePolicy:
    updateMode: "Off"  # ‰ªÖÊé®ËçêÔºå‰∏çËá™Âä®Êõ¥Êñ∞
  resourcePolicy:
    containerPolicies:
    - containerName: postgresql
      minAllowed:
        cpu: 500m
        memory: 1Gi
      maxAllowed:
        cpu: 4000m
        memory: 16Gi
```

---

## üß™ Ê∑∑Ê≤åÂ∑•Á®ã‰∏éÈüßÊÄßÊµãËØï

### üì¶ Chaos MeshÂÆûÈ™å

```yaml
# chaos-experiments.yaml
apiVersion: chaos-mesh.org/v1alpha1
kind: PodChaos
metadata:
  name: chat2sql-pod-failure
  namespace: chat2sql
spec:
  action: pod-kill
  mode: one
  duration: "30s"
  scheduler:
    cron: "0 */6 * * *"  # ÊØè6Â∞èÊó∂ÊâßË°å‰∏ÄÊ¨°
  selector:
    namespaces:
    - chat2sql
    labelSelectors:
      "app": "chat2sql-backend"
---
# ÁΩëÁªúÂª∂ËøüÂÆûÈ™å
apiVersion: chaos-mesh.org/v1alpha1
kind: NetworkChaos
metadata:
  name: chat2sql-network-delay
  namespace: chat2sql
spec:
  action: delay
  mode: one
  duration: "5m"
  scheduler:
    cron: "0 2 * * 1"  # ÊØèÂë®‰∏ÄÂáåÊô®2ÁÇπ
  selector:
    namespaces:
    - chat2sql
    labelSelectors:
      "app": "chat2sql-backend"
  delay:
    latency: "100ms"
    correlation: "100"
    jitter: "10ms"
  direction: to
  target:
    mode: one
    selector:
      namespaces:
      - chat2sql
      labelSelectors:
        "app": "postgresql"
---
# Á£ÅÁõòIOÂéãÂäõÊµãËØï
apiVersion: chaos-mesh.org/v1alpha1
kind: StressChaos
metadata:
  name: chat2sql-disk-stress
  namespace: chat2sql
spec:
  mode: one
  duration: "10m"
  scheduler:
    cron: "0 3 * * 0"  # ÊØèÂë®Êó•ÂáåÊô®3ÁÇπ
  selector:
    namespaces:
    - chat2sql
    labelSelectors:
      "app": "postgresql"
  stressors:
    iomix:
      workers: 2
      size: "1GB"
```

### üîç ÈüßÊÄßÊµãËØïËÑöÊú¨

```bash
#!/bin/bash
# resilience-test.sh

set -e

NAMESPACE="chat2sql"
TEST_DURATION="300"  # 5ÂàÜÈíü
CONCURRENT_USERS="50"

echo "üß™ ÂºÄÂßãÈüßÊÄßÊµãËØï..."

# ËøêË°åË¥üËΩΩÊµãËØï
run_load_test() {
    echo "üìà ÂêØÂä®Ë¥üËΩΩÊµãËØï..."
    
    kubectl run load-test --image=grafana/k6:latest --rm -i --restart=Never -- \
        run - <<EOF
import http from 'k6/http';
import { check, sleep } from 'k6';

export let options = {
    vus: $CONCURRENT_USERS,
    duration: '${TEST_DURATION}s',
    thresholds: {
        http_req_duration: ['p(95)<2000'],
        http_req_failed: ['rate<0.1'],
    },
};

export default function() {
    let response = http.post('http://chat2sql-backend.chat2sql.svc.cluster.local:8080/api/query', 
        JSON.stringify({
            query: "SELECT COUNT(*) FROM users WHERE active = true"
        }), 
        {
            headers: {
                'Content-Type': 'application/json',
                'Authorization': 'Bearer test-token'
            }
        }
    );
    
    check(response, {
        'status is 200': (r) => r.status === 200,
        'response time < 2s': (r) => r.timings.duration < 2000,
    });
    
    sleep(1);
}
EOF
}

# ÊïÖÈöúÊ≥®ÂÖ•ÊµãËØï
inject_failures() {
    echo "üí• Ê≥®ÂÖ•ÊïÖÈöúËøõË°åÊµãËØï..."
    
    # PodÊïÖÈöú
    kubectl apply -f - <<EOF
apiVersion: chaos-mesh.org/v1alpha1
kind: PodChaos
metadata:
  name: resilience-test-pod-kill
  namespace: $NAMESPACE
spec:
  action: pod-kill
  mode: fixed-percent
  value: "33"
  duration: "60s"
  selector:
    namespaces:
    - $NAMESPACE
    labelSelectors:
      "app": "chat2sql-backend"
EOF
    
    sleep 60
    
    # ÁΩëÁªúÊïÖÈöú
    kubectl apply -f - <<EOF
apiVersion: chaos-mesh.org/v1alpha1
kind: NetworkChaos
metadata:
  name: resilience-test-network-partition
  namespace: $NAMESPACE
spec:
  action: partition
  mode: one
  duration: "60s"
  selector:
    namespaces:
    - $NAMESPACE
    labelSelectors:
      "app": "chat2sql-backend"
  direction: both
  target:
    mode: one
    selector:
      namespaces:
      - $NAMESPACE
      labelSelectors:
        "app": "postgresql"
EOF
    
    sleep 60
}

# ÁõëÊéßÂíåÊî∂ÈõÜÊåáÊ†á
monitor_metrics() {
    echo "üìä Êî∂ÈõÜÈüßÊÄßÊµãËØïÊåáÊ†á..."
    
    # ÈîôËØØÁéá
    error_rate=$(kubectl exec -n monitoring deployment/prometheus -- \
        promtool query instant 'rate(http_requests_total{status=~"5.."}[5m]) / rate(http_requests_total[5m])' | \
        grep -o '[0-9.]*' | tail -1)
    
    # Âπ≥ÂùáÂìçÂ∫îÊó∂Èó¥
    avg_response_time=$(kubectl exec -n monitoring deployment/prometheus -- \
        promtool query instant 'histogram_quantile(0.5, rate(http_request_duration_seconds_bucket[5m]))' | \
        grep -o '[0-9.]*' | tail -1)
    
    # ÊÅ¢Â§çÊó∂Èó¥
    recovery_time=$(kubectl exec -n monitoring deployment/prometheus -- \
        promtool query instant 'time() - on() chat2sql_last_failure_timestamp' | \
        grep -o '[0-9.]*' | tail -1)
    
    echo "üìà ÈüßÊÄßÊµãËØïÁªìÊûú:"
    echo "   ÈîôËØØÁéá: ${error_rate}%"
    echo "   Âπ≥ÂùáÂìçÂ∫îÊó∂Èó¥: ${avg_response_time}s"
    echo "   ÊÅ¢Â§çÊó∂Èó¥: ${recovery_time}s"
}

# Ê∏ÖÁêÜÊµãËØïËµÑÊ∫ê
cleanup() {
    echo "üßπ Ê∏ÖÁêÜÊµãËØïËµÑÊ∫ê..."
    
    kubectl delete podchaos resilience-test-pod-kill -n $NAMESPACE --ignore-not-found
    kubectl delete networkchaos resilience-test-network-partition -n $NAMESPACE --ignore-not-found
    
    echo "‚úÖ Ê∏ÖÁêÜÂÆåÊàê"
}

# ‰∏ªÂáΩÊï∞
main() {
    trap cleanup EXIT
    
    echo "üöÄ ÂºÄÂßãÈüßÊÄßÊµãËØï - $(date)"
    
    # Âπ∂Ë°åËøêË°åË¥üËΩΩÊµãËØïÂíåÊïÖÈöúÊ≥®ÂÖ•
    run_load_test &
    LOAD_TEST_PID=$!
    
    sleep 60  # ËÆ©Ë¥üËΩΩÊµãËØïÂÖàËøêË°å1ÂàÜÈíü
    inject_failures
    
    wait $LOAD_TEST_PID
    
    monitor_metrics
    
    echo "‚úÖ ÈüßÊÄßÊµãËØïÂÆåÊàê - $(date)"
}

main "$@"
```

---

## üìö ÊúÄ‰Ω≥ÂÆûË∑µÊÄªÁªì

### ‚úÖ Êé®ËçêÂÅöÊ≥ï

1. **CI/CDÊµÅÊ∞¥Á∫ø**
   - Ëá™Âä®ÂåñÊµãËØïË¶ÜÁõñÁéá>80%
   - Â§öÁéØÂ¢ÉÈÉ®ÁΩ≤Á≠ñÁï•
   - ÂõûÊªöÊú∫Âà∂ÂÆåÂñÑ

2. **Â§á‰ªΩÁ≠ñÁï•**
   - Ëá™Âä®ÂåñÂÆöÊúüÂ§á‰ªΩ
   - Ë∑®Âú∞ÂüüÂ§á‰ªΩÂ≠òÂÇ®
   - ÂÆöÊúüÊÅ¢Â§çÊºîÁªÉ

3. **ÁõëÊéßÂëäË≠¶**
   - ‰∏öÂä°ÊåáÊ†á‰ºòÂÖà
   - ÂàÜÁ∫ßÂëäË≠¶Êú∫Âà∂
   - Ëá™Âä®ÂåñÂìçÂ∫î

4. **ÊïÖÈöúÂ§ÑÁêÜ**
   - È¢ÑÂÆö‰πâÂ§ÑÁêÜÊµÅÁ®ã
   - Ëá™Âä®ÂåñÊïÖÈöúÊÅ¢Â§ç
   - ÊïÖÈöúÂ§çÁõòÊú∫Âà∂

### ‚ùå ÈÅøÂÖçÁöÑÈô∑Èò±

1. **ËøáÂ∫¶Ëá™Âä®Âåñ**
   - ÈÅøÂÖçËá™Âä®ÂåñÂÖ≥ÈîÆÊìç‰ΩúÊó†‰∫∫ÂÆ°Ê†∏
   - ‰øùÁïôÊâãÂä®Âπ≤È¢ÑËÉΩÂäõ

2. **Â§á‰ªΩÁñèÊºè**
   - ‰∏çË¶ÅÂøΩËßÜÂ§á‰ªΩÈ™åËØÅ
   - ÈÅøÂÖçÂçïÁÇπÂ§á‰ªΩÂ§±Ë¥•

3. **ÂëäË≠¶ËøáËΩΩ**
   - ÈÅøÂÖçÂëäË≠¶È£éÊö¥
   - ÂêàÁêÜËÆæÁΩÆÂëäË≠¶ÈòàÂÄº

---

## üîó Áõ∏ÂÖ≥ËµÑÊ∫ê

- **KubernetesÂÆòÊñπËøêÁª¥ÊåáÂçó**Ôºöhttps://kubernetes.io/docs/tasks/
- **PrometheusÁõëÊéßÊúÄ‰Ω≥ÂÆûË∑µ**Ôºöhttps://prometheus.io/docs/practices/
- **Chaos EngineeringÂéüÁêÜ**Ôºöhttps://principlesofchaos.org/
- **GitOpsÂ∑•‰ΩúÊµÅÊåáÂçó**Ôºöhttps://www.gitops.tech/

---

üí° **ÂÆûÊñΩÂª∫ËÆÆ**ÔºöÊåâÁÖßÁ¨¨4Âë®ÁöÑÂºÄÂèëËÆ°ÂàíÔºåÂÖàÂª∫Á´ãCI/CDÊµÅÊ∞¥Á∫øÔºåÁÑ∂ÂêéÂÆûÁé∞Ëá™Âä®ÂåñÂ§á‰ªΩ„ÄÅÊïÖÈöúËá™ÊÑàÊú∫Âà∂ÔºåÊúÄÂêéËøõË°åÈüßÊÄßÊµãËØïÈ™åËØÅÔºåÁ°Æ‰øùËøêÁª¥Ëá™Âä®ÂåñÁ®ãÂ∫¶ËææÂà∞90%‰ª•‰∏ä„ÄÇ